{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from implmentations import *\n",
    "from helpers import *\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing and split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio = 0.8  #ratio is the percentage of the data allocated for training \n",
    "seed = 1  #random seed for data shuffling\n",
    "x_tr, y_tr, x_te, y_te = preprocess_data() #preprocess intput data from the training and test sets\n",
    "x_tr, x_v, y_tr, y_v = split_data(x_tr, y_tr, ratio, seed) #split training data into training and validation sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient descent training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GD iter. 0/119: loss=0.1710925\n",
      "GD iter. 1/119: loss=0.1507788120723302\n",
      "GD iter. 2/119: loss=0.1379807832186268\n",
      "GD iter. 3/119: loss=0.12829206477993352\n",
      "GD iter. 4/119: loss=0.12076152783792526\n",
      "GD iter. 5/119: loss=0.11483679099935948\n",
      "GD iter. 6/119: loss=0.11013123064064143\n",
      "GD iter. 7/119: loss=0.10636456660669256\n",
      "GD iter. 8/119: loss=0.10332936490285559\n",
      "GD iter. 9/119: loss=0.10086940201838299\n",
      "GD iter. 10/119: loss=0.09886525901515608\n",
      "GD iter. 11/119: loss=0.09722451219516665\n",
      "GD iter. 12/119: loss=0.09587490310016941\n",
      "GD iter. 13/119: loss=0.09475947724687928\n",
      "GD iter. 14/119: loss=0.09383305117249642\n",
      "GD iter. 15/119: loss=0.09305959544955598\n",
      "GD iter. 16/119: loss=0.09241026334385057\n",
      "GD iter. 17/119: loss=0.09186188432520141\n",
      "GD iter. 18/119: loss=0.09139579892901982\n",
      "GD iter. 19/119: loss=0.090996948748936\n",
      "GD iter. 20/119: loss=0.09065316006813702\n",
      "GD iter. 21/119: loss=0.09035457637679377\n",
      "GD iter. 22/119: loss=0.09009320659948655\n",
      "GD iter. 23/119: loss=0.08986256403512916\n",
      "GD iter. 24/119: loss=0.08965737690991366\n",
      "GD iter. 25/119: loss=0.08947335577908516\n",
      "GD iter. 26/119: loss=0.08930700625492334\n",
      "GD iter. 27/119: loss=0.08915547799838902\n",
      "GD iter. 28/119: loss=0.08901644280257054\n",
      "GD iter. 29/119: loss=0.08888799606439397\n",
      "GD iter. 30/119: loss=0.08876857709116058\n",
      "GD iter. 31/119: loss=0.08865690459552812\n",
      "GD iter. 32/119: loss=0.08855192445185608\n",
      "GD iter. 33/119: loss=0.08845276735975069\n",
      "GD iter. 34/119: loss=0.08835871451853652\n",
      "GD iter. 35/119: loss=0.0882691697833513\n",
      "GD iter. 36/119: loss=0.0881836370682949\n",
      "GD iter. 37/119: loss=0.08810170199919529\n",
      "GD iter. 38/119: loss=0.08802301700960115\n",
      "GD iter. 39/119: loss=0.08794728922770226\n",
      "GD iter. 40/119: loss=0.0878742706262736\n",
      "GD iter. 41/119: loss=0.08780375000823695\n",
      "GD iter. 42/119: loss=0.08773554648167169\n",
      "GD iter. 43/119: loss=0.0876695041438122\n",
      "GD iter. 44/119: loss=0.08760548774673436\n",
      "GD iter. 45/119: loss=0.08754337916046621\n",
      "GD iter. 46/119: loss=0.08748307448410401\n",
      "GD iter. 47/119: loss=0.08742448168373718\n",
      "GD iter. 48/119: loss=0.08736751865884962\n",
      "GD iter. 49/119: loss=0.08731211165739616\n",
      "GD iter. 50/119: loss=0.08725819397476858\n",
      "GD iter. 51/119: loss=0.08720570488404533\n",
      "GD iter. 52/119: loss=0.0871545887547906\n",
      "GD iter. 53/119: loss=0.08710479432567925\n",
      "GD iter. 54/119: loss=0.08705627410272007\n",
      "GD iter. 55/119: loss=0.08700898386012375\n",
      "GD iter. 56/119: loss=0.08696288222514138\n",
      "GD iter. 57/119: loss=0.08691793033167255\n",
      "GD iter. 58/119: loss=0.08687409153026608\n",
      "GD iter. 59/119: loss=0.08683133114442654\n",
      "GD iter. 60/119: loss=0.08678961626500323\n",
      "GD iter. 61/119: loss=0.08674891557595243\n",
      "GD iter. 62/119: loss=0.08670919920599417\n",
      "GD iter. 63/119: loss=0.0866704386016868\n",
      "GD iter. 64/119: loss=0.08663260641825729\n",
      "GD iter. 65/119: loss=0.08659567642518928\n",
      "GD iter. 66/119: loss=0.08655962342411032\n",
      "GD iter. 67/119: loss=0.08652442317696193\n",
      "GD iter. 68/119: loss=0.08649005234279386\n",
      "GD iter. 69/119: loss=0.08645648842181834\n",
      "GD iter. 70/119: loss=0.08642370970559879\n",
      "GD iter. 71/119: loss=0.08639169523244389\n",
      "GD iter. 72/119: loss=0.0863604247472373\n",
      "GD iter. 73/119: loss=0.0863298786650655\n",
      "GD iter. 74/119: loss=0.08630003803811233\n",
      "GD iter. 75/119: loss=0.08627088452537868\n",
      "GD iter. 76/119: loss=0.0862424003648567\n",
      "GD iter. 77/119: loss=0.086214568347849\n",
      "GD iter. 78/119: loss=0.08618737179517114\n",
      "GD iter. 79/119: loss=0.08616079453501768\n",
      "GD iter. 80/119: loss=0.08613482088230451\n",
      "GD iter. 81/119: loss=0.08610943561932861\n",
      "GD iter. 82/119: loss=0.08608462397760977\n",
      "GD iter. 83/119: loss=0.08606037162079692\n",
      "GD iter. 84/119: loss=0.08603666462853947\n",
      "GD iter. 85/119: loss=0.0860134894812359\n",
      "GD iter. 86/119: loss=0.08599083304558428\n",
      "GD iter. 87/119: loss=0.08596868256086827\n",
      "GD iter. 88/119: loss=0.08594702562592056\n",
      "GD iter. 89/119: loss=0.08592585018671213\n",
      "GD iter. 90/119: loss=0.08590514452452197\n",
      "GD iter. 91/119: loss=0.08588489724464687\n",
      "GD iter. 92/119: loss=0.08586509726561384\n",
      "GD iter. 93/119: loss=0.08584573380886422\n",
      "GD iter. 94/119: loss=0.08582679638887801\n",
      "GD iter. 95/119: loss=0.0858082748037132\n",
      "GD iter. 96/119: loss=0.08579015912593474\n",
      "GD iter. 97/119: loss=0.08577243969391117\n",
      "GD iter. 98/119: loss=0.08575510710345878\n",
      "GD iter. 99/119: loss=0.08573815219981383\n",
      "GD iter. 100/119: loss=0.08572156606991622\n",
      "GD iter. 101/119: loss=0.08570534003498802\n",
      "GD iter. 102/119: loss=0.08568946564339218\n",
      "GD iter. 103/119: loss=0.08567393466375783\n",
      "GD iter. 104/119: loss=0.08565873907835866\n",
      "GD iter. 105/119: loss=0.08564387107673306\n",
      "GD iter. 106/119: loss=0.08562932304953406\n",
      "GD iter. 107/119: loss=0.0856150875825991\n",
      "GD iter. 108/119: loss=0.08560115745122923\n",
      "GD iter. 109/119: loss=0.08558752561466887\n",
      "GD iter. 110/119: loss=0.08557418521077693\n",
      "GD iter. 111/119: loss=0.08556112955088117\n",
      "GD iter. 112/119: loss=0.08554835211480788\n",
      "GD iter. 113/119: loss=0.08553584654608001\n",
      "GD iter. 114/119: loss=0.08552360664727583\n",
      "GD iter. 115/119: loss=0.08551162637554238\n",
      "GD iter. 116/119: loss=0.0854998998382569\n",
      "GD iter. 117/119: loss=0.08548842128883036\n",
      "GD iter. 118/119: loss=0.08547718512264768\n",
      "GD iter. 119/119: loss=0.08546618587313902\n"
     ]
    }
   ],
   "source": [
    "# Define the parameters of the algorithm.\n",
    "max_iters = 120\n",
    "gamma = 0.1\n",
    "# Initialization\n",
    "initial_w = generate_w(x_tr.shape)\n",
    "w, loss = mean_squared_error_gd(y_tr, x_tr, initial_w, max_iters, gamma)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training accuracy is: 0.7416\n",
      "The validation accuracy is: 0.7409600000000001\n"
     ]
    }
   ],
   "source": [
    "print(\"The training accuracy is:\", get_accuracy(y_tr, x_tr, w))\n",
    "print(\"The validation accuracy is:\", get_accuracy(y_v, x_v, w))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SGD training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD iter. 0/99: loss=0.22\n",
      "SGD iter. 1/99: loss=0.18874003830963992\n",
      "SGD iter. 2/99: loss=0.19961883383071083\n",
      "SGD iter. 3/99: loss=0.1489904761763348\n",
      "SGD iter. 4/99: loss=0.1612607033998702\n",
      "SGD iter. 5/99: loss=0.1317553048967049\n",
      "SGD iter. 6/99: loss=0.19990065898721432\n",
      "SGD iter. 7/99: loss=0.13084697146656507\n",
      "SGD iter. 8/99: loss=0.10347821021664405\n",
      "SGD iter. 9/99: loss=0.11552288375159403\n",
      "SGD iter. 10/99: loss=0.10155106758771121\n",
      "SGD iter. 11/99: loss=0.1636962814802348\n",
      "SGD iter. 12/99: loss=0.12125711653377634\n",
      "SGD iter. 13/99: loss=0.11044349006489007\n",
      "SGD iter. 14/99: loss=0.0988205309472375\n",
      "SGD iter. 15/99: loss=0.11031589577014085\n",
      "SGD iter. 16/99: loss=0.11791190558898883\n",
      "SGD iter. 17/99: loss=0.10391852003317081\n",
      "SGD iter. 18/99: loss=0.11121441750272382\n",
      "SGD iter. 19/99: loss=0.09989218501731627\n",
      "SGD iter. 20/99: loss=0.10025048034754254\n",
      "SGD iter. 21/99: loss=0.12678043286266039\n",
      "SGD iter. 22/99: loss=0.12099256612892562\n",
      "SGD iter. 23/99: loss=0.11946199160607218\n",
      "SGD iter. 24/99: loss=0.07776603564093469\n",
      "SGD iter. 25/99: loss=0.09513672190578525\n",
      "SGD iter. 26/99: loss=0.08855998313547749\n",
      "SGD iter. 27/99: loss=0.09761724878277424\n",
      "SGD iter. 28/99: loss=0.10823147685801482\n",
      "SGD iter. 29/99: loss=0.08869321938934364\n",
      "SGD iter. 30/99: loss=0.10182854423486465\n",
      "SGD iter. 31/99: loss=0.10288649682702289\n",
      "SGD iter. 32/99: loss=0.1124436074048575\n",
      "SGD iter. 33/99: loss=0.1145438013267797\n",
      "SGD iter. 34/99: loss=0.08253253781936905\n",
      "SGD iter. 35/99: loss=0.087446598582707\n",
      "SGD iter. 36/99: loss=0.12777423996018383\n",
      "SGD iter. 37/99: loss=0.09866433197329039\n",
      "SGD iter. 38/99: loss=0.09560861450832916\n",
      "SGD iter. 39/99: loss=0.10774253348987178\n",
      "SGD iter. 40/99: loss=0.08608155750916001\n",
      "SGD iter. 41/99: loss=0.11752922877678391\n",
      "SGD iter. 42/99: loss=0.08137274891824427\n",
      "SGD iter. 43/99: loss=0.10524703113169576\n",
      "SGD iter. 44/99: loss=0.0900772890920754\n",
      "SGD iter. 45/99: loss=0.07905762173306809\n",
      "SGD iter. 46/99: loss=0.10116825566667527\n",
      "SGD iter. 47/99: loss=0.07911592729272479\n",
      "SGD iter. 48/99: loss=0.10721139554346552\n",
      "SGD iter. 49/99: loss=0.06301203972242796\n",
      "SGD iter. 50/99: loss=0.08090168420001877\n",
      "SGD iter. 51/99: loss=0.09233870273461628\n",
      "SGD iter. 52/99: loss=0.08636090355149817\n",
      "SGD iter. 53/99: loss=0.08953912014343392\n",
      "SGD iter. 54/99: loss=0.07721651444427771\n",
      "SGD iter. 55/99: loss=0.07340185946881085\n",
      "SGD iter. 56/99: loss=0.08406234072578472\n",
      "SGD iter. 57/99: loss=0.09492333580500789\n",
      "SGD iter. 58/99: loss=0.07818615452408713\n",
      "SGD iter. 59/99: loss=0.08320956065433924\n",
      "SGD iter. 60/99: loss=0.08555773858074443\n",
      "SGD iter. 61/99: loss=0.08528185578852852\n",
      "SGD iter. 62/99: loss=0.09312508546331555\n",
      "SGD iter. 63/99: loss=0.09303173814168261\n",
      "SGD iter. 64/99: loss=0.0845825727539877\n",
      "SGD iter. 65/99: loss=0.10920961253264051\n",
      "SGD iter. 66/99: loss=0.09983017200135721\n",
      "SGD iter. 67/99: loss=0.10388099224757054\n",
      "SGD iter. 68/99: loss=0.0880359815275711\n",
      "SGD iter. 69/99: loss=0.0953424765623094\n",
      "SGD iter. 70/99: loss=0.09365034190519542\n",
      "SGD iter. 71/99: loss=0.09578065351979724\n",
      "SGD iter. 72/99: loss=0.08982065765889784\n",
      "SGD iter. 73/99: loss=0.08203549912180798\n",
      "SGD iter. 74/99: loss=0.08141618393056457\n",
      "SGD iter. 75/99: loss=0.08446966256762233\n",
      "SGD iter. 76/99: loss=0.06433005484919384\n",
      "SGD iter. 77/99: loss=0.10291870138751019\n",
      "SGD iter. 78/99: loss=0.12135455695402518\n",
      "SGD iter. 79/99: loss=0.10335105773781013\n",
      "SGD iter. 80/99: loss=0.1357075718226993\n",
      "SGD iter. 81/99: loss=0.09823012810641822\n",
      "SGD iter. 82/99: loss=0.09397940547332757\n",
      "SGD iter. 83/99: loss=0.08457035130682634\n",
      "SGD iter. 84/99: loss=0.07708645262277188\n",
      "SGD iter. 85/99: loss=0.07826926592368003\n",
      "SGD iter. 86/99: loss=0.08574396152420061\n",
      "SGD iter. 87/99: loss=0.12361659408099658\n",
      "SGD iter. 88/99: loss=0.061298560934783725\n",
      "SGD iter. 89/99: loss=0.0578804622116323\n",
      "SGD iter. 90/99: loss=0.08304481248034339\n",
      "SGD iter. 91/99: loss=0.08877603404765705\n",
      "SGD iter. 92/99: loss=0.0798411061789677\n",
      "SGD iter. 93/99: loss=0.11040327322077713\n",
      "SGD iter. 94/99: loss=0.09603722528178835\n",
      "SGD iter. 95/99: loss=0.08622939177587559\n",
      "SGD iter. 96/99: loss=0.13387831279767679\n",
      "SGD iter. 97/99: loss=0.09390176503167921\n",
      "SGD iter. 98/99: loss=0.09519966085834655\n",
      "SGD iter. 99/99: loss=0.07785222151607668\n"
     ]
    }
   ],
   "source": [
    "# Define the parameters of the algorithm.\n",
    "max_iters = 100\n",
    "gamma = 0.04\n",
    "batch_size = 50\n",
    "# Initialization\n",
    "initial_w = generate_w(x_tr.shape)\n",
    "w, loss = mean_squared_error_sgd(y_tr, x_tr, initial_w, batch_size, max_iters, gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training accuracy is: 0.71585\n",
      "The validation accuracy is: 0.71382\n"
     ]
    }
   ],
   "source": [
    "print(\"The training accuracy is:\", get_accuracy(y_tr, x_tr, w))\n",
    "print(\"The validation accuracy is:\", get_accuracy(y_v, x_v, w))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# insert remaining test codes below"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ee6b41961f93c6f250bc55b15f7bfcab9769f15680d1f879ddd8dd4e686622cd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
