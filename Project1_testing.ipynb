{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "#%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from implementations import *\n",
    "from helpers import *\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing and split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio = 0.8  #ratio is the percentage of the data allocated for training \n",
    "seed = 1  #random seed for data shuffling\n",
    "x_tr, y_tr, x_te, id_te = preprocess_data() #preprocess intput data from the training and test sets\n",
    "x_tr, x_v, y_tr, y_v = split_data(x_tr, y_tr, ratio, seed) #split training data into training and validation setsb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GD iter. 0/799: loss=0.1668872322922502\n",
      "GD iter. 1/799: loss=0.15188350618145277\n",
      "GD iter. 2/799: loss=0.1409887958693643\n",
      "GD iter. 3/799: loss=0.1330757653331919\n",
      "GD iter. 4/799: loss=0.12732637382539863\n",
      "GD iter. 5/799: loss=0.12314701779005434\n",
      "GD iter. 6/799: loss=0.12010695439691883\n",
      "GD iter. 7/799: loss=0.11789361916126491\n",
      "GD iter. 8/799: loss=0.11628020259725604\n",
      "GD iter. 9/799: loss=0.1151021225230892\n",
      "GD iter. 10/799: loss=0.1142399514117192\n",
      "GD iter. 11/799: loss=0.11360702778436337\n",
      "GD iter. 12/799: loss=0.11314046653535499\n",
      "GD iter. 13/799: loss=0.11279463565938627\n",
      "GD iter. 14/799: loss=0.1125364227003216\n",
      "GD iter. 15/799: loss=0.11234179989454252\n",
      "GD iter. 16/799: loss=0.11219333169969907\n",
      "GD iter. 17/799: loss=0.11207836615651844\n",
      "GD iter. 18/799: loss=0.11198772246760552\n",
      "GD iter. 19/799: loss=0.11191473865141037\n",
      "GD iter. 20/799: loss=0.11185458048133591\n",
      "GD iter. 21/799: loss=0.11180374002393646\n",
      "GD iter. 22/799: loss=0.11175967175790354\n",
      "GD iter. 23/799: loss=0.11172052852724905\n",
      "GD iter. 24/799: loss=0.11168496993822925\n",
      "GD iter. 25/799: loss=0.1116520233243849\n",
      "GD iter. 26/799: loss=0.1116209828571369\n",
      "GD iter. 27/799: loss=0.1115913363363443\n",
      "GD iter. 28/799: loss=0.11156271206656465\n",
      "GD iter. 29/799: loss=0.11153484030831474\n",
      "GD iter. 30/799: loss=0.1115075253055423\n",
      "GD iter. 31/799: loss=0.11148062498762527\n",
      "GD iter. 32/799: loss=0.11145403624031934\n",
      "GD iter. 33/799: loss=0.11142768421776013\n",
      "GD iter. 34/799: loss=0.11140151458681885\n",
      "GD iter. 35/799: loss=0.11137548789929155\n",
      "GD iter. 36/799: loss=0.1113495755081321\n",
      "GD iter. 37/799: loss=0.11132375660410458\n",
      "GD iter. 38/799: loss=0.11129801606545818\n",
      "GD iter. 39/799: loss=0.11127234289756392\n",
      "GD iter. 40/799: loss=0.11124672910065193\n",
      "GD iter. 41/799: loss=0.11122116884819512\n",
      "GD iter. 42/799: loss=0.11119565789071129\n",
      "GD iter. 43/799: loss=0.11117019312313742\n",
      "GD iter. 44/799: loss=0.1111447722708992\n",
      "GD iter. 45/799: loss=0.11111939366210957\n",
      "GD iter. 46/799: loss=0.11109405606226708\n",
      "GD iter. 47/799: loss=0.11106875855430609\n",
      "GD iter. 48/799: loss=0.1110435004515562\n",
      "GD iter. 49/799: loss=0.11101828123458182\n",
      "GD iter. 50/799: loss=0.11099310050535056\n",
      "GD iter. 51/799: loss=0.11096795795397547\n",
      "GD iter. 52/799: loss=0.11094285333458201\n",
      "GD iter. 53/799: loss=0.11091778644779603\n",
      "GD iter. 54/799: loss=0.11089275712803581\n",
      "GD iter. 55/799: loss=0.11086776523429116\n",
      "GD iter. 56/799: loss=0.11084281064343166\n",
      "GD iter. 57/799: loss=0.11081789324535102\n",
      "GD iter. 58/799: loss=0.11079301293944345\n",
      "GD iter. 59/799: loss=0.11076816963204665\n",
      "GD iter. 60/799: loss=0.11074336323458614\n",
      "GD iter. 61/799: loss=0.11071859366222866\n",
      "GD iter. 62/799: loss=0.11069386083290497\n",
      "GD iter. 63/799: loss=0.11066916466660039\n",
      "GD iter. 64/799: loss=0.11064450508484015\n",
      "GD iter. 65/799: loss=0.1106198820103156\n",
      "GD iter. 66/799: loss=0.1105952953666129\n",
      "GD iter. 67/799: loss=0.11057074507801617\n",
      "GD iter. 68/799: loss=0.11054623106936426\n",
      "GD iter. 69/799: loss=0.11052175326594704\n",
      "GD iter. 70/799: loss=0.11049731159342957\n",
      "GD iter. 71/799: loss=0.11047290597779744\n",
      "GD iter. 72/799: loss=0.11044853634531655\n",
      "GD iter. 73/799: loss=0.11042420262250416\n",
      "GD iter. 74/799: loss=0.11039990473610753\n",
      "GD iter. 75/799: loss=0.11037564261308841\n",
      "GD iter. 76/799: loss=0.11035141618061152\n",
      "GD iter. 77/799: loss=0.1103272253660364\n",
      "GD iter. 78/799: loss=0.11030307009691095\n",
      "GD iter. 79/799: loss=0.11027895030096688\n",
      "GD iter. 80/799: loss=0.11025486590611637\n",
      "GD iter. 81/799: loss=0.1102308168404492\n",
      "GD iter. 82/799: loss=0.11020680303223089\n",
      "GD iter. 83/799: loss=0.11018282440990097\n",
      "GD iter. 84/799: loss=0.1101588809020719\n",
      "GD iter. 85/799: loss=0.11013497243752779\n",
      "GD iter. 86/799: loss=0.11011109894522375\n",
      "GD iter. 87/799: loss=0.11008726035428491\n",
      "GD iter. 88/799: loss=0.11006345659400596\n",
      "GD iter. 89/799: loss=0.11003968759385042\n",
      "GD iter. 90/799: loss=0.11001595328345028\n",
      "GD iter. 91/799: loss=0.1099922535926051\n",
      "GD iter. 92/799: loss=0.10996858845128203\n",
      "GD iter. 93/799: loss=0.10994495778961491\n",
      "GD iter. 94/799: loss=0.10992136153790406\n",
      "GD iter. 95/799: loss=0.10989779962661576\n",
      "GD iter. 96/799: loss=0.1098742719863818\n",
      "GD iter. 97/799: loss=0.10985077854799906\n",
      "GD iter. 98/799: loss=0.10982731924242904\n",
      "GD iter. 99/799: loss=0.10980389400079762\n",
      "GD iter. 100/799: loss=0.10978050275439433\n",
      "GD iter. 101/799: loss=0.10975714543467226\n",
      "GD iter. 102/799: loss=0.1097338219732474\n",
      "GD iter. 103/799: loss=0.10971053230189837\n",
      "GD iter. 104/799: loss=0.10968727635256587\n",
      "GD iter. 105/799: loss=0.10966405405735244\n",
      "GD iter. 106/799: loss=0.10964086534852195\n",
      "GD iter. 107/799: loss=0.10961771015849918\n",
      "GD iter. 108/799: loss=0.1095945884198694\n",
      "GD iter. 109/799: loss=0.10957150006537816\n",
      "GD iter. 110/799: loss=0.1095484450279306\n",
      "GD iter. 111/799: loss=0.10952542324059111\n",
      "GD iter. 112/799: loss=0.10950243463658318\n",
      "GD iter. 113/799: loss=0.10947947914928872\n",
      "GD iter. 114/799: loss=0.10945655671224767\n",
      "GD iter. 115/799: loss=0.10943366725915796\n",
      "GD iter. 116/799: loss=0.10941081072387439\n",
      "GD iter. 117/799: loss=0.10938798704040906\n",
      "GD iter. 118/799: loss=0.10936519614293053\n",
      "GD iter. 119/799: loss=0.10934243796576326\n",
      "GD iter. 120/799: loss=0.1093197124433877\n",
      "GD iter. 121/799: loss=0.10929701951043955\n",
      "GD iter. 122/799: loss=0.10927435910170939\n",
      "GD iter. 123/799: loss=0.1092517311521425\n",
      "GD iter. 124/799: loss=0.1092291355968381\n",
      "GD iter. 125/799: loss=0.10920657237104946\n",
      "GD iter. 126/799: loss=0.10918404141018305\n",
      "GD iter. 127/799: loss=0.10916154264979842\n",
      "GD iter. 128/799: loss=0.10913907602560775\n",
      "GD iter. 129/799: loss=0.10911664147347531\n",
      "GD iter. 130/799: loss=0.10909423892941743\n",
      "GD iter. 131/799: loss=0.10907186832960171\n",
      "GD iter. 132/799: loss=0.10904952961034703\n",
      "GD iter. 133/799: loss=0.10902722270812278\n",
      "GD iter. 134/799: loss=0.1090049475595488\n",
      "GD iter. 135/799: loss=0.10898270410139474\n",
      "GD iter. 136/799: loss=0.10896049227058004\n",
      "GD iter. 137/799: loss=0.10893831200417309\n",
      "GD iter. 138/799: loss=0.10891616323939117\n",
      "GD iter. 139/799: loss=0.10889404591360008\n",
      "GD iter. 140/799: loss=0.10887195996431352\n",
      "GD iter. 141/799: loss=0.1088499053291931\n",
      "GD iter. 142/799: loss=0.10882788194604749\n",
      "GD iter. 143/799: loss=0.10880588975283247\n",
      "GD iter. 144/799: loss=0.10878392868765041\n",
      "GD iter. 145/799: loss=0.10876199868874975\n",
      "GD iter. 146/799: loss=0.10874009969452485\n",
      "GD iter. 147/799: loss=0.10871823164351556\n",
      "GD iter. 148/799: loss=0.1086963944744068\n",
      "GD iter. 149/799: loss=0.10867458812602816\n",
      "GD iter. 150/799: loss=0.10865281253735373\n",
      "GD iter. 151/799: loss=0.10863106764750154\n",
      "GD iter. 152/799: loss=0.10860935339573323\n",
      "GD iter. 153/799: loss=0.10858766972145378\n",
      "GD iter. 154/799: loss=0.10856601656421111\n",
      "GD iter. 155/799: loss=0.1085443938636956\n",
      "GD iter. 156/799: loss=0.1085228015597399\n",
      "GD iter. 157/799: loss=0.10850123959231854\n",
      "GD iter. 158/799: loss=0.10847970790154739\n",
      "GD iter. 159/799: loss=0.1084582064276837\n",
      "GD iter. 160/799: loss=0.10843673511112521\n",
      "GD iter. 161/799: loss=0.10841529389241035\n",
      "GD iter. 162/799: loss=0.10839388271221737\n",
      "GD iter. 163/799: loss=0.10837250151136438\n",
      "GD iter. 164/799: loss=0.10835115023080885\n",
      "GD iter. 165/799: loss=0.10832982881164718\n",
      "GD iter. 166/799: loss=0.10830853719511449\n",
      "GD iter. 167/799: loss=0.10828727532258421\n",
      "GD iter. 168/799: loss=0.10826604313556779\n",
      "GD iter. 169/799: loss=0.10824484057571414\n",
      "GD iter. 170/799: loss=0.10822366758480957\n",
      "GD iter. 171/799: loss=0.10820252410477724\n",
      "GD iter. 172/799: loss=0.10818141007767697\n",
      "GD iter. 173/799: loss=0.10816032544570478\n",
      "GD iter. 174/799: loss=0.10813927015119248\n",
      "GD iter. 175/799: loss=0.10811824413660764\n",
      "GD iter. 176/799: loss=0.10809724734455287\n",
      "GD iter. 177/799: loss=0.10807627971776572\n",
      "GD iter. 178/799: loss=0.10805534119911823\n",
      "GD iter. 179/799: loss=0.10803443173161666\n",
      "GD iter. 180/799: loss=0.10801355125840109\n",
      "GD iter. 181/799: loss=0.10799269972274525\n",
      "GD iter. 182/799: loss=0.10797187706805587\n",
      "GD iter. 183/799: loss=0.10795108323787259\n",
      "GD iter. 184/799: loss=0.10793031817586761\n",
      "GD iter. 185/799: loss=0.10790958182584533\n",
      "GD iter. 186/799: loss=0.10788887413174181\n",
      "GD iter. 187/799: loss=0.10786819503762486\n",
      "GD iter. 188/799: loss=0.10784754448769338\n",
      "GD iter. 189/799: loss=0.10782692242627705\n",
      "GD iter. 190/799: loss=0.10780632879783619\n",
      "GD iter. 191/799: loss=0.10778576354696122\n",
      "GD iter. 192/799: loss=0.10776522661837257\n",
      "GD iter. 193/799: loss=0.10774471795692003\n",
      "GD iter. 194/799: loss=0.10772423750758275\n",
      "GD iter. 195/799: loss=0.10770378521546871\n",
      "GD iter. 196/799: loss=0.10768336102581448\n",
      "GD iter. 197/799: loss=0.10766296488398484\n",
      "GD iter. 198/799: loss=0.10764259673547262\n",
      "GD iter. 199/799: loss=0.10762225652589798\n",
      "GD iter. 200/799: loss=0.1076019442010087\n",
      "GD iter. 201/799: loss=0.10758165970667928\n",
      "GD iter. 202/799: loss=0.1075614029889109\n",
      "GD iter. 203/799: loss=0.1075411739938312\n",
      "GD iter. 204/799: loss=0.10752097266769366\n",
      "GD iter. 205/799: loss=0.10750079895687756\n",
      "GD iter. 206/799: loss=0.10748065280788743\n",
      "GD iter. 207/799: loss=0.10746053416735309\n",
      "GD iter. 208/799: loss=0.10744044298202886\n",
      "GD iter. 209/799: loss=0.10742037919879358\n",
      "GD iter. 210/799: loss=0.10740034276465023\n",
      "GD iter. 211/799: loss=0.10738033362672567\n",
      "GD iter. 212/799: loss=0.10736035173227011\n",
      "GD iter. 213/799: loss=0.10734039702865703\n",
      "GD iter. 214/799: loss=0.10732046946338278\n",
      "GD iter. 215/799: loss=0.10730056898406617\n",
      "GD iter. 216/799: loss=0.1072806955384485\n",
      "GD iter. 217/799: loss=0.10726084907439286\n",
      "GD iter. 218/799: loss=0.10724102953988404\n",
      "GD iter. 219/799: loss=0.1072212368830281\n",
      "GD iter. 220/799: loss=0.10720147105205224\n",
      "GD iter. 221/799: loss=0.10718173199530437\n",
      "GD iter. 222/799: loss=0.1071620196612527\n",
      "GD iter. 223/799: loss=0.10714233399848583\n",
      "GD iter. 224/799: loss=0.10712267495571194\n",
      "GD iter. 225/799: loss=0.10710304248175888\n",
      "GD iter. 226/799: loss=0.10708343652557369\n",
      "GD iter. 227/799: loss=0.10706385703622227\n",
      "GD iter. 228/799: loss=0.1070443039628893\n",
      "GD iter. 229/799: loss=0.10702477725487766\n",
      "GD iter. 230/799: loss=0.10700527686160831\n",
      "GD iter. 231/799: loss=0.1069858027326199\n",
      "GD iter. 232/799: loss=0.10696635481756867\n",
      "GD iter. 233/799: loss=0.10694693306622784\n",
      "GD iter. 234/799: loss=0.10692753742848758\n",
      "GD iter. 235/799: loss=0.10690816785435463\n",
      "GD iter. 236/799: loss=0.1068888242939519\n",
      "GD iter. 237/799: loss=0.10686950669751841\n",
      "GD iter. 238/799: loss=0.10685021501540881\n",
      "GD iter. 239/799: loss=0.10683094919809309\n",
      "GD iter. 240/799: loss=0.1068117091961565\n",
      "GD iter. 241/799: loss=0.10679249496029891\n",
      "GD iter. 242/799: loss=0.10677330644133488\n",
      "GD iter. 243/799: loss=0.10675414359019317\n",
      "GD iter. 244/799: loss=0.10673500635791643\n",
      "GD iter. 245/799: loss=0.10671589469566117\n",
      "GD iter. 246/799: loss=0.10669680855469704\n",
      "GD iter. 247/799: loss=0.10667774788640694\n",
      "GD iter. 248/799: loss=0.10665871264228662\n",
      "GD iter. 249/799: loss=0.10663970277394429\n",
      "GD iter. 250/799: loss=0.10662071823310043\n",
      "GD iter. 251/799: loss=0.10660175897158754\n",
      "GD iter. 252/799: loss=0.10658282494134977\n",
      "GD iter. 253/799: loss=0.10656391609444268\n",
      "GD iter. 254/799: loss=0.10654503238303298\n",
      "GD iter. 255/799: loss=0.10652617375939827\n",
      "GD iter. 256/799: loss=0.10650734017592667\n",
      "GD iter. 257/799: loss=0.10648853158511669\n",
      "GD iter. 258/799: loss=0.10646974793957675\n",
      "GD iter. 259/799: loss=0.1064509891920251\n",
      "GD iter. 260/799: loss=0.10643225529528946\n",
      "GD iter. 261/799: loss=0.10641354620230674\n",
      "GD iter. 262/799: loss=0.10639486186612283\n",
      "GD iter. 263/799: loss=0.10637620223989207\n",
      "GD iter. 264/799: loss=0.10635756727687755\n",
      "GD iter. 265/799: loss=0.10633895693045008\n",
      "GD iter. 266/799: loss=0.10632037115408861\n",
      "GD iter. 267/799: loss=0.10630180990137955\n",
      "GD iter. 268/799: loss=0.10628327312601649\n",
      "GD iter. 269/799: loss=0.10626476078180035\n",
      "GD iter. 270/799: loss=0.10624627282263852\n",
      "GD iter. 271/799: loss=0.1062278092025451\n",
      "GD iter. 272/799: loss=0.10620936987564024\n",
      "GD iter. 273/799: loss=0.10619095479615022\n",
      "GD iter. 274/799: loss=0.10617256391840696\n",
      "GD iter. 275/799: loss=0.10615419719684784\n",
      "GD iter. 276/799: loss=0.10613585458601531\n",
      "GD iter. 277/799: loss=0.10611753604055693\n",
      "GD iter. 278/799: loss=0.10609924151522468\n",
      "GD iter. 279/799: loss=0.10608097096487511\n",
      "GD iter. 280/799: loss=0.10606272434446881\n",
      "GD iter. 281/799: loss=0.1060445016090702\n",
      "GD iter. 282/799: loss=0.10602630271384748\n",
      "GD iter. 283/799: loss=0.106008127614072\n",
      "GD iter. 284/799: loss=0.10598997626511826\n",
      "GD iter. 285/799: loss=0.1059718486224637\n",
      "GD iter. 286/799: loss=0.10595374464168808\n",
      "GD iter. 287/799: loss=0.10593566427847381\n",
      "GD iter. 288/799: loss=0.10591760748860514\n",
      "GD iter. 289/799: loss=0.10589957422796817\n",
      "GD iter. 290/799: loss=0.10588156445255055\n",
      "GD iter. 291/799: loss=0.10586357811844127\n",
      "GD iter. 292/799: loss=0.10584561518183033\n",
      "GD iter. 293/799: loss=0.10582767559900855\n",
      "GD iter. 294/799: loss=0.10580975932636726\n",
      "GD iter. 295/799: loss=0.10579186632039808\n",
      "GD iter. 296/799: loss=0.10577399653769276\n",
      "GD iter. 297/799: loss=0.10575614993494267\n",
      "GD iter. 298/799: loss=0.10573832646893892\n",
      "GD iter. 299/799: loss=0.10572052609657177\n",
      "GD iter. 300/799: loss=0.10570274877483052\n",
      "GD iter. 301/799: loss=0.10568499446080341\n",
      "GD iter. 302/799: loss=0.10566726311167705\n",
      "GD iter. 303/799: loss=0.10564955468473648\n",
      "GD iter. 304/799: loss=0.10563186913736476\n",
      "GD iter. 305/799: loss=0.1056142064270428\n",
      "GD iter. 306/799: loss=0.10559656651134898\n",
      "GD iter. 307/799: loss=0.10557894934795911\n",
      "GD iter. 308/799: loss=0.10556135489464606\n",
      "GD iter. 309/799: loss=0.10554378310927952\n",
      "GD iter. 310/799: loss=0.10552623394982578\n",
      "GD iter. 311/799: loss=0.1055087073743475\n",
      "GD iter. 312/799: loss=0.1054912033410035\n",
      "GD iter. 313/799: loss=0.10547372180804836\n",
      "GD iter. 314/799: loss=0.10545626273383245\n",
      "GD iter. 315/799: loss=0.10543882607680144\n",
      "GD iter. 316/799: loss=0.10542141179549619\n",
      "GD iter. 317/799: loss=0.1054040198485525\n",
      "GD iter. 318/799: loss=0.10538665019470085\n",
      "GD iter. 319/799: loss=0.10536930279276614\n",
      "GD iter. 320/799: loss=0.1053519776016675\n",
      "GD iter. 321/799: loss=0.10533467458041819\n",
      "GD iter. 322/799: loss=0.105317393688125\n",
      "GD iter. 323/799: loss=0.10530013488398829\n",
      "GD iter. 324/799: loss=0.10528289812730186\n",
      "GD iter. 325/799: loss=0.10526568337745228\n",
      "GD iter. 326/799: loss=0.10524849059391922\n",
      "GD iter. 327/799: loss=0.10523131973627471\n",
      "GD iter. 328/799: loss=0.10521417076418335\n",
      "GD iter. 329/799: loss=0.10519704363740166\n",
      "GD iter. 330/799: loss=0.10517993831577817\n",
      "GD iter. 331/799: loss=0.10516285475925306\n",
      "GD iter. 332/799: loss=0.10514579292785795\n",
      "GD iter. 333/799: loss=0.10512875278171563\n",
      "GD iter. 334/799: loss=0.10511173428103991\n",
      "GD iter. 335/799: loss=0.10509473738613544\n",
      "GD iter. 336/799: loss=0.10507776205739722\n",
      "GD iter. 337/799: loss=0.10506080825531063\n",
      "GD iter. 338/799: loss=0.10504387594045127\n",
      "GD iter. 339/799: loss=0.10502696507348427\n",
      "GD iter. 340/799: loss=0.10501007561516484\n",
      "GD iter. 341/799: loss=0.10499320752633717\n",
      "GD iter. 342/799: loss=0.10497636076793491\n",
      "GD iter. 343/799: loss=0.10495953530098055\n",
      "GD iter. 344/799: loss=0.10494273108658539\n",
      "GD iter. 345/799: loss=0.1049259480859492\n",
      "GD iter. 346/799: loss=0.10490918626036005\n",
      "GD iter. 347/799: loss=0.10489244557119422\n",
      "GD iter. 348/799: loss=0.1048757259799157\n",
      "GD iter. 349/799: loss=0.10485902744807613\n",
      "GD iter. 350/799: loss=0.10484234993731462\n",
      "GD iter. 351/799: loss=0.1048256934093575\n",
      "GD iter. 352/799: loss=0.10480905782601814\n",
      "GD iter. 353/799: loss=0.10479244314919656\n",
      "GD iter. 354/799: loss=0.10477584934087947\n",
      "GD iter. 355/799: loss=0.10475927636313982\n",
      "GD iter. 356/799: loss=0.10474272417813672\n",
      "GD iter. 357/799: loss=0.10472619274811529\n",
      "GD iter. 358/799: loss=0.10470968203540615\n",
      "GD iter. 359/799: loss=0.1046931920024256\n",
      "GD iter. 360/799: loss=0.10467672261167514\n",
      "GD iter. 361/799: loss=0.10466027382574132\n",
      "GD iter. 362/799: loss=0.10464384560729559\n",
      "GD iter. 363/799: loss=0.10462743791909399\n",
      "GD iter. 364/799: loss=0.10461105072397708\n",
      "GD iter. 365/799: loss=0.10459468398486944\n",
      "GD iter. 366/799: loss=0.10457833766477992\n",
      "GD iter. 367/799: loss=0.10456201172680109\n",
      "GD iter. 368/799: loss=0.10454570613410893\n",
      "GD iter. 369/799: loss=0.10452942084996304\n",
      "GD iter. 370/799: loss=0.10451315583770622\n",
      "GD iter. 371/799: loss=0.10449691106076396\n",
      "GD iter. 372/799: loss=0.1044806864826448\n",
      "GD iter. 373/799: loss=0.10446448206693974\n",
      "GD iter. 374/799: loss=0.10444829777732215\n",
      "GD iter. 375/799: loss=0.10443213357754756\n",
      "GD iter. 376/799: loss=0.10441598943145336\n",
      "GD iter. 377/799: loss=0.10439986530295885\n",
      "GD iter. 378/799: loss=0.10438376115606474\n",
      "GD iter. 379/799: loss=0.1043676769548531\n",
      "GD iter. 380/799: loss=0.10435161266348723\n",
      "GD iter. 381/799: loss=0.10433556824621129\n",
      "GD iter. 382/799: loss=0.10431954366735009\n",
      "GD iter. 383/799: loss=0.1043035388913092\n",
      "GD iter. 384/799: loss=0.10428755388257428\n",
      "GD iter. 385/799: loss=0.10427158860571131\n",
      "GD iter. 386/799: loss=0.10425564302536615\n",
      "GD iter. 387/799: loss=0.10423971710626438\n",
      "GD iter. 388/799: loss=0.10422381081321112\n",
      "GD iter. 389/799: loss=0.10420792411109091\n",
      "GD iter. 390/799: loss=0.10419205696486726\n",
      "GD iter. 391/799: loss=0.10417620933958285\n",
      "GD iter. 392/799: loss=0.10416038120035895\n",
      "GD iter. 393/799: loss=0.10414457251239548\n",
      "GD iter. 394/799: loss=0.10412878324097072\n",
      "GD iter. 395/799: loss=0.10411301335144107\n",
      "GD iter. 396/799: loss=0.10409726280924099\n",
      "GD iter. 397/799: loss=0.10408153157988258\n",
      "GD iter. 398/799: loss=0.10406581962895566\n",
      "GD iter. 399/799: loss=0.10405012692212748\n",
      "GD iter. 400/799: loss=0.10403445342514236\n",
      "GD iter. 401/799: loss=0.10401879910382171\n",
      "GD iter. 402/799: loss=0.1040031639240638\n",
      "GD iter. 403/799: loss=0.10398754785184343\n",
      "GD iter. 404/799: loss=0.10397195085321201\n",
      "GD iter. 405/799: loss=0.103956372894297\n",
      "GD iter. 406/799: loss=0.10394081394130213\n",
      "GD iter. 407/799: loss=0.10392527396050685\n",
      "GD iter. 408/799: loss=0.10390975291826644\n",
      "GD iter. 409/799: loss=0.1038942507810115\n",
      "GD iter. 410/799: loss=0.10387876751524808\n",
      "GD iter. 411/799: loss=0.10386330308755744\n",
      "GD iter. 412/799: loss=0.10384785746459554\n",
      "GD iter. 413/799: loss=0.10383243061309327\n",
      "GD iter. 414/799: loss=0.10381702249985612\n",
      "GD iter. 415/799: loss=0.10380163309176384\n",
      "GD iter. 416/799: loss=0.10378626235577049\n",
      "GD iter. 417/799: loss=0.10377091025890406\n",
      "GD iter. 418/799: loss=0.10375557676826651\n",
      "GD iter. 419/799: loss=0.10374026185103329\n",
      "GD iter. 420/799: loss=0.10372496547445345\n",
      "GD iter. 421/799: loss=0.10370968760584928\n",
      "GD iter. 422/799: loss=0.10369442821261622\n",
      "GD iter. 423/799: loss=0.10367918726222256\n",
      "GD iter. 424/799: loss=0.1036639647222094\n",
      "GD iter. 425/799: loss=0.10364876056019039\n",
      "GD iter. 426/799: loss=0.10363357474385163\n",
      "GD iter. 427/799: loss=0.10361840724095127\n",
      "GD iter. 428/799: loss=0.10360325801931967\n",
      "GD iter. 429/799: loss=0.10358812704685895\n",
      "GD iter. 430/799: loss=0.10357301429154293\n",
      "GD iter. 431/799: loss=0.10355791972141692\n",
      "GD iter. 432/799: loss=0.10354284330459754\n",
      "GD iter. 433/799: loss=0.10352778500927261\n",
      "GD iter. 434/799: loss=0.10351274480370086\n",
      "GD iter. 435/799: loss=0.10349772265621181\n",
      "GD iter. 436/799: loss=0.10348271853520567\n",
      "GD iter. 437/799: loss=0.10346773240915305\n",
      "GD iter. 438/799: loss=0.10345276424659477\n",
      "GD iter. 439/799: loss=0.10343781401614191\n",
      "GD iter. 440/799: loss=0.10342288168647534\n",
      "GD iter. 441/799: loss=0.10340796722634568\n",
      "GD iter. 442/799: loss=0.10339307060457319\n",
      "GD iter. 443/799: loss=0.10337819179004751\n",
      "GD iter. 444/799: loss=0.10336333075172757\n",
      "GD iter. 445/799: loss=0.10334848745864127\n",
      "GD iter. 446/799: loss=0.10333366187988553\n",
      "GD iter. 447/799: loss=0.10331885398462577\n",
      "GD iter. 448/799: loss=0.10330406374209626\n",
      "GD iter. 449/799: loss=0.1032892911215994\n",
      "GD iter. 450/799: loss=0.10327453609250602\n",
      "GD iter. 451/799: loss=0.10325979862425486\n",
      "GD iter. 452/799: loss=0.10324507868635258\n",
      "GD iter. 453/799: loss=0.10323037624837353\n",
      "GD iter. 454/799: loss=0.10321569127995962\n",
      "GD iter. 455/799: loss=0.10320102375082026\n",
      "GD iter. 456/799: loss=0.10318637363073183\n",
      "GD iter. 457/799: loss=0.10317174088953796\n",
      "GD iter. 458/799: loss=0.10315712549714913\n",
      "GD iter. 459/799: loss=0.10314252742354245\n",
      "GD iter. 460/799: loss=0.10312794663876168\n",
      "GD iter. 461/799: loss=0.10311338311291689\n",
      "GD iter. 462/799: loss=0.10309883681618448\n",
      "GD iter. 463/799: loss=0.10308430771880674\n",
      "GD iter. 464/799: loss=0.10306979579109207\n",
      "GD iter. 465/799: loss=0.10305530100341448\n",
      "GD iter. 466/799: loss=0.10304082332621357\n",
      "GD iter. 467/799: loss=0.10302636272999438\n",
      "GD iter. 468/799: loss=0.1030119191853272\n",
      "GD iter. 469/799: loss=0.10299749266284741\n",
      "GD iter. 470/799: loss=0.10298308313325523\n",
      "GD iter. 471/799: loss=0.10296869056731586\n",
      "GD iter. 472/799: loss=0.1029543149358589\n",
      "GD iter. 473/799: loss=0.1029399562097785\n",
      "GD iter. 474/799: loss=0.1029256143600332\n",
      "GD iter. 475/799: loss=0.10291128935764542\n",
      "GD iter. 476/799: loss=0.10289698117370183\n",
      "GD iter. 477/799: loss=0.10288268977935273\n",
      "GD iter. 478/799: loss=0.10286841514581217\n",
      "GD iter. 479/799: loss=0.10285415724435777\n",
      "GD iter. 480/799: loss=0.10283991604633039\n",
      "GD iter. 481/799: loss=0.10282569152313409\n",
      "GD iter. 482/799: loss=0.102811483646236\n",
      "GD iter. 483/799: loss=0.10279729238716614\n",
      "GD iter. 484/799: loss=0.10278311771751729\n",
      "GD iter. 485/799: loss=0.1027689596089448\n",
      "GD iter. 486/799: loss=0.1027548180331663\n",
      "GD iter. 487/799: loss=0.10274069296196192\n",
      "GD iter. 488/799: loss=0.10272658436717375\n",
      "GD iter. 489/799: loss=0.10271249222070583\n",
      "GD iter. 490/799: loss=0.10269841649452413\n",
      "GD iter. 491/799: loss=0.10268435716065619\n",
      "GD iter. 492/799: loss=0.10267031419119105\n",
      "GD iter. 493/799: loss=0.10265628755827916\n",
      "GD iter. 494/799: loss=0.10264227723413215\n",
      "GD iter. 495/799: loss=0.1026282831910227\n",
      "GD iter. 496/799: loss=0.10261430540128431\n",
      "GD iter. 497/799: loss=0.10260034383731145\n",
      "GD iter. 498/799: loss=0.10258639847155901\n",
      "GD iter. 499/799: loss=0.10257246927654239\n",
      "GD iter. 500/799: loss=0.10255855622483728\n",
      "GD iter. 501/799: loss=0.10254465928907959\n",
      "GD iter. 502/799: loss=0.10253077844196518\n",
      "GD iter. 503/799: loss=0.10251691365624982\n",
      "GD iter. 504/799: loss=0.10250306490474893\n",
      "GD iter. 505/799: loss=0.10248923216033759\n",
      "GD iter. 506/799: loss=0.10247541539595026\n",
      "GD iter. 507/799: loss=0.10246161458458067\n",
      "GD iter. 508/799: loss=0.10244782969928166\n",
      "GD iter. 509/799: loss=0.10243406071316515\n",
      "GD iter. 510/799: loss=0.10242030759940184\n",
      "GD iter. 511/799: loss=0.10240657033122115\n",
      "GD iter. 512/799: loss=0.102392848881911\n",
      "GD iter. 513/799: loss=0.10237914322481778\n",
      "GD iter. 514/799: loss=0.10236545333334617\n",
      "GD iter. 515/799: loss=0.10235177918095886\n",
      "GD iter. 516/799: loss=0.10233812074117672\n",
      "GD iter. 517/799: loss=0.10232447798757825\n",
      "GD iter. 518/799: loss=0.10231085089379977\n",
      "GD iter. 519/799: loss=0.10229723943353516\n",
      "GD iter. 520/799: loss=0.10228364358053568\n",
      "GD iter. 521/799: loss=0.10227006330860988\n",
      "GD iter. 522/799: loss=0.10225649859162336\n",
      "GD iter. 523/799: loss=0.10224294940349891\n",
      "GD iter. 524/799: loss=0.10222941571821605\n",
      "GD iter. 525/799: loss=0.10221589750981099\n",
      "GD iter. 526/799: loss=0.10220239475237652\n",
      "GD iter. 527/799: loss=0.10218890742006195\n",
      "GD iter. 528/799: loss=0.1021754354870729\n",
      "GD iter. 529/799: loss=0.10216197892767102\n",
      "GD iter. 530/799: loss=0.10214853771617416\n",
      "GD iter. 531/799: loss=0.1021351118269559\n",
      "GD iter. 532/799: loss=0.1021217012344456\n",
      "GD iter. 533/799: loss=0.10210830591312835\n",
      "GD iter. 534/799: loss=0.10209492583754459\n",
      "GD iter. 535/799: loss=0.10208156098229015\n",
      "GD iter. 536/799: loss=0.10206821132201616\n",
      "GD iter. 537/799: loss=0.10205487683142865\n",
      "GD iter. 538/799: loss=0.10204155748528874\n",
      "GD iter. 539/799: loss=0.10202825325841221\n",
      "GD iter. 540/799: loss=0.10201496412566961\n",
      "GD iter. 541/799: loss=0.10200169006198599\n",
      "GD iter. 542/799: loss=0.10198843104234089\n",
      "GD iter. 543/799: loss=0.101975187041768\n",
      "GD iter. 544/799: loss=0.10196195803535517\n",
      "GD iter. 545/799: loss=0.10194874399824429\n",
      "GD iter. 546/799: loss=0.10193554490563113\n",
      "GD iter. 547/799: loss=0.1019223607327651\n",
      "GD iter. 548/799: loss=0.10190919145494945\n",
      "GD iter. 549/799: loss=0.10189603704754063\n",
      "GD iter. 550/799: loss=0.10188289748594856\n",
      "GD iter. 551/799: loss=0.10186977274563648\n",
      "GD iter. 552/799: loss=0.10185666280212052\n",
      "GD iter. 553/799: loss=0.10184356763096994\n",
      "GD iter. 554/799: loss=0.10183048720780669\n",
      "GD iter. 555/799: loss=0.10181742150830553\n",
      "GD iter. 556/799: loss=0.10180437050819371\n",
      "GD iter. 557/799: loss=0.10179133418325098\n",
      "GD iter. 558/799: loss=0.1017783125093094\n",
      "GD iter. 559/799: loss=0.10176530546225314\n",
      "GD iter. 560/799: loss=0.10175231301801853\n",
      "GD iter. 561/799: loss=0.1017393351525938\n",
      "GD iter. 562/799: loss=0.10172637184201892\n",
      "GD iter. 563/799: loss=0.10171342306238561\n",
      "GD iter. 564/799: loss=0.10170048878983716\n",
      "GD iter. 565/799: loss=0.10168756900056822\n",
      "GD iter. 566/799: loss=0.10167466367082474\n",
      "GD iter. 567/799: loss=0.10166177277690397\n",
      "GD iter. 568/799: loss=0.10164889629515403\n",
      "GD iter. 569/799: loss=0.10163603420197413\n",
      "GD iter. 570/799: loss=0.10162318647381413\n",
      "GD iter. 571/799: loss=0.10161035308717475\n",
      "GD iter. 572/799: loss=0.10159753401860708\n",
      "GD iter. 573/799: loss=0.10158472924471275\n",
      "GD iter. 574/799: loss=0.10157193874214371\n",
      "GD iter. 575/799: loss=0.10155916248760202\n",
      "GD iter. 576/799: loss=0.10154640045783984\n",
      "GD iter. 577/799: loss=0.10153365262965937\n",
      "GD iter. 578/799: loss=0.10152091897991239\n",
      "GD iter. 579/799: loss=0.10150819948550072\n",
      "GD iter. 580/799: loss=0.1014954941233754\n",
      "GD iter. 581/799: loss=0.10148280287053714\n",
      "GD iter. 582/799: loss=0.101470125704036\n",
      "GD iter. 583/799: loss=0.10145746260097116\n",
      "GD iter. 584/799: loss=0.10144481353849091\n",
      "GD iter. 585/799: loss=0.1014321784937926\n",
      "GD iter. 586/799: loss=0.10141955744412234\n",
      "GD iter. 587/799: loss=0.10140695036677505\n",
      "GD iter. 588/799: loss=0.10139435723909422\n",
      "GD iter. 589/799: loss=0.10138177803847191\n",
      "GD iter. 590/799: loss=0.10136921274234845\n",
      "GD iter. 591/799: loss=0.10135666132821256\n",
      "GD iter. 592/799: loss=0.10134412377360105\n",
      "GD iter. 593/799: loss=0.10133160005609876\n",
      "GD iter. 594/799: loss=0.10131909015333848\n",
      "GD iter. 595/799: loss=0.10130659404300071\n",
      "GD iter. 596/799: loss=0.10129411170281376\n",
      "GD iter. 597/799: loss=0.10128164311055342\n",
      "GD iter. 598/799: loss=0.10126918824404298\n",
      "GD iter. 599/799: loss=0.10125674708115295\n",
      "GD iter. 600/799: loss=0.1012443195998013\n",
      "GD iter. 601/799: loss=0.10123190577795284\n",
      "GD iter. 602/799: loss=0.10121950559361954\n",
      "GD iter. 603/799: loss=0.10120711902486021\n",
      "GD iter. 604/799: loss=0.10119474604978033\n",
      "GD iter. 605/799: loss=0.10118238664653223\n",
      "GD iter. 606/799: loss=0.10117004079331458\n",
      "GD iter. 607/799: loss=0.10115770846837253\n",
      "GD iter. 608/799: loss=0.10114538964999763\n",
      "GD iter. 609/799: loss=0.10113308431652752\n",
      "GD iter. 610/799: loss=0.101120792446346\n",
      "GD iter. 611/799: loss=0.10110851401788278\n",
      "GD iter. 612/799: loss=0.10109624900961348\n",
      "GD iter. 613/799: loss=0.10108399740005947\n",
      "GD iter. 614/799: loss=0.10107175916778771\n",
      "GD iter. 615/799: loss=0.10105953429141078\n",
      "GD iter. 616/799: loss=0.10104732274958658\n",
      "GD iter. 617/799: loss=0.10103512452101837\n",
      "GD iter. 618/799: loss=0.10102293958445469\n",
      "GD iter. 619/799: loss=0.10101076791868896\n",
      "GD iter. 620/799: loss=0.10099860950255979\n",
      "GD iter. 621/799: loss=0.10098646431495058\n",
      "GD iter. 622/799: loss=0.10097433233478942\n",
      "GD iter. 623/799: loss=0.10096221354104924\n",
      "GD iter. 624/799: loss=0.10095010791274729\n",
      "GD iter. 625/799: loss=0.10093801542894547\n",
      "GD iter. 626/799: loss=0.10092593606874982\n",
      "GD iter. 627/799: loss=0.10091386981131076\n",
      "GD iter. 628/799: loss=0.1009018166358227\n",
      "GD iter. 629/799: loss=0.10088977652152419\n",
      "GD iter. 630/799: loss=0.10087774944769755\n",
      "GD iter. 631/799: loss=0.10086573539366903\n",
      "GD iter. 632/799: loss=0.10085373433880838\n",
      "GD iter. 633/799: loss=0.10084174626252916\n",
      "GD iter. 634/799: loss=0.10082977114428827\n",
      "GD iter. 635/799: loss=0.10081780896358603\n",
      "GD iter. 636/799: loss=0.10080585969996599\n",
      "GD iter. 637/799: loss=0.10079392333301483\n",
      "GD iter. 638/799: loss=0.1007819998423625\n",
      "GD iter. 639/799: loss=0.10077008920768162\n",
      "GD iter. 640/799: loss=0.10075819140868782\n",
      "GD iter. 641/799: loss=0.1007463064251395\n",
      "GD iter. 642/799: loss=0.10073443423683763\n",
      "GD iter. 643/799: loss=0.10072257482362573\n",
      "GD iter. 644/799: loss=0.10071072816538981\n",
      "GD iter. 645/799: loss=0.10069889424205813\n",
      "GD iter. 646/799: loss=0.10068707303360132\n",
      "GD iter. 647/799: loss=0.10067526452003199\n",
      "GD iter. 648/799: loss=0.10066346868140484\n",
      "GD iter. 649/799: loss=0.1006516854978166\n",
      "GD iter. 650/799: loss=0.10063991494940558\n",
      "GD iter. 651/799: loss=0.10062815701635217\n",
      "GD iter. 652/799: loss=0.10061641167887796\n",
      "GD iter. 653/799: loss=0.10060467891724643\n",
      "GD iter. 654/799: loss=0.10059295871176235\n",
      "GD iter. 655/799: loss=0.10058125104277174\n",
      "GD iter. 656/799: loss=0.10056955589066197\n",
      "GD iter. 657/799: loss=0.10055787323586139\n",
      "GD iter. 658/799: loss=0.1005462030588396\n",
      "GD iter. 659/799: loss=0.10053454534010685\n",
      "GD iter. 660/799: loss=0.10052290006021443\n",
      "GD iter. 661/799: loss=0.10051126719975431\n",
      "GD iter. 662/799: loss=0.10049964673935895\n",
      "GD iter. 663/799: loss=0.10048803865970163\n",
      "GD iter. 664/799: loss=0.10047644294149576\n",
      "GD iter. 665/799: loss=0.10046485956549533\n",
      "GD iter. 666/799: loss=0.1004532885124944\n",
      "GD iter. 667/799: loss=0.10044172976332721\n",
      "GD iter. 668/799: loss=0.10043018329886817\n",
      "GD iter. 669/799: loss=0.10041864910003151\n",
      "GD iter. 670/799: loss=0.10040712714777132\n",
      "GD iter. 671/799: loss=0.10039561742308145\n",
      "GD iter. 672/799: loss=0.10038411990699557\n",
      "GD iter. 673/799: loss=0.10037263458058665\n",
      "GD iter. 674/799: loss=0.1003611614249674\n",
      "GD iter. 675/799: loss=0.10034970042128966\n",
      "GD iter. 676/799: loss=0.10033825155074473\n",
      "GD iter. 677/799: loss=0.10032681479456303\n",
      "GD iter. 678/799: loss=0.10031539013401405\n",
      "GD iter. 679/799: loss=0.10030397755040635\n",
      "GD iter. 680/799: loss=0.10029257702508734\n",
      "GD iter. 681/799: loss=0.10028118853944325\n",
      "GD iter. 682/799: loss=0.10026981207489902\n",
      "GD iter. 683/799: loss=0.1002584476129182\n",
      "GD iter. 684/799: loss=0.10024709513500299\n",
      "GD iter. 685/799: loss=0.10023575462269385\n",
      "GD iter. 686/799: loss=0.10022442605756969\n",
      "GD iter. 687/799: loss=0.10021310942124774\n",
      "GD iter. 688/799: loss=0.10020180469538316\n",
      "GD iter. 689/799: loss=0.10019051186166951\n",
      "GD iter. 690/799: loss=0.1001792309018379\n",
      "GD iter. 691/799: loss=0.10016796179765788\n",
      "GD iter. 692/799: loss=0.10015670453093631\n",
      "GD iter. 693/799: loss=0.10014545908351796\n",
      "GD iter. 694/799: loss=0.1001342254372852\n",
      "GD iter. 695/799: loss=0.10012300357415796\n",
      "GD iter. 696/799: loss=0.10011179347609359\n",
      "GD iter. 697/799: loss=0.10010059512508665\n",
      "GD iter. 698/799: loss=0.10008940850316916\n",
      "GD iter. 699/799: loss=0.10007823359241023\n",
      "GD iter. 700/799: loss=0.10006707037491598\n",
      "GD iter. 701/799: loss=0.10005591883282956\n",
      "GD iter. 702/799: loss=0.10004477894833108\n",
      "GD iter. 703/799: loss=0.10003365070363736\n",
      "GD iter. 704/799: loss=0.10002253408100206\n",
      "GD iter. 705/799: loss=0.10001142906271529\n",
      "GD iter. 706/799: loss=0.10000033563110391\n",
      "GD iter. 707/799: loss=0.09998925376853114\n",
      "GD iter. 708/799: loss=0.09997818345739654\n",
      "GD iter. 709/799: loss=0.09996712468013612\n",
      "GD iter. 710/799: loss=0.09995607741922176\n",
      "GD iter. 711/799: loss=0.09994504165716178\n",
      "GD iter. 712/799: loss=0.09993401737650046\n",
      "GD iter. 713/799: loss=0.0999230045598178\n",
      "GD iter. 714/799: loss=0.09991200318972991\n",
      "GD iter. 715/799: loss=0.09990101324888849\n",
      "GD iter. 716/799: loss=0.09989003471998106\n",
      "GD iter. 717/799: loss=0.09987906758573065\n",
      "GD iter. 718/799: loss=0.09986811182889574\n",
      "GD iter. 719/799: loss=0.09985716743227044\n",
      "GD iter. 720/799: loss=0.09984623437868395\n",
      "GD iter. 721/799: loss=0.09983531265100087\n",
      "GD iter. 722/799: loss=0.09982440223212101\n",
      "GD iter. 723/799: loss=0.09981350310497912\n",
      "GD iter. 724/799: loss=0.09980261525254511\n",
      "GD iter. 725/799: loss=0.09979173865782365\n",
      "GD iter. 726/799: loss=0.09978087330385434\n",
      "GD iter. 727/799: loss=0.09977001917371153\n",
      "GD iter. 728/799: loss=0.09975917625050428\n",
      "GD iter. 729/799: loss=0.09974834451737608\n",
      "GD iter. 730/799: loss=0.09973752395750511\n",
      "GD iter. 731/799: loss=0.09972671455410381\n",
      "GD iter. 732/799: loss=0.0997159162904191\n",
      "GD iter. 733/799: loss=0.09970512914973205\n",
      "GD iter. 734/799: loss=0.09969435311535799\n",
      "GD iter. 735/799: loss=0.09968358817064624\n",
      "GD iter. 736/799: loss=0.09967283429898022\n",
      "GD iter. 737/799: loss=0.09966209148377722\n",
      "GD iter. 738/799: loss=0.09965135970848843\n",
      "GD iter. 739/799: loss=0.09964063895659878\n",
      "GD iter. 740/799: loss=0.09962992921162689\n",
      "GD iter. 741/799: loss=0.099619230457125\n",
      "GD iter. 742/799: loss=0.09960854267667886\n",
      "GD iter. 743/799: loss=0.0995978658539077\n",
      "GD iter. 744/799: loss=0.09958719997246403\n",
      "GD iter. 745/799: loss=0.09957654501603377\n",
      "GD iter. 746/799: loss=0.09956590096833595\n",
      "GD iter. 747/799: loss=0.0995552678131228\n",
      "GD iter. 748/799: loss=0.09954464553417952\n",
      "GD iter. 749/799: loss=0.0995340341153244\n",
      "GD iter. 750/799: loss=0.09952343354040846\n",
      "GD iter. 751/799: loss=0.09951284379331568\n",
      "GD iter. 752/799: loss=0.09950226485796272\n",
      "GD iter. 753/799: loss=0.09949169671829894\n",
      "GD iter. 754/799: loss=0.09948113935830616\n",
      "GD iter. 755/799: loss=0.0994705927619988\n",
      "GD iter. 756/799: loss=0.0994600569134237\n",
      "GD iter. 757/799: loss=0.09944953179666005\n",
      "GD iter. 758/799: loss=0.0994390173958193\n",
      "GD iter. 759/799: loss=0.09942851369504506\n",
      "GD iter. 760/799: loss=0.09941802067851313\n",
      "GD iter. 761/799: loss=0.09940753833043127\n",
      "GD iter. 762/799: loss=0.09939706663503928\n",
      "GD iter. 763/799: loss=0.09938660557660878\n",
      "GD iter. 764/799: loss=0.09937615513944327\n",
      "GD iter. 765/799: loss=0.09936571530787791\n",
      "GD iter. 766/799: loss=0.09935528606627962\n",
      "GD iter. 767/799: loss=0.09934486739904681\n",
      "GD iter. 768/799: loss=0.09933445929060947\n",
      "GD iter. 769/799: loss=0.09932406172542894\n",
      "GD iter. 770/799: loss=0.09931367468799808\n",
      "GD iter. 771/799: loss=0.09930329816284088\n",
      "GD iter. 772/799: loss=0.09929293213451262\n",
      "GD iter. 773/799: loss=0.0992825765875997\n",
      "GD iter. 774/799: loss=0.0992722315067196\n",
      "GD iter. 775/799: loss=0.09926189687652075\n",
      "GD iter. 776/799: loss=0.09925157268168254\n",
      "GD iter. 777/799: loss=0.09924125890691515\n",
      "GD iter. 778/799: loss=0.09923095553695964\n",
      "GD iter. 779/799: loss=0.09922066255658767\n",
      "GD iter. 780/799: loss=0.09921037995060154\n",
      "GD iter. 781/799: loss=0.09920010770383413\n",
      "GD iter. 782/799: loss=0.09918984580114877\n",
      "GD iter. 783/799: loss=0.09917959422743919\n",
      "GD iter. 784/799: loss=0.09916935296762955\n",
      "GD iter. 785/799: loss=0.09915912200667415\n",
      "GD iter. 786/799: loss=0.09914890132955757\n",
      "GD iter. 787/799: loss=0.09913869092129443\n",
      "GD iter. 788/799: loss=0.09912849076692946\n",
      "GD iter. 789/799: loss=0.09911830085153733\n",
      "GD iter. 790/799: loss=0.0991081211602227\n",
      "GD iter. 791/799: loss=0.09909795167811997\n",
      "GD iter. 792/799: loss=0.09908779239039328\n",
      "GD iter. 793/799: loss=0.09907764328223659\n",
      "GD iter. 794/799: loss=0.09906750433887339\n",
      "GD iter. 795/799: loss=0.09905737554555676\n",
      "GD iter. 796/799: loss=0.09904725688756925\n",
      "GD iter. 797/799: loss=0.09903714835022283\n",
      "GD iter. 798/799: loss=0.09902704991885883\n",
      "GD iter. 799/799: loss=0.09901696157884776\n",
      "The training accuracy is: 0.685775\n",
      "The validation accuracy is: 0.68388\n"
     ]
    }
   ],
   "source": [
    "# Define the parameters of the algorithm.\n",
    "max_iters = 800\n",
    "gamma = 0.013\n",
    "# Initialization\n",
    "initial_w = generate_w(x_tr.shape)\n",
    "w, loss = mean_squared_error_gd(y_tr, x_tr, initial_w, max_iters, gamma)\n",
    "pred = predict_mse(x_tr, w)\n",
    "print(\"The training accuracy is:\", get_accuracy(y_tr, pred))\n",
    "pred = predict_mse(x_v, w)\n",
    "print(\"The validation accuracy is:\", get_accuracy(y_v, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD iter. 0/3599: loss=0.1330589680938983\n",
      "SGD iter. 1/3599: loss=0.11424740088504098\n",
      "SGD iter. 2/3599: loss=0.1063972097067579\n",
      "SGD iter. 3/3599: loss=0.11031145768290833\n",
      "SGD iter. 4/3599: loss=0.12312341948779097\n",
      "SGD iter. 5/3599: loss=0.11196519491603513\n",
      "SGD iter. 6/3599: loss=0.10771268170277179\n",
      "SGD iter. 7/3599: loss=0.11484499275588089\n",
      "SGD iter. 8/3599: loss=0.11407352166336848\n",
      "SGD iter. 9/3599: loss=0.11583061875438223\n",
      "SGD iter. 10/3599: loss=0.10849487585418209\n",
      "SGD iter. 11/3599: loss=0.11918215267458647\n",
      "SGD iter. 12/3599: loss=0.12161104518506752\n",
      "SGD iter. 13/3599: loss=0.11314252945711137\n",
      "SGD iter. 14/3599: loss=0.10810485166363903\n",
      "SGD iter. 15/3599: loss=0.11555451538116514\n",
      "SGD iter. 16/3599: loss=0.1208778114316703\n",
      "SGD iter. 17/3599: loss=0.1096344583364117\n",
      "SGD iter. 18/3599: loss=0.1188160120243833\n",
      "SGD iter. 19/3599: loss=0.11499504732876496\n",
      "SGD iter. 20/3599: loss=0.11061305359881382\n",
      "SGD iter. 21/3599: loss=0.11588664406988303\n",
      "SGD iter. 22/3599: loss=0.11092539034278898\n",
      "SGD iter. 23/3599: loss=0.1154653854919874\n",
      "SGD iter. 24/3599: loss=0.11706739287010158\n",
      "SGD iter. 25/3599: loss=0.11803788055139389\n",
      "SGD iter. 26/3599: loss=0.11149465158805874\n",
      "SGD iter. 27/3599: loss=0.11640849965850276\n",
      "SGD iter. 28/3599: loss=0.11005295702523\n",
      "SGD iter. 29/3599: loss=0.10619971718199189\n",
      "SGD iter. 30/3599: loss=0.11420076538304709\n",
      "SGD iter. 31/3599: loss=0.10379327700878252\n",
      "SGD iter. 32/3599: loss=0.11720391047314375\n",
      "SGD iter. 33/3599: loss=0.11383675186678141\n",
      "SGD iter. 34/3599: loss=0.10677745881873169\n",
      "SGD iter. 35/3599: loss=0.11119947156506807\n",
      "SGD iter. 36/3599: loss=0.10673332591967494\n",
      "SGD iter. 37/3599: loss=0.10947146944665874\n",
      "SGD iter. 38/3599: loss=0.11038860896284089\n",
      "SGD iter. 39/3599: loss=0.11447094260520768\n",
      "SGD iter. 40/3599: loss=0.10856870958021513\n",
      "SGD iter. 41/3599: loss=0.11371595135092855\n",
      "SGD iter. 42/3599: loss=0.11070990603187983\n",
      "SGD iter. 43/3599: loss=0.10084812840321981\n",
      "SGD iter. 44/3599: loss=0.1213294871063179\n",
      "SGD iter. 45/3599: loss=0.1144119669265436\n",
      "SGD iter. 46/3599: loss=0.10594516549644985\n",
      "SGD iter. 47/3599: loss=0.11404305552746714\n",
      "SGD iter. 48/3599: loss=0.12067518519740233\n",
      "SGD iter. 49/3599: loss=0.11495461520113974\n",
      "SGD iter. 50/3599: loss=0.11497278299324765\n",
      "SGD iter. 51/3599: loss=0.10869860483432388\n",
      "SGD iter. 52/3599: loss=0.11444410376543293\n",
      "SGD iter. 53/3599: loss=0.11624147784614472\n",
      "SGD iter. 54/3599: loss=0.11894529959396233\n",
      "SGD iter. 55/3599: loss=0.11116766376666716\n",
      "SGD iter. 56/3599: loss=0.11760440712271425\n",
      "SGD iter. 57/3599: loss=0.10889487491311725\n",
      "SGD iter. 58/3599: loss=0.11766493174472242\n",
      "SGD iter. 59/3599: loss=0.09731325160819604\n",
      "SGD iter. 60/3599: loss=0.11614975445461906\n",
      "SGD iter. 61/3599: loss=0.10384080207540007\n",
      "SGD iter. 62/3599: loss=0.11282995574278441\n",
      "SGD iter. 63/3599: loss=0.11370789849411825\n",
      "SGD iter. 64/3599: loss=0.10851106735733342\n",
      "SGD iter. 65/3599: loss=0.11080419492479733\n",
      "SGD iter. 66/3599: loss=0.11666836119797816\n",
      "SGD iter. 67/3599: loss=0.10605198914102155\n",
      "SGD iter. 68/3599: loss=0.11529669501675874\n",
      "SGD iter. 69/3599: loss=0.11635941498578463\n",
      "SGD iter. 70/3599: loss=0.09600378678634386\n",
      "SGD iter. 71/3599: loss=0.10911938301693369\n",
      "SGD iter. 72/3599: loss=0.12046321596807823\n",
      "SGD iter. 73/3599: loss=0.11256434706609686\n",
      "SGD iter. 74/3599: loss=0.10713139956892305\n",
      "SGD iter. 75/3599: loss=0.11541143662933045\n",
      "SGD iter. 76/3599: loss=0.11075038365858024\n",
      "SGD iter. 77/3599: loss=0.1134846022885434\n",
      "SGD iter. 78/3599: loss=0.11271246272676595\n",
      "SGD iter. 79/3599: loss=0.10787117804390065\n",
      "SGD iter. 80/3599: loss=0.10412882940812895\n",
      "SGD iter. 81/3599: loss=0.10306693762457222\n",
      "SGD iter. 82/3599: loss=0.11175886553287237\n",
      "SGD iter. 83/3599: loss=0.09865091592739814\n",
      "SGD iter. 84/3599: loss=0.10910729514223647\n",
      "SGD iter. 85/3599: loss=0.11230510635866768\n",
      "SGD iter. 86/3599: loss=0.09963721495488076\n",
      "SGD iter. 87/3599: loss=0.0996655090380637\n",
      "SGD iter. 88/3599: loss=0.10362207446792153\n",
      "SGD iter. 89/3599: loss=0.10833318841812584\n",
      "SGD iter. 90/3599: loss=0.10725544002309345\n",
      "SGD iter. 91/3599: loss=0.11403773961722741\n",
      "SGD iter. 92/3599: loss=0.1069272852873943\n",
      "SGD iter. 93/3599: loss=0.11732269405697215\n",
      "SGD iter. 94/3599: loss=0.11614285183046716\n",
      "SGD iter. 95/3599: loss=0.1081635014736535\n",
      "SGD iter. 96/3599: loss=0.11155064041034718\n",
      "SGD iter. 97/3599: loss=0.11078466487041701\n",
      "SGD iter. 98/3599: loss=0.11612441330320558\n",
      "SGD iter. 99/3599: loss=0.11274769493200804\n",
      "SGD iter. 100/3599: loss=0.09733305962133007\n",
      "SGD iter. 101/3599: loss=0.11789893281115758\n",
      "SGD iter. 102/3599: loss=0.10372100936382664\n",
      "SGD iter. 103/3599: loss=0.10699936821177349\n",
      "SGD iter. 104/3599: loss=0.10125767673046313\n",
      "SGD iter. 105/3599: loss=0.1073978442666928\n",
      "SGD iter. 106/3599: loss=0.1148823382072715\n",
      "SGD iter. 107/3599: loss=0.10579473646600593\n",
      "SGD iter. 108/3599: loss=0.10728408901417485\n",
      "SGD iter. 109/3599: loss=0.10509461516725516\n",
      "SGD iter. 110/3599: loss=0.1095844902176556\n",
      "SGD iter. 111/3599: loss=0.10652367415591926\n",
      "SGD iter. 112/3599: loss=0.11686526846014568\n",
      "SGD iter. 113/3599: loss=0.10331374365693632\n",
      "SGD iter. 114/3599: loss=0.11697197591941874\n",
      "SGD iter. 115/3599: loss=0.10719203170773257\n",
      "SGD iter. 116/3599: loss=0.1087475138336473\n",
      "SGD iter. 117/3599: loss=0.1074548788877856\n",
      "SGD iter. 118/3599: loss=0.11600574422495082\n",
      "SGD iter. 119/3599: loss=0.11035072421355659\n",
      "SGD iter. 120/3599: loss=0.09261992606342158\n",
      "SGD iter. 121/3599: loss=0.11696817244756184\n",
      "SGD iter. 122/3599: loss=0.11294748118482414\n",
      "SGD iter. 123/3599: loss=0.11354077409582003\n",
      "SGD iter. 124/3599: loss=0.10821746514710268\n",
      "SGD iter. 125/3599: loss=0.11259571611422077\n",
      "SGD iter. 126/3599: loss=0.1142406438966473\n",
      "SGD iter. 127/3599: loss=0.1112461841490204\n",
      "SGD iter. 128/3599: loss=0.10695634228989168\n",
      "SGD iter. 129/3599: loss=0.10497978511675155\n",
      "SGD iter. 130/3599: loss=0.11181347142695472\n",
      "SGD iter. 131/3599: loss=0.10490956037668939\n",
      "SGD iter. 132/3599: loss=0.11507721238091828\n",
      "SGD iter. 133/3599: loss=0.11816284418348472\n",
      "SGD iter. 134/3599: loss=0.1059609336954552\n",
      "SGD iter. 135/3599: loss=0.11088008662401597\n",
      "SGD iter. 136/3599: loss=0.09867524668045272\n",
      "SGD iter. 137/3599: loss=0.1133464519734606\n",
      "SGD iter. 138/3599: loss=0.110553564658755\n",
      "SGD iter. 139/3599: loss=0.11979735714415513\n",
      "SGD iter. 140/3599: loss=0.1143815183306873\n",
      "SGD iter. 141/3599: loss=0.11590121045289217\n",
      "SGD iter. 142/3599: loss=0.11327905408420191\n",
      "SGD iter. 143/3599: loss=0.11121345764539596\n",
      "SGD iter. 144/3599: loss=0.10064781063058523\n",
      "SGD iter. 145/3599: loss=0.11107545931074464\n",
      "SGD iter. 146/3599: loss=0.11082713091840395\n",
      "SGD iter. 147/3599: loss=0.10770834609730784\n",
      "SGD iter. 148/3599: loss=0.1164563719433368\n",
      "SGD iter. 149/3599: loss=0.1148372767092137\n",
      "SGD iter. 150/3599: loss=0.11335257499803153\n",
      "SGD iter. 151/3599: loss=0.1021467352933918\n",
      "SGD iter. 152/3599: loss=0.11156451274207613\n",
      "SGD iter. 153/3599: loss=0.10837437713582308\n",
      "SGD iter. 154/3599: loss=0.11218155435477048\n",
      "SGD iter. 155/3599: loss=0.10366220748887171\n",
      "SGD iter. 156/3599: loss=0.1145798175104828\n",
      "SGD iter. 157/3599: loss=0.1162082758527973\n",
      "SGD iter. 158/3599: loss=0.11473409203297089\n",
      "SGD iter. 159/3599: loss=0.10603957033549463\n",
      "SGD iter. 160/3599: loss=0.11070130088180286\n",
      "SGD iter. 161/3599: loss=0.10919111018745933\n",
      "SGD iter. 162/3599: loss=0.1090372211570889\n",
      "SGD iter. 163/3599: loss=0.10210560464919365\n",
      "SGD iter. 164/3599: loss=0.11002816043958091\n",
      "SGD iter. 165/3599: loss=0.10644884105776542\n",
      "SGD iter. 166/3599: loss=0.1113611187460474\n",
      "SGD iter. 167/3599: loss=0.10731986505270111\n",
      "SGD iter. 168/3599: loss=0.11304181166354706\n",
      "SGD iter. 169/3599: loss=0.10944233961822177\n",
      "SGD iter. 170/3599: loss=0.11219204341226065\n",
      "SGD iter. 171/3599: loss=0.0996224747998066\n",
      "SGD iter. 172/3599: loss=0.10502419552514652\n",
      "SGD iter. 173/3599: loss=0.11257943609454649\n",
      "SGD iter. 174/3599: loss=0.11493881645110493\n",
      "SGD iter. 175/3599: loss=0.11070930702913734\n",
      "SGD iter. 176/3599: loss=0.10237783158667492\n",
      "SGD iter. 177/3599: loss=0.10202162537849094\n",
      "SGD iter. 178/3599: loss=0.10949969021178829\n",
      "SGD iter. 179/3599: loss=0.10872634691043928\n",
      "SGD iter. 180/3599: loss=0.11419967159806596\n",
      "SGD iter. 181/3599: loss=0.10946447237323739\n",
      "SGD iter. 182/3599: loss=0.10727596293039528\n",
      "SGD iter. 183/3599: loss=0.1113169395340212\n",
      "SGD iter. 184/3599: loss=0.11293594309466043\n",
      "SGD iter. 185/3599: loss=0.11215690660190882\n",
      "SGD iter. 186/3599: loss=0.11233882920385962\n",
      "SGD iter. 187/3599: loss=0.11237703708459618\n",
      "SGD iter. 188/3599: loss=0.11261255249966845\n",
      "SGD iter. 189/3599: loss=0.10572617874911708\n",
      "SGD iter. 190/3599: loss=0.10978902733551071\n",
      "SGD iter. 191/3599: loss=0.10728636756931116\n",
      "SGD iter. 192/3599: loss=0.0979555221713382\n",
      "SGD iter. 193/3599: loss=0.11523579319143734\n",
      "SGD iter. 194/3599: loss=0.11060891311547669\n",
      "SGD iter. 195/3599: loss=0.11239687360055556\n",
      "SGD iter. 196/3599: loss=0.10503228586826446\n",
      "SGD iter. 197/3599: loss=0.11527621194668247\n",
      "SGD iter. 198/3599: loss=0.1107429290087977\n",
      "SGD iter. 199/3599: loss=0.10768240141071636\n",
      "SGD iter. 200/3599: loss=0.11180759103203597\n",
      "SGD iter. 201/3599: loss=0.10890339714587324\n",
      "SGD iter. 202/3599: loss=0.1093091782019634\n",
      "SGD iter. 203/3599: loss=0.10321188551431121\n",
      "SGD iter. 204/3599: loss=0.10994245373837598\n",
      "SGD iter. 205/3599: loss=0.09719196344428885\n",
      "SGD iter. 206/3599: loss=0.11000135991956686\n",
      "SGD iter. 207/3599: loss=0.1114112063787573\n",
      "SGD iter. 208/3599: loss=0.10273115824273556\n",
      "SGD iter. 209/3599: loss=0.11759602778518832\n",
      "SGD iter. 210/3599: loss=0.11600906452070475\n",
      "SGD iter. 211/3599: loss=0.10660294999173664\n",
      "SGD iter. 212/3599: loss=0.11317405997774152\n",
      "SGD iter. 213/3599: loss=0.10638869478419313\n",
      "SGD iter. 214/3599: loss=0.10948547210989334\n",
      "SGD iter. 215/3599: loss=0.10107109133367015\n",
      "SGD iter. 216/3599: loss=0.10888748242625801\n",
      "SGD iter. 217/3599: loss=0.11189976128264219\n",
      "SGD iter. 218/3599: loss=0.10904404558556602\n",
      "SGD iter. 219/3599: loss=0.10833193331754645\n",
      "SGD iter. 220/3599: loss=0.10895301032111494\n",
      "SGD iter. 221/3599: loss=0.11078583817960037\n",
      "SGD iter. 222/3599: loss=0.1046959379408155\n",
      "SGD iter. 223/3599: loss=0.09708347806542848\n",
      "SGD iter. 224/3599: loss=0.099206223987798\n",
      "SGD iter. 225/3599: loss=0.10492504813404066\n",
      "SGD iter. 226/3599: loss=0.11791554959079756\n",
      "SGD iter. 227/3599: loss=0.10880503369639204\n",
      "SGD iter. 228/3599: loss=0.10381849634161838\n",
      "SGD iter. 229/3599: loss=0.10998366625794065\n",
      "SGD iter. 230/3599: loss=0.10675710502925469\n",
      "SGD iter. 231/3599: loss=0.10839687568559853\n",
      "SGD iter. 232/3599: loss=0.10372886914574575\n",
      "SGD iter. 233/3599: loss=0.10983189489947973\n",
      "SGD iter. 234/3599: loss=0.11298192621316555\n",
      "SGD iter. 235/3599: loss=0.11366498176379111\n",
      "SGD iter. 236/3599: loss=0.10687240641892165\n",
      "SGD iter. 237/3599: loss=0.10707075495318624\n",
      "SGD iter. 238/3599: loss=0.10212553522997263\n",
      "SGD iter. 239/3599: loss=0.10644962886141263\n",
      "SGD iter. 240/3599: loss=0.10107756938709411\n",
      "SGD iter. 241/3599: loss=0.1096960529609548\n",
      "SGD iter. 242/3599: loss=0.10747176026018196\n",
      "SGD iter. 243/3599: loss=0.1051140139913656\n",
      "SGD iter. 244/3599: loss=0.10620184610469588\n",
      "SGD iter. 245/3599: loss=0.11103699143196881\n",
      "SGD iter. 246/3599: loss=0.11154502754803446\n",
      "SGD iter. 247/3599: loss=0.10669780002242132\n",
      "SGD iter. 248/3599: loss=0.09562793931841714\n",
      "SGD iter. 249/3599: loss=0.09566657274995498\n",
      "SGD iter. 250/3599: loss=0.1147251450570751\n",
      "SGD iter. 251/3599: loss=0.09586415564221565\n",
      "SGD iter. 252/3599: loss=0.0997186369433826\n",
      "SGD iter. 253/3599: loss=0.10458194837144918\n",
      "SGD iter. 254/3599: loss=0.0942101558973707\n",
      "SGD iter. 255/3599: loss=0.11139043678688804\n",
      "SGD iter. 256/3599: loss=0.10372159255992369\n",
      "SGD iter. 257/3599: loss=0.10544377061990351\n",
      "SGD iter. 258/3599: loss=0.10430737461639354\n",
      "SGD iter. 259/3599: loss=0.11031984759877356\n",
      "SGD iter. 260/3599: loss=0.1100701374097339\n",
      "SGD iter. 261/3599: loss=0.10465260319036537\n",
      "SGD iter. 262/3599: loss=0.1087066086597846\n",
      "SGD iter. 263/3599: loss=0.11331595509253442\n",
      "SGD iter. 264/3599: loss=0.11396308314088813\n",
      "SGD iter. 265/3599: loss=0.1073683025075057\n",
      "SGD iter. 266/3599: loss=0.1066225197093287\n",
      "SGD iter. 267/3599: loss=0.10826421385230912\n",
      "SGD iter. 268/3599: loss=0.10367101427509999\n",
      "SGD iter. 269/3599: loss=0.09862526182219994\n",
      "SGD iter. 270/3599: loss=0.09946416263028506\n",
      "SGD iter. 271/3599: loss=0.10192728417461924\n",
      "SGD iter. 272/3599: loss=0.1141412144146261\n",
      "SGD iter. 273/3599: loss=0.11287553169708266\n",
      "SGD iter. 274/3599: loss=0.1093787991942056\n",
      "SGD iter. 275/3599: loss=0.10234751432866401\n",
      "SGD iter. 276/3599: loss=0.11652691723320426\n",
      "SGD iter. 277/3599: loss=0.11302920654904161\n",
      "SGD iter. 278/3599: loss=0.11575793763257554\n",
      "SGD iter. 279/3599: loss=0.11085321572378948\n",
      "SGD iter. 280/3599: loss=0.10928735249566118\n",
      "SGD iter. 281/3599: loss=0.10396588283870431\n",
      "SGD iter. 282/3599: loss=0.09961707899618055\n",
      "SGD iter. 283/3599: loss=0.10785766363626606\n",
      "SGD iter. 284/3599: loss=0.10087445322306415\n",
      "SGD iter. 285/3599: loss=0.10752292040994732\n",
      "SGD iter. 286/3599: loss=0.10333927919501033\n",
      "SGD iter. 287/3599: loss=0.11122759373858321\n",
      "SGD iter. 288/3599: loss=0.10451785896414562\n",
      "SGD iter. 289/3599: loss=0.10822078898809495\n",
      "SGD iter. 290/3599: loss=0.09606982428595767\n",
      "SGD iter. 291/3599: loss=0.11211055649602679\n",
      "SGD iter. 292/3599: loss=0.1109115571218566\n",
      "SGD iter. 293/3599: loss=0.11320772134288914\n",
      "SGD iter. 294/3599: loss=0.11008140108513731\n",
      "SGD iter. 295/3599: loss=0.10866297380382485\n",
      "SGD iter. 296/3599: loss=0.1054994048774055\n",
      "SGD iter. 297/3599: loss=0.1094865906910013\n",
      "SGD iter. 298/3599: loss=0.10499463100891349\n",
      "SGD iter. 299/3599: loss=0.1071832411825844\n",
      "SGD iter. 300/3599: loss=0.10898364136287858\n",
      "SGD iter. 301/3599: loss=0.10424733948682294\n",
      "SGD iter. 302/3599: loss=0.10542627168256447\n",
      "SGD iter. 303/3599: loss=0.1113345018850633\n",
      "SGD iter. 304/3599: loss=0.11290523007834471\n",
      "SGD iter. 305/3599: loss=0.112347849169039\n",
      "SGD iter. 306/3599: loss=0.10670626362584507\n",
      "SGD iter. 307/3599: loss=0.10584854571544192\n",
      "SGD iter. 308/3599: loss=0.10366626830132972\n",
      "SGD iter. 309/3599: loss=0.10632771509585626\n",
      "SGD iter. 310/3599: loss=0.10788435792203235\n",
      "SGD iter. 311/3599: loss=0.10656734440306265\n",
      "SGD iter. 312/3599: loss=0.09677334130943976\n",
      "SGD iter. 313/3599: loss=0.10968296077281478\n",
      "SGD iter. 314/3599: loss=0.11514650974476517\n",
      "SGD iter. 315/3599: loss=0.10331094453853881\n",
      "SGD iter. 316/3599: loss=0.10736431982643634\n",
      "SGD iter. 317/3599: loss=0.10997998113624824\n",
      "SGD iter. 318/3599: loss=0.11099220316068095\n",
      "SGD iter. 319/3599: loss=0.10617962043867853\n",
      "SGD iter. 320/3599: loss=0.10553863278914812\n",
      "SGD iter. 321/3599: loss=0.10751131242390811\n",
      "SGD iter. 322/3599: loss=0.1083208374354469\n",
      "SGD iter. 323/3599: loss=0.11266279778845593\n",
      "SGD iter. 324/3599: loss=0.11855932396668555\n",
      "SGD iter. 325/3599: loss=0.09833450529340022\n",
      "SGD iter. 326/3599: loss=0.09717196871676678\n",
      "SGD iter. 327/3599: loss=0.10345035803657227\n",
      "SGD iter. 328/3599: loss=0.10628989288955026\n",
      "SGD iter. 329/3599: loss=0.10488009962951325\n",
      "SGD iter. 330/3599: loss=0.09462686391187966\n",
      "SGD iter. 331/3599: loss=0.11193344088122559\n",
      "SGD iter. 332/3599: loss=0.11025975802686734\n",
      "SGD iter. 333/3599: loss=0.10685363345098463\n",
      "SGD iter. 334/3599: loss=0.1058416781730902\n",
      "SGD iter. 335/3599: loss=0.1037258195522359\n",
      "SGD iter. 336/3599: loss=0.1078793194656692\n",
      "SGD iter. 337/3599: loss=0.11263566572684099\n",
      "SGD iter. 338/3599: loss=0.10749494373221531\n",
      "SGD iter. 339/3599: loss=0.10551313345734835\n",
      "SGD iter. 340/3599: loss=0.1142153285820499\n",
      "SGD iter. 341/3599: loss=0.1068694961995323\n",
      "SGD iter. 342/3599: loss=0.11660438863450848\n",
      "SGD iter. 343/3599: loss=0.10847747307291247\n",
      "SGD iter. 344/3599: loss=0.11333692817071617\n",
      "SGD iter. 345/3599: loss=0.10953470728520363\n",
      "SGD iter. 346/3599: loss=0.1120544004902704\n",
      "SGD iter. 347/3599: loss=0.10652279064278122\n",
      "SGD iter. 348/3599: loss=0.10313624308061882\n",
      "SGD iter. 349/3599: loss=0.1105410201874067\n",
      "SGD iter. 350/3599: loss=0.11438622027343312\n",
      "SGD iter. 351/3599: loss=0.10883378538758634\n",
      "SGD iter. 352/3599: loss=0.10533489578851571\n",
      "SGD iter. 353/3599: loss=0.10884308831633116\n",
      "SGD iter. 354/3599: loss=0.10886893539943464\n",
      "SGD iter. 355/3599: loss=0.10209134341636766\n",
      "SGD iter. 356/3599: loss=0.10627809400494816\n",
      "SGD iter. 357/3599: loss=0.10497002361810964\n",
      "SGD iter. 358/3599: loss=0.10359841100497118\n",
      "SGD iter. 359/3599: loss=0.10635544466503234\n",
      "SGD iter. 360/3599: loss=0.1093661998154892\n",
      "SGD iter. 361/3599: loss=0.10451851604632006\n",
      "SGD iter. 362/3599: loss=0.09823623003205806\n",
      "SGD iter. 363/3599: loss=0.10785544151416787\n",
      "SGD iter. 364/3599: loss=0.09628734841639264\n",
      "SGD iter. 365/3599: loss=0.1127583553688161\n",
      "SGD iter. 366/3599: loss=0.09830652354022855\n",
      "SGD iter. 367/3599: loss=0.10222708303163201\n",
      "SGD iter. 368/3599: loss=0.11109190701226564\n",
      "SGD iter. 369/3599: loss=0.10687066092208575\n",
      "SGD iter. 370/3599: loss=0.10251872703536971\n",
      "SGD iter. 371/3599: loss=0.10679023988280625\n",
      "SGD iter. 372/3599: loss=0.11307133428347291\n",
      "SGD iter. 373/3599: loss=0.11170476861516683\n",
      "SGD iter. 374/3599: loss=0.10370802392529638\n",
      "SGD iter. 375/3599: loss=0.10009989323007407\n",
      "SGD iter. 376/3599: loss=0.099042566133812\n",
      "SGD iter. 377/3599: loss=0.10359410309109215\n",
      "SGD iter. 378/3599: loss=0.10228641893171203\n",
      "SGD iter. 379/3599: loss=0.09463686844329344\n",
      "SGD iter. 380/3599: loss=0.10958294760338065\n",
      "SGD iter. 381/3599: loss=0.10881301287563293\n",
      "SGD iter. 382/3599: loss=0.10663159017588297\n",
      "SGD iter. 383/3599: loss=0.10765417274353983\n",
      "SGD iter. 384/3599: loss=0.10549297579093161\n",
      "SGD iter. 385/3599: loss=0.10393253331959687\n",
      "SGD iter. 386/3599: loss=0.11458895527299906\n",
      "SGD iter. 387/3599: loss=0.10185865480080289\n",
      "SGD iter. 388/3599: loss=0.11069764731935341\n",
      "SGD iter. 389/3599: loss=0.10897438216091357\n",
      "SGD iter. 390/3599: loss=0.10312743653789117\n",
      "SGD iter. 391/3599: loss=0.10721695209060358\n",
      "SGD iter. 392/3599: loss=0.10320680836445274\n",
      "SGD iter. 393/3599: loss=0.10822483572829761\n",
      "SGD iter. 394/3599: loss=0.10288992698093452\n",
      "SGD iter. 395/3599: loss=0.10657294049642685\n",
      "SGD iter. 396/3599: loss=0.10304638867782603\n",
      "SGD iter. 397/3599: loss=0.10347131482228823\n",
      "SGD iter. 398/3599: loss=0.10785534506551947\n",
      "SGD iter. 399/3599: loss=0.10950201186951214\n",
      "SGD iter. 400/3599: loss=0.10849020495480233\n",
      "SGD iter. 401/3599: loss=0.10107309876082268\n",
      "SGD iter. 402/3599: loss=0.10835241871484788\n",
      "SGD iter. 403/3599: loss=0.11316164153327016\n",
      "SGD iter. 404/3599: loss=0.11032060028411467\n",
      "SGD iter. 405/3599: loss=0.10670701676594815\n",
      "SGD iter. 406/3599: loss=0.11011673316037679\n",
      "SGD iter. 407/3599: loss=0.10183397810743806\n",
      "SGD iter. 408/3599: loss=0.1009226567992632\n",
      "SGD iter. 409/3599: loss=0.10808057248708197\n",
      "SGD iter. 410/3599: loss=0.11312627459557158\n",
      "SGD iter. 411/3599: loss=0.10350258980812356\n",
      "SGD iter. 412/3599: loss=0.10702249116562113\n",
      "SGD iter. 413/3599: loss=0.10428391492487935\n",
      "SGD iter. 414/3599: loss=0.1043922171510731\n",
      "SGD iter. 415/3599: loss=0.10350625270628666\n",
      "SGD iter. 416/3599: loss=0.10291305332713852\n",
      "SGD iter. 417/3599: loss=0.10411033992271271\n",
      "SGD iter. 418/3599: loss=0.11187138457538143\n",
      "SGD iter. 419/3599: loss=0.10834296556704609\n",
      "SGD iter. 420/3599: loss=0.10377065489139303\n",
      "SGD iter. 421/3599: loss=0.11208891306024309\n",
      "SGD iter. 422/3599: loss=0.11191368012175533\n",
      "SGD iter. 423/3599: loss=0.1036748015990919\n",
      "SGD iter. 424/3599: loss=0.11236875924824263\n",
      "SGD iter. 425/3599: loss=0.10482988671742446\n",
      "SGD iter. 426/3599: loss=0.10379853052020176\n",
      "SGD iter. 427/3599: loss=0.10157314112466762\n",
      "SGD iter. 428/3599: loss=0.10752638825053698\n",
      "SGD iter. 429/3599: loss=0.10768511566829927\n",
      "SGD iter. 430/3599: loss=0.10162857526596038\n",
      "SGD iter. 431/3599: loss=0.10973421523209491\n",
      "SGD iter. 432/3599: loss=0.10670943963422083\n",
      "SGD iter. 433/3599: loss=0.10835348463390676\n",
      "SGD iter. 434/3599: loss=0.10333362076295947\n",
      "SGD iter. 435/3599: loss=0.10921749136139806\n",
      "SGD iter. 436/3599: loss=0.10648697195619719\n",
      "SGD iter. 437/3599: loss=0.11367138025382467\n",
      "SGD iter. 438/3599: loss=0.10083097660026134\n",
      "SGD iter. 439/3599: loss=0.111392520244892\n",
      "SGD iter. 440/3599: loss=0.10710626059742692\n",
      "SGD iter. 441/3599: loss=0.10393413519183085\n",
      "SGD iter. 442/3599: loss=0.10877716470386342\n",
      "SGD iter. 443/3599: loss=0.10998383192029773\n",
      "SGD iter. 444/3599: loss=0.09981069990389968\n",
      "SGD iter. 445/3599: loss=0.09441686822390394\n",
      "SGD iter. 446/3599: loss=0.10569068835649008\n",
      "SGD iter. 447/3599: loss=0.10961100991418199\n",
      "SGD iter. 448/3599: loss=0.10064591288483778\n",
      "SGD iter. 449/3599: loss=0.10998242201273614\n",
      "SGD iter. 450/3599: loss=0.10785033132690525\n",
      "SGD iter. 451/3599: loss=0.10750728527726329\n",
      "SGD iter. 452/3599: loss=0.10348058655799248\n",
      "SGD iter. 453/3599: loss=0.10547483514844828\n",
      "SGD iter. 454/3599: loss=0.10690401090253725\n",
      "SGD iter. 455/3599: loss=0.10620626859479793\n",
      "SGD iter. 456/3599: loss=0.11385208704229627\n",
      "SGD iter. 457/3599: loss=0.10032707199880789\n",
      "SGD iter. 458/3599: loss=0.11196880947603002\n",
      "SGD iter. 459/3599: loss=0.10326303879272039\n",
      "SGD iter. 460/3599: loss=0.1076669559190839\n",
      "SGD iter. 461/3599: loss=0.09935236040669826\n",
      "SGD iter. 462/3599: loss=0.10837076253138724\n",
      "SGD iter. 463/3599: loss=0.10732036666537521\n",
      "SGD iter. 464/3599: loss=0.10773500304921287\n",
      "SGD iter. 465/3599: loss=0.10190000636477917\n",
      "SGD iter. 466/3599: loss=0.10692706776322149\n",
      "SGD iter. 467/3599: loss=0.10567803034261034\n",
      "SGD iter. 468/3599: loss=0.10437174201159227\n",
      "SGD iter. 469/3599: loss=0.10377082284557912\n",
      "SGD iter. 470/3599: loss=0.09541869495673623\n",
      "SGD iter. 471/3599: loss=0.10583907736046949\n",
      "SGD iter. 472/3599: loss=0.10358829654620134\n",
      "SGD iter. 473/3599: loss=0.10267731336747472\n",
      "SGD iter. 474/3599: loss=0.1111082480731565\n",
      "SGD iter. 475/3599: loss=0.10197063520429914\n",
      "SGD iter. 476/3599: loss=0.11048190088306398\n",
      "SGD iter. 477/3599: loss=0.10999247470420877\n",
      "SGD iter. 478/3599: loss=0.1030380351189833\n",
      "SGD iter. 479/3599: loss=0.10948368116268514\n",
      "SGD iter. 480/3599: loss=0.10853756515139044\n",
      "SGD iter. 481/3599: loss=0.1061354884631722\n",
      "SGD iter. 482/3599: loss=0.10069085348226736\n",
      "SGD iter. 483/3599: loss=0.09615089351774525\n",
      "SGD iter. 484/3599: loss=0.10431787592802433\n",
      "SGD iter. 485/3599: loss=0.10721912823901496\n",
      "SGD iter. 486/3599: loss=0.11285986099458484\n",
      "SGD iter. 487/3599: loss=0.1091871385622723\n",
      "SGD iter. 488/3599: loss=0.10651766155035342\n",
      "SGD iter. 489/3599: loss=0.10148840969416444\n",
      "SGD iter. 490/3599: loss=0.09765638800590754\n",
      "SGD iter. 491/3599: loss=0.10551668436718113\n",
      "SGD iter. 492/3599: loss=0.10263182706319349\n",
      "SGD iter. 493/3599: loss=0.10610447146499626\n",
      "SGD iter. 494/3599: loss=0.1071873089984342\n",
      "SGD iter. 495/3599: loss=0.10582488723131364\n",
      "SGD iter. 496/3599: loss=0.11033707851896477\n",
      "SGD iter. 497/3599: loss=0.10837668774129688\n",
      "SGD iter. 498/3599: loss=0.09518014911693945\n",
      "SGD iter. 499/3599: loss=0.10405269943282978\n",
      "SGD iter. 500/3599: loss=0.10621052435956684\n",
      "SGD iter. 501/3599: loss=0.10995923282193593\n",
      "SGD iter. 502/3599: loss=0.10004968914622543\n",
      "SGD iter. 503/3599: loss=0.10067405394806365\n",
      "SGD iter. 504/3599: loss=0.10975702668244633\n",
      "SGD iter. 505/3599: loss=0.09935908567910312\n",
      "SGD iter. 506/3599: loss=0.10311741095092344\n",
      "SGD iter. 507/3599: loss=0.10995529531472334\n",
      "SGD iter. 508/3599: loss=0.1086585521620122\n",
      "SGD iter. 509/3599: loss=0.10137701191413087\n",
      "SGD iter. 510/3599: loss=0.11374450739189948\n",
      "SGD iter. 511/3599: loss=0.11141532433596592\n",
      "SGD iter. 512/3599: loss=0.1029621021764236\n",
      "SGD iter. 513/3599: loss=0.10212146614778415\n",
      "SGD iter. 514/3599: loss=0.10184149511958751\n",
      "SGD iter. 515/3599: loss=0.09473481601023276\n",
      "SGD iter. 516/3599: loss=0.11077581262607256\n",
      "SGD iter. 517/3599: loss=0.10805643642851404\n",
      "SGD iter. 518/3599: loss=0.1088473097483578\n",
      "SGD iter. 519/3599: loss=0.10927583922577153\n",
      "SGD iter. 520/3599: loss=0.11291850433263499\n",
      "SGD iter. 521/3599: loss=0.09938852100981677\n",
      "SGD iter. 522/3599: loss=0.10778211659457733\n",
      "SGD iter. 523/3599: loss=0.1087828693345447\n",
      "SGD iter. 524/3599: loss=0.10446661113945749\n",
      "SGD iter. 525/3599: loss=0.11053642463054916\n",
      "SGD iter. 526/3599: loss=0.09952545364158749\n",
      "SGD iter. 527/3599: loss=0.10235331915118046\n",
      "SGD iter. 528/3599: loss=0.10970685843910447\n",
      "SGD iter. 529/3599: loss=0.0954110954955863\n",
      "SGD iter. 530/3599: loss=0.09598000647897709\n",
      "SGD iter. 531/3599: loss=0.10916902827613048\n",
      "SGD iter. 532/3599: loss=0.103930416501174\n",
      "SGD iter. 533/3599: loss=0.10332548378760106\n",
      "SGD iter. 534/3599: loss=0.10453178400176016\n",
      "SGD iter. 535/3599: loss=0.1073168826040664\n",
      "SGD iter. 536/3599: loss=0.11210126623883993\n",
      "SGD iter. 537/3599: loss=0.10348395848987443\n",
      "SGD iter. 538/3599: loss=0.10905371870067881\n",
      "SGD iter. 539/3599: loss=0.1050851208545364\n",
      "SGD iter. 540/3599: loss=0.10523166902758051\n",
      "SGD iter. 541/3599: loss=0.10292499724522064\n",
      "SGD iter. 542/3599: loss=0.10340258290339277\n",
      "SGD iter. 543/3599: loss=0.1107606356482015\n",
      "SGD iter. 544/3599: loss=0.10336706098569881\n",
      "SGD iter. 545/3599: loss=0.10472275924910468\n",
      "SGD iter. 546/3599: loss=0.10577349341089763\n",
      "SGD iter. 547/3599: loss=0.10678635421058622\n",
      "SGD iter. 548/3599: loss=0.10554173272123488\n",
      "SGD iter. 549/3599: loss=0.09814456566792029\n",
      "SGD iter. 550/3599: loss=0.10508350728371244\n",
      "SGD iter. 551/3599: loss=0.09889764955552945\n",
      "SGD iter. 552/3599: loss=0.10004505339133521\n",
      "SGD iter. 553/3599: loss=0.10508648591639022\n",
      "SGD iter. 554/3599: loss=0.1012414647352496\n",
      "SGD iter. 555/3599: loss=0.10626221141916885\n",
      "SGD iter. 556/3599: loss=0.10350113277924525\n",
      "SGD iter. 557/3599: loss=0.10359216750613795\n",
      "SGD iter. 558/3599: loss=0.0938566042705479\n",
      "SGD iter. 559/3599: loss=0.10102916317188088\n",
      "SGD iter. 560/3599: loss=0.09960570227518184\n",
      "SGD iter. 561/3599: loss=0.10303333004193929\n",
      "SGD iter. 562/3599: loss=0.09913482535684581\n",
      "SGD iter. 563/3599: loss=0.1051126378618756\n",
      "SGD iter. 564/3599: loss=0.09288359963659196\n",
      "SGD iter. 565/3599: loss=0.09951731387521323\n",
      "SGD iter. 566/3599: loss=0.10043882261590636\n",
      "SGD iter. 567/3599: loss=0.10505707480287965\n",
      "SGD iter. 568/3599: loss=0.10511783503814648\n",
      "SGD iter. 569/3599: loss=0.09456047118654953\n",
      "SGD iter. 570/3599: loss=0.10376412377200553\n",
      "SGD iter. 571/3599: loss=0.10154087873093331\n",
      "SGD iter. 572/3599: loss=0.10443054097332143\n",
      "SGD iter. 573/3599: loss=0.11384440966197658\n",
      "SGD iter. 574/3599: loss=0.10594682118610188\n",
      "SGD iter. 575/3599: loss=0.10391199030336809\n",
      "SGD iter. 576/3599: loss=0.10469018527134696\n",
      "SGD iter. 577/3599: loss=0.10060945797315403\n",
      "SGD iter. 578/3599: loss=0.10190073309209234\n",
      "SGD iter. 579/3599: loss=0.10453669056064972\n",
      "SGD iter. 580/3599: loss=0.10530232826735338\n",
      "SGD iter. 581/3599: loss=0.11206609407147955\n",
      "SGD iter. 582/3599: loss=0.11143832520307625\n",
      "SGD iter. 583/3599: loss=0.0990272732908901\n",
      "SGD iter. 584/3599: loss=0.0982195752792433\n",
      "SGD iter. 585/3599: loss=0.10707644517054912\n",
      "SGD iter. 586/3599: loss=0.11144682397212771\n",
      "SGD iter. 587/3599: loss=0.09969420078118084\n",
      "SGD iter. 588/3599: loss=0.10358524372276862\n",
      "SGD iter. 589/3599: loss=0.10731809912930351\n",
      "SGD iter. 590/3599: loss=0.10050753617736513\n",
      "SGD iter. 591/3599: loss=0.10709681979004512\n",
      "SGD iter. 592/3599: loss=0.10205961812199649\n",
      "SGD iter. 593/3599: loss=0.09119875724503836\n",
      "SGD iter. 594/3599: loss=0.09558502637552047\n",
      "SGD iter. 595/3599: loss=0.09545379081021574\n",
      "SGD iter. 596/3599: loss=0.09865562668027607\n",
      "SGD iter. 597/3599: loss=0.09771139791079325\n",
      "SGD iter. 598/3599: loss=0.10107083220131613\n",
      "SGD iter. 599/3599: loss=0.1100743270064106\n",
      "SGD iter. 600/3599: loss=0.10779312519744064\n",
      "SGD iter. 601/3599: loss=0.09087725929714463\n",
      "SGD iter. 602/3599: loss=0.10109094275046221\n",
      "SGD iter. 603/3599: loss=0.1070321351456717\n",
      "SGD iter. 604/3599: loss=0.09446842853406082\n",
      "SGD iter. 605/3599: loss=0.09126407538150182\n",
      "SGD iter. 606/3599: loss=0.10797785560985217\n",
      "SGD iter. 607/3599: loss=0.09413714419507774\n",
      "SGD iter. 608/3599: loss=0.11351268508355772\n",
      "SGD iter. 609/3599: loss=0.09838725332271592\n",
      "SGD iter. 610/3599: loss=0.10727907261523936\n",
      "SGD iter. 611/3599: loss=0.1056625441574198\n",
      "SGD iter. 612/3599: loss=0.09960754501442626\n",
      "SGD iter. 613/3599: loss=0.10175364017156983\n",
      "SGD iter. 614/3599: loss=0.10874087297178013\n",
      "SGD iter. 615/3599: loss=0.10404097144871341\n",
      "SGD iter. 616/3599: loss=0.10774509784371594\n",
      "SGD iter. 617/3599: loss=0.1070354593045073\n",
      "SGD iter. 618/3599: loss=0.10475997067160356\n",
      "SGD iter. 619/3599: loss=0.10044632638149159\n",
      "SGD iter. 620/3599: loss=0.10918353930141897\n",
      "SGD iter. 621/3599: loss=0.10504343659917162\n",
      "SGD iter. 622/3599: loss=0.10177569418016816\n",
      "SGD iter. 623/3599: loss=0.09679021742632388\n",
      "SGD iter. 624/3599: loss=0.11027534653089996\n",
      "SGD iter. 625/3599: loss=0.09744413670379726\n",
      "SGD iter. 626/3599: loss=0.10477193660214211\n",
      "SGD iter. 627/3599: loss=0.10798001700888694\n",
      "SGD iter. 628/3599: loss=0.11115469802874556\n",
      "SGD iter. 629/3599: loss=0.09978681372273347\n",
      "SGD iter. 630/3599: loss=0.09681790009207451\n",
      "SGD iter. 631/3599: loss=0.10800375559383449\n",
      "SGD iter. 632/3599: loss=0.0993912241359575\n",
      "SGD iter. 633/3599: loss=0.10562277861676125\n",
      "SGD iter. 634/3599: loss=0.10425241541400196\n",
      "SGD iter. 635/3599: loss=0.10134572595725863\n",
      "SGD iter. 636/3599: loss=0.10287206585928169\n",
      "SGD iter. 637/3599: loss=0.10504313902094418\n",
      "SGD iter. 638/3599: loss=0.09824980635436625\n",
      "SGD iter. 639/3599: loss=0.10390121249445369\n",
      "SGD iter. 640/3599: loss=0.09975821489657968\n",
      "SGD iter. 641/3599: loss=0.10704757844200143\n",
      "SGD iter. 642/3599: loss=0.09734431551302704\n",
      "SGD iter. 643/3599: loss=0.10524027989805554\n",
      "SGD iter. 644/3599: loss=0.1011552343003379\n",
      "SGD iter. 645/3599: loss=0.1004146047637765\n",
      "SGD iter. 646/3599: loss=0.10163426341708709\n",
      "SGD iter. 647/3599: loss=0.10497420292443649\n",
      "SGD iter. 648/3599: loss=0.10123649966296996\n",
      "SGD iter. 649/3599: loss=0.09701537578321688\n",
      "SGD iter. 650/3599: loss=0.10406922794261819\n",
      "SGD iter. 651/3599: loss=0.09999077081722699\n",
      "SGD iter. 652/3599: loss=0.10545401544367379\n",
      "SGD iter. 653/3599: loss=0.10603385793683677\n",
      "SGD iter. 654/3599: loss=0.09679391618446057\n",
      "SGD iter. 655/3599: loss=0.10577122462711055\n",
      "SGD iter. 656/3599: loss=0.1064803669758893\n",
      "SGD iter. 657/3599: loss=0.09878615015014819\n",
      "SGD iter. 658/3599: loss=0.10021786720934897\n",
      "SGD iter. 659/3599: loss=0.10145183648788604\n",
      "SGD iter. 660/3599: loss=0.10348385785442307\n",
      "SGD iter. 661/3599: loss=0.09417303989856862\n",
      "SGD iter. 662/3599: loss=0.10755414935756821\n",
      "SGD iter. 663/3599: loss=0.09504712853523595\n",
      "SGD iter. 664/3599: loss=0.10910137513130948\n",
      "SGD iter. 665/3599: loss=0.10289620647483773\n",
      "SGD iter. 666/3599: loss=0.1073862026701324\n",
      "SGD iter. 667/3599: loss=0.10298217270816815\n",
      "SGD iter. 668/3599: loss=0.09710793463415378\n",
      "SGD iter. 669/3599: loss=0.10529709891789257\n",
      "SGD iter. 670/3599: loss=0.09824907528319976\n",
      "SGD iter. 671/3599: loss=0.10316320272393077\n",
      "SGD iter. 672/3599: loss=0.10047241030246616\n",
      "SGD iter. 673/3599: loss=0.09883876411471278\n",
      "SGD iter. 674/3599: loss=0.10491416731615562\n",
      "SGD iter. 675/3599: loss=0.10270425004636648\n",
      "SGD iter. 676/3599: loss=0.10762894248697219\n",
      "SGD iter. 677/3599: loss=0.10451619691825151\n",
      "SGD iter. 678/3599: loss=0.09510327004219199\n",
      "SGD iter. 679/3599: loss=0.11052769187188041\n",
      "SGD iter. 680/3599: loss=0.10394111898551317\n",
      "SGD iter. 681/3599: loss=0.11259005320789243\n",
      "SGD iter. 682/3599: loss=0.09625288789930761\n",
      "SGD iter. 683/3599: loss=0.10148487043730599\n",
      "SGD iter. 684/3599: loss=0.10228268137888297\n",
      "SGD iter. 685/3599: loss=0.09644672662186193\n",
      "SGD iter. 686/3599: loss=0.10191044097444367\n",
      "SGD iter. 687/3599: loss=0.10539648710276041\n",
      "SGD iter. 688/3599: loss=0.09472090861313055\n",
      "SGD iter. 689/3599: loss=0.10019765802755502\n",
      "SGD iter. 690/3599: loss=0.0982046310083385\n",
      "SGD iter. 691/3599: loss=0.1065051038450031\n",
      "SGD iter. 692/3599: loss=0.10027293832575018\n",
      "SGD iter. 693/3599: loss=0.09648196330438309\n",
      "SGD iter. 694/3599: loss=0.10256947448674178\n",
      "SGD iter. 695/3599: loss=0.1077408922908877\n",
      "SGD iter. 696/3599: loss=0.09888460609484523\n",
      "SGD iter. 697/3599: loss=0.10312303353783832\n",
      "SGD iter. 698/3599: loss=0.10345932355330961\n",
      "SGD iter. 699/3599: loss=0.10263529494396369\n",
      "SGD iter. 700/3599: loss=0.09807719772783915\n",
      "SGD iter. 701/3599: loss=0.10382030486440974\n",
      "SGD iter. 702/3599: loss=0.10318754310676091\n",
      "SGD iter. 703/3599: loss=0.10789554538664732\n",
      "SGD iter. 704/3599: loss=0.09576488467072063\n",
      "SGD iter. 705/3599: loss=0.10434544555293666\n",
      "SGD iter. 706/3599: loss=0.10418865552187129\n",
      "SGD iter. 707/3599: loss=0.10271485997446902\n",
      "SGD iter. 708/3599: loss=0.10463872824258919\n",
      "SGD iter. 709/3599: loss=0.1035407046013955\n",
      "SGD iter. 710/3599: loss=0.09556645680120274\n",
      "SGD iter. 711/3599: loss=0.11619630692954577\n",
      "SGD iter. 712/3599: loss=0.1089294489372134\n",
      "SGD iter. 713/3599: loss=0.09443230022140005\n",
      "SGD iter. 714/3599: loss=0.10458965873149703\n",
      "SGD iter. 715/3599: loss=0.10774919945719977\n",
      "SGD iter. 716/3599: loss=0.10009972703264235\n",
      "SGD iter. 717/3599: loss=0.09936452494653031\n",
      "SGD iter. 718/3599: loss=0.10539423840161577\n",
      "SGD iter. 719/3599: loss=0.10316338912129458\n",
      "SGD iter. 720/3599: loss=0.1111097233074785\n",
      "SGD iter. 721/3599: loss=0.10478692236866144\n",
      "SGD iter. 722/3599: loss=0.10547376789952564\n",
      "SGD iter. 723/3599: loss=0.1084368761244484\n",
      "SGD iter. 724/3599: loss=0.08749117887793362\n",
      "SGD iter. 725/3599: loss=0.10444192283143691\n",
      "SGD iter. 726/3599: loss=0.0991852179429254\n",
      "SGD iter. 727/3599: loss=0.10501713284514878\n",
      "SGD iter. 728/3599: loss=0.08987904715226223\n",
      "SGD iter. 729/3599: loss=0.10284942602617267\n",
      "SGD iter. 730/3599: loss=0.09822125835326652\n",
      "SGD iter. 731/3599: loss=0.10174409209935295\n",
      "SGD iter. 732/3599: loss=0.09345185479526939\n",
      "SGD iter. 733/3599: loss=0.11188075181309783\n",
      "SGD iter. 734/3599: loss=0.1029012338862849\n",
      "SGD iter. 735/3599: loss=0.0907429591800828\n",
      "SGD iter. 736/3599: loss=0.1001883055726987\n",
      "SGD iter. 737/3599: loss=0.1015751359095666\n",
      "SGD iter. 738/3599: loss=0.10289090210142737\n",
      "SGD iter. 739/3599: loss=0.10128300844014071\n",
      "SGD iter. 740/3599: loss=0.10297504100502813\n",
      "SGD iter. 741/3599: loss=0.10462925581404539\n",
      "SGD iter. 742/3599: loss=0.1004506169847478\n",
      "SGD iter. 743/3599: loss=0.10203870115204261\n",
      "SGD iter. 744/3599: loss=0.09987849869963172\n",
      "SGD iter. 745/3599: loss=0.10451085829231246\n",
      "SGD iter. 746/3599: loss=0.09671580498812771\n",
      "SGD iter. 747/3599: loss=0.10193419032157819\n",
      "SGD iter. 748/3599: loss=0.08880737113567018\n",
      "SGD iter. 749/3599: loss=0.10120786401138679\n",
      "SGD iter. 750/3599: loss=0.10050443686375662\n",
      "SGD iter. 751/3599: loss=0.10656926872785545\n",
      "SGD iter. 752/3599: loss=0.10736447949757774\n",
      "SGD iter. 753/3599: loss=0.09737608788121946\n",
      "SGD iter. 754/3599: loss=0.1058809655593798\n",
      "SGD iter. 755/3599: loss=0.10380565510787851\n",
      "SGD iter. 756/3599: loss=0.10248872836641215\n",
      "SGD iter. 757/3599: loss=0.09967914928385797\n",
      "SGD iter. 758/3599: loss=0.10876992525502098\n",
      "SGD iter. 759/3599: loss=0.11027843145639049\n",
      "SGD iter. 760/3599: loss=0.10016714745357078\n",
      "SGD iter. 761/3599: loss=0.10690101431446991\n",
      "SGD iter. 762/3599: loss=0.09721048504815173\n",
      "SGD iter. 763/3599: loss=0.10475167319607426\n",
      "SGD iter. 764/3599: loss=0.10107757039532352\n",
      "SGD iter. 765/3599: loss=0.11221866969275862\n",
      "SGD iter. 766/3599: loss=0.09768358621338102\n",
      "SGD iter. 767/3599: loss=0.09921424476436849\n",
      "SGD iter. 768/3599: loss=0.10109961613197227\n",
      "SGD iter. 769/3599: loss=0.08936449459341933\n",
      "SGD iter. 770/3599: loss=0.09216531469535165\n",
      "SGD iter. 771/3599: loss=0.10321596691827137\n",
      "SGD iter. 772/3599: loss=0.0978919388691675\n",
      "SGD iter. 773/3599: loss=0.10324224526271802\n",
      "SGD iter. 774/3599: loss=0.1038703535686679\n",
      "SGD iter. 775/3599: loss=0.09402479207054748\n",
      "SGD iter. 776/3599: loss=0.10481286789996239\n",
      "SGD iter. 777/3599: loss=0.10045109750268352\n",
      "SGD iter. 778/3599: loss=0.09328463041708016\n",
      "SGD iter. 779/3599: loss=0.10186653475308713\n",
      "SGD iter. 780/3599: loss=0.10669570098293213\n",
      "SGD iter. 781/3599: loss=0.1075500933419526\n",
      "SGD iter. 782/3599: loss=0.09740800689186974\n",
      "SGD iter. 783/3599: loss=0.10425991874561334\n",
      "SGD iter. 784/3599: loss=0.10336177732920722\n",
      "SGD iter. 785/3599: loss=0.10393261607834234\n",
      "SGD iter. 786/3599: loss=0.100258558564857\n",
      "SGD iter. 787/3599: loss=0.09990980106012629\n",
      "SGD iter. 788/3599: loss=0.09448904271014952\n",
      "SGD iter. 789/3599: loss=0.10398635646122492\n",
      "SGD iter. 790/3599: loss=0.10019597336011504\n",
      "SGD iter. 791/3599: loss=0.10282305383623266\n",
      "SGD iter. 792/3599: loss=0.09370766123881177\n",
      "SGD iter. 793/3599: loss=0.09737496622196778\n",
      "SGD iter. 794/3599: loss=0.10316691239278106\n",
      "SGD iter. 795/3599: loss=0.10090432837893956\n",
      "SGD iter. 796/3599: loss=0.10040296128194523\n",
      "SGD iter. 797/3599: loss=0.10625916808242047\n",
      "SGD iter. 798/3599: loss=0.10335657930513326\n",
      "SGD iter. 799/3599: loss=0.1080936463456003\n",
      "SGD iter. 800/3599: loss=0.09850994201056847\n",
      "SGD iter. 801/3599: loss=0.1021451967077243\n",
      "SGD iter. 802/3599: loss=0.10957115729696937\n",
      "SGD iter. 803/3599: loss=0.10484631183060042\n",
      "SGD iter. 804/3599: loss=0.10849016403876183\n",
      "SGD iter. 805/3599: loss=0.10043723238055627\n",
      "SGD iter. 806/3599: loss=0.1018804039262084\n",
      "SGD iter. 807/3599: loss=0.10320376126297631\n",
      "SGD iter. 808/3599: loss=0.10789876675105414\n",
      "SGD iter. 809/3599: loss=0.09809264120744256\n",
      "SGD iter. 810/3599: loss=0.09797318399120516\n",
      "SGD iter. 811/3599: loss=0.10545164963468524\n",
      "SGD iter. 812/3599: loss=0.09491006664821974\n",
      "SGD iter. 813/3599: loss=0.10000149191996259\n",
      "SGD iter. 814/3599: loss=0.09432304035855593\n",
      "SGD iter. 815/3599: loss=0.09849352255299787\n",
      "SGD iter. 816/3599: loss=0.10014776591504385\n",
      "SGD iter. 817/3599: loss=0.1034215595626207\n",
      "SGD iter. 818/3599: loss=0.09684867900267122\n",
      "SGD iter. 819/3599: loss=0.10283810407856324\n",
      "SGD iter. 820/3599: loss=0.10442666871076613\n",
      "SGD iter. 821/3599: loss=0.10008570720153026\n",
      "SGD iter. 822/3599: loss=0.10697590618721452\n",
      "SGD iter. 823/3599: loss=0.10161422148463958\n",
      "SGD iter. 824/3599: loss=0.10055577356422427\n",
      "SGD iter. 825/3599: loss=0.09361759448920275\n",
      "SGD iter. 826/3599: loss=0.10321073964555187\n",
      "SGD iter. 827/3599: loss=0.09201407972037869\n",
      "SGD iter. 828/3599: loss=0.10254443955969453\n",
      "SGD iter. 829/3599: loss=0.10841208468774408\n",
      "SGD iter. 830/3599: loss=0.10104474543511122\n",
      "SGD iter. 831/3599: loss=0.10093831550401088\n",
      "SGD iter. 832/3599: loss=0.0995271823161861\n",
      "SGD iter. 833/3599: loss=0.09626053088924252\n",
      "SGD iter. 834/3599: loss=0.10124981357077585\n",
      "SGD iter. 835/3599: loss=0.10488043648027295\n",
      "SGD iter. 836/3599: loss=0.09268585620331034\n",
      "SGD iter. 837/3599: loss=0.10147156743952888\n",
      "SGD iter. 838/3599: loss=0.10325777358734174\n",
      "SGD iter. 839/3599: loss=0.09407539107891938\n",
      "SGD iter. 840/3599: loss=0.10213980380093252\n",
      "SGD iter. 841/3599: loss=0.10037264504836654\n",
      "SGD iter. 842/3599: loss=0.10176421309684697\n",
      "SGD iter. 843/3599: loss=0.09719000468236379\n",
      "SGD iter. 844/3599: loss=0.0991655881689608\n",
      "SGD iter. 845/3599: loss=0.10418749160834379\n",
      "SGD iter. 846/3599: loss=0.09512376289863989\n",
      "SGD iter. 847/3599: loss=0.10501765194982612\n",
      "SGD iter. 848/3599: loss=0.09527520541790899\n",
      "SGD iter. 849/3599: loss=0.10921267581667177\n",
      "SGD iter. 850/3599: loss=0.10729653338509004\n",
      "SGD iter. 851/3599: loss=0.09437469712092192\n",
      "SGD iter. 852/3599: loss=0.09210942614402655\n",
      "SGD iter. 853/3599: loss=0.0994511521639034\n",
      "SGD iter. 854/3599: loss=0.10245188377533476\n",
      "SGD iter. 855/3599: loss=0.09989324996438848\n",
      "SGD iter. 856/3599: loss=0.10266265622375077\n",
      "SGD iter. 857/3599: loss=0.09713485838544533\n",
      "SGD iter. 858/3599: loss=0.10418206241631356\n",
      "SGD iter. 859/3599: loss=0.08983324338572557\n",
      "SGD iter. 860/3599: loss=0.10501687282108375\n",
      "SGD iter. 861/3599: loss=0.09761534752346437\n",
      "SGD iter. 862/3599: loss=0.10708119148895269\n",
      "SGD iter. 863/3599: loss=0.1024283689331087\n",
      "SGD iter. 864/3599: loss=0.10123188227093262\n",
      "SGD iter. 865/3599: loss=0.101109432394537\n",
      "SGD iter. 866/3599: loss=0.10128832041509267\n",
      "SGD iter. 867/3599: loss=0.1040916973177711\n",
      "SGD iter. 868/3599: loss=0.09977960315064584\n",
      "SGD iter. 869/3599: loss=0.09981406977129904\n",
      "SGD iter. 870/3599: loss=0.09675730563117253\n",
      "SGD iter. 871/3599: loss=0.09808862716790331\n",
      "SGD iter. 872/3599: loss=0.10584685480169619\n",
      "SGD iter. 873/3599: loss=0.0960180416573772\n",
      "SGD iter. 874/3599: loss=0.10752491427228215\n",
      "SGD iter. 875/3599: loss=0.10209104887523673\n",
      "SGD iter. 876/3599: loss=0.09896821260609387\n",
      "SGD iter. 877/3599: loss=0.100950562491367\n",
      "SGD iter. 878/3599: loss=0.10229757389803584\n",
      "SGD iter. 879/3599: loss=0.1050320574678068\n",
      "SGD iter. 880/3599: loss=0.10424045780294054\n",
      "SGD iter. 881/3599: loss=0.10489113920173967\n",
      "SGD iter. 882/3599: loss=0.09806515711785531\n",
      "SGD iter. 883/3599: loss=0.09898611726862613\n",
      "SGD iter. 884/3599: loss=0.10446079800243524\n",
      "SGD iter. 885/3599: loss=0.10329759714814722\n",
      "SGD iter. 886/3599: loss=0.09327806165907734\n",
      "SGD iter. 887/3599: loss=0.10113471284233322\n",
      "SGD iter. 888/3599: loss=0.1054894177637013\n",
      "SGD iter. 889/3599: loss=0.10452494998168543\n",
      "SGD iter. 890/3599: loss=0.09677869805115674\n",
      "SGD iter. 891/3599: loss=0.10415606353761238\n",
      "SGD iter. 892/3599: loss=0.08641472966503365\n",
      "SGD iter. 893/3599: loss=0.09869280558197069\n",
      "SGD iter. 894/3599: loss=0.09619300415461249\n",
      "SGD iter. 895/3599: loss=0.09869714180317196\n",
      "SGD iter. 896/3599: loss=0.0978756301120448\n",
      "SGD iter. 897/3599: loss=0.09542182653718398\n",
      "SGD iter. 898/3599: loss=0.08749946236537288\n",
      "SGD iter. 899/3599: loss=0.09246732032641106\n",
      "SGD iter. 900/3599: loss=0.09843744225498624\n",
      "SGD iter. 901/3599: loss=0.09930975733859743\n",
      "SGD iter. 902/3599: loss=0.09768060600271111\n",
      "SGD iter. 903/3599: loss=0.09820649156167244\n",
      "SGD iter. 904/3599: loss=0.09948584191986458\n",
      "SGD iter. 905/3599: loss=0.09835726843287132\n",
      "SGD iter. 906/3599: loss=0.09649219242476238\n",
      "SGD iter. 907/3599: loss=0.10011363195438054\n",
      "SGD iter. 908/3599: loss=0.10261739646055931\n",
      "SGD iter. 909/3599: loss=0.10227870057357684\n",
      "SGD iter. 910/3599: loss=0.096240706236762\n",
      "SGD iter. 911/3599: loss=0.09898835799375243\n",
      "SGD iter. 912/3599: loss=0.10193500390820712\n",
      "SGD iter. 913/3599: loss=0.10514194564997927\n",
      "SGD iter. 914/3599: loss=0.09837682731534532\n",
      "SGD iter. 915/3599: loss=0.09344858169722006\n",
      "SGD iter. 916/3599: loss=0.10062938842758663\n",
      "SGD iter. 917/3599: loss=0.10785623074649711\n",
      "SGD iter. 918/3599: loss=0.09286591855613292\n",
      "SGD iter. 919/3599: loss=0.10927477438107866\n",
      "SGD iter. 920/3599: loss=0.11067180244315752\n",
      "SGD iter. 921/3599: loss=0.09328658591080809\n",
      "SGD iter. 922/3599: loss=0.0956878508345829\n",
      "SGD iter. 923/3599: loss=0.09989639908882045\n",
      "SGD iter. 924/3599: loss=0.10306076914311951\n",
      "SGD iter. 925/3599: loss=0.0961356313086478\n",
      "SGD iter. 926/3599: loss=0.09376756225377658\n",
      "SGD iter. 927/3599: loss=0.09382654547540978\n",
      "SGD iter. 928/3599: loss=0.08972180645866429\n",
      "SGD iter. 929/3599: loss=0.09877399123097978\n",
      "SGD iter. 930/3599: loss=0.10343799739224481\n",
      "SGD iter. 931/3599: loss=0.09876443762335302\n",
      "SGD iter. 932/3599: loss=0.09958056599630279\n",
      "SGD iter. 933/3599: loss=0.09804380257806866\n",
      "SGD iter. 934/3599: loss=0.0972770571361855\n",
      "SGD iter. 935/3599: loss=0.09257993182387289\n",
      "SGD iter. 936/3599: loss=0.10941994262311588\n",
      "SGD iter. 937/3599: loss=0.0972520513732961\n",
      "SGD iter. 938/3599: loss=0.09883764548164464\n",
      "SGD iter. 939/3599: loss=0.10476439097591686\n",
      "SGD iter. 940/3599: loss=0.10816973634261134\n",
      "SGD iter. 941/3599: loss=0.0993002663043144\n",
      "SGD iter. 942/3599: loss=0.09266895871197853\n",
      "SGD iter. 943/3599: loss=0.10610668537797804\n",
      "SGD iter. 944/3599: loss=0.10417240077820268\n",
      "SGD iter. 945/3599: loss=0.08479612406141017\n",
      "SGD iter. 946/3599: loss=0.1057472909589394\n",
      "SGD iter. 947/3599: loss=0.10414750248297278\n",
      "SGD iter. 948/3599: loss=0.09607158309654751\n",
      "SGD iter. 949/3599: loss=0.10203845340766197\n",
      "SGD iter. 950/3599: loss=0.10292735089336012\n",
      "SGD iter. 951/3599: loss=0.10753742376396624\n",
      "SGD iter. 952/3599: loss=0.10702969730671691\n",
      "SGD iter. 953/3599: loss=0.10303114160770568\n",
      "SGD iter. 954/3599: loss=0.09856364846452323\n",
      "SGD iter. 955/3599: loss=0.0923248313519957\n",
      "SGD iter. 956/3599: loss=0.09682857834771888\n",
      "SGD iter. 957/3599: loss=0.09742427115324206\n",
      "SGD iter. 958/3599: loss=0.10020475952783531\n",
      "SGD iter. 959/3599: loss=0.09749488644758739\n",
      "SGD iter. 960/3599: loss=0.10134599870747008\n",
      "SGD iter. 961/3599: loss=0.10906532990683845\n",
      "SGD iter. 962/3599: loss=0.10771796709053433\n",
      "SGD iter. 963/3599: loss=0.10102423877441741\n",
      "SGD iter. 964/3599: loss=0.09241003277159818\n",
      "SGD iter. 965/3599: loss=0.10127018655805684\n",
      "SGD iter. 966/3599: loss=0.09818892473013627\n",
      "SGD iter. 967/3599: loss=0.10341246031993603\n",
      "SGD iter. 968/3599: loss=0.10773871485116165\n",
      "SGD iter. 969/3599: loss=0.09873567869916205\n",
      "SGD iter. 970/3599: loss=0.11030636445054279\n",
      "SGD iter. 971/3599: loss=0.10543386752745063\n",
      "SGD iter. 972/3599: loss=0.10215863956479049\n",
      "SGD iter. 973/3599: loss=0.09967587828767796\n",
      "SGD iter. 974/3599: loss=0.09425548590792665\n",
      "SGD iter. 975/3599: loss=0.1011740966338476\n",
      "SGD iter. 976/3599: loss=0.09866234293891751\n",
      "SGD iter. 977/3599: loss=0.10615121090283633\n",
      "SGD iter. 978/3599: loss=0.09812646550157048\n",
      "SGD iter. 979/3599: loss=0.09756012364152028\n",
      "SGD iter. 980/3599: loss=0.10428568089252889\n",
      "SGD iter. 981/3599: loss=0.09805303912489582\n",
      "SGD iter. 982/3599: loss=0.09848792532888354\n",
      "SGD iter. 983/3599: loss=0.10323392996053915\n",
      "SGD iter. 984/3599: loss=0.09365281120397734\n",
      "SGD iter. 985/3599: loss=0.09693822425238874\n",
      "SGD iter. 986/3599: loss=0.09952578572564225\n",
      "SGD iter. 987/3599: loss=0.09985157430279265\n",
      "SGD iter. 988/3599: loss=0.10440022229756031\n",
      "SGD iter. 989/3599: loss=0.09792730582843855\n",
      "SGD iter. 990/3599: loss=0.09374883722404376\n",
      "SGD iter. 991/3599: loss=0.09829830343115845\n",
      "SGD iter. 992/3599: loss=0.10085747759098454\n",
      "SGD iter. 993/3599: loss=0.09932460198956022\n",
      "SGD iter. 994/3599: loss=0.09743155297385792\n",
      "SGD iter. 995/3599: loss=0.0998118649363435\n",
      "SGD iter. 996/3599: loss=0.09549446691299462\n",
      "SGD iter. 997/3599: loss=0.09837766078821869\n",
      "SGD iter. 998/3599: loss=0.09304797760980765\n",
      "SGD iter. 999/3599: loss=0.10548715452919397\n",
      "SGD iter. 1000/3599: loss=0.10257981536764024\n",
      "SGD iter. 1001/3599: loss=0.09638402644778143\n",
      "SGD iter. 1002/3599: loss=0.09433797740991531\n",
      "SGD iter. 1003/3599: loss=0.10142880962730103\n",
      "SGD iter. 1004/3599: loss=0.10360470236308836\n",
      "SGD iter. 1005/3599: loss=0.1073424803776746\n",
      "SGD iter. 1006/3599: loss=0.09998647812814951\n",
      "SGD iter. 1007/3599: loss=0.09793140274509132\n",
      "SGD iter. 1008/3599: loss=0.10219692814353781\n",
      "SGD iter. 1009/3599: loss=0.09433696841743253\n",
      "SGD iter. 1010/3599: loss=0.09328327272372101\n",
      "SGD iter. 1011/3599: loss=0.09777588630974904\n",
      "SGD iter. 1012/3599: loss=0.10551664256851855\n",
      "SGD iter. 1013/3599: loss=0.10036067988601793\n",
      "SGD iter. 1014/3599: loss=0.09941520310508534\n",
      "SGD iter. 1015/3599: loss=0.10312863211820252\n",
      "SGD iter. 1016/3599: loss=0.10442915998289046\n",
      "SGD iter. 1017/3599: loss=0.09628853007145158\n",
      "SGD iter. 1018/3599: loss=0.1089678641003349\n",
      "SGD iter. 1019/3599: loss=0.1074239607734398\n",
      "SGD iter. 1020/3599: loss=0.09540919895240788\n",
      "SGD iter. 1021/3599: loss=0.10387236112992607\n",
      "SGD iter. 1022/3599: loss=0.09991993979201468\n",
      "SGD iter. 1023/3599: loss=0.10348148278437919\n",
      "SGD iter. 1024/3599: loss=0.10196524775430693\n",
      "SGD iter. 1025/3599: loss=0.0829608907066913\n",
      "SGD iter. 1026/3599: loss=0.10143647939807086\n",
      "SGD iter. 1027/3599: loss=0.09856219671920113\n",
      "SGD iter. 1028/3599: loss=0.10312122672025198\n",
      "SGD iter. 1029/3599: loss=0.09681821391348355\n",
      "SGD iter. 1030/3599: loss=0.09388964020396723\n",
      "SGD iter. 1031/3599: loss=0.08849902605304452\n",
      "SGD iter. 1032/3599: loss=0.1050513069644686\n",
      "SGD iter. 1033/3599: loss=0.09978289410611693\n",
      "SGD iter. 1034/3599: loss=0.09220369769216466\n",
      "SGD iter. 1035/3599: loss=0.10204685969794396\n",
      "SGD iter. 1036/3599: loss=0.1016449204362046\n",
      "SGD iter. 1037/3599: loss=0.09427411249846168\n",
      "SGD iter. 1038/3599: loss=0.09813634249716424\n",
      "SGD iter. 1039/3599: loss=0.1042645755497966\n",
      "SGD iter. 1040/3599: loss=0.0897476133600372\n",
      "SGD iter. 1041/3599: loss=0.09710021549845921\n",
      "SGD iter. 1042/3599: loss=0.106399159592528\n",
      "SGD iter. 1043/3599: loss=0.10120327590177909\n",
      "SGD iter. 1044/3599: loss=0.09943195420784359\n",
      "SGD iter. 1045/3599: loss=0.0957384678106098\n",
      "SGD iter. 1046/3599: loss=0.10031345539131165\n",
      "SGD iter. 1047/3599: loss=0.08934173869164118\n",
      "SGD iter. 1048/3599: loss=0.1019952401132262\n",
      "SGD iter. 1049/3599: loss=0.09754493426018537\n",
      "SGD iter. 1050/3599: loss=0.09074099493808194\n",
      "SGD iter. 1051/3599: loss=0.09848968328452312\n",
      "SGD iter. 1052/3599: loss=0.11064688996631057\n",
      "SGD iter. 1053/3599: loss=0.09765366771173047\n",
      "SGD iter. 1054/3599: loss=0.10495397860836778\n",
      "SGD iter. 1055/3599: loss=0.10477753252498143\n",
      "SGD iter. 1056/3599: loss=0.10091290639869781\n",
      "SGD iter. 1057/3599: loss=0.09598725890687125\n",
      "SGD iter. 1058/3599: loss=0.10301794335665965\n",
      "SGD iter. 1059/3599: loss=0.09452141415645073\n",
      "SGD iter. 1060/3599: loss=0.10490881477823871\n",
      "SGD iter. 1061/3599: loss=0.09719013428586062\n",
      "SGD iter. 1062/3599: loss=0.09632749891513294\n",
      "SGD iter. 1063/3599: loss=0.101054489594023\n",
      "SGD iter. 1064/3599: loss=0.10159617987830244\n",
      "SGD iter. 1065/3599: loss=0.08571276606486786\n",
      "SGD iter. 1066/3599: loss=0.09625274460805656\n",
      "SGD iter. 1067/3599: loss=0.10217406233555967\n",
      "SGD iter. 1068/3599: loss=0.09351651062567089\n",
      "SGD iter. 1069/3599: loss=0.09735764639612834\n",
      "SGD iter. 1070/3599: loss=0.10148767718898095\n",
      "SGD iter. 1071/3599: loss=0.10272740348000135\n",
      "SGD iter. 1072/3599: loss=0.09668077500130215\n",
      "SGD iter. 1073/3599: loss=0.10167838256399303\n",
      "SGD iter. 1074/3599: loss=0.09726310921357934\n",
      "SGD iter. 1075/3599: loss=0.09319035769764981\n",
      "SGD iter. 1076/3599: loss=0.10512863272295217\n",
      "SGD iter. 1077/3599: loss=0.09132569940528568\n",
      "SGD iter. 1078/3599: loss=0.10203318594178072\n",
      "SGD iter. 1079/3599: loss=0.10302050664710063\n",
      "SGD iter. 1080/3599: loss=0.09929149406280911\n",
      "SGD iter. 1081/3599: loss=0.09756649508545114\n",
      "SGD iter. 1082/3599: loss=0.10724050014657904\n",
      "SGD iter. 1083/3599: loss=0.08964405817400983\n",
      "SGD iter. 1084/3599: loss=0.09552346157029368\n",
      "SGD iter. 1085/3599: loss=0.09381676572556469\n",
      "SGD iter. 1086/3599: loss=0.10969288896875473\n",
      "SGD iter. 1087/3599: loss=0.10183941686253264\n",
      "SGD iter. 1088/3599: loss=0.09697838015828528\n",
      "SGD iter. 1089/3599: loss=0.0964286598519364\n",
      "SGD iter. 1090/3599: loss=0.10623660482187874\n",
      "SGD iter. 1091/3599: loss=0.10557035434168335\n",
      "SGD iter. 1092/3599: loss=0.1019411607033851\n",
      "SGD iter. 1093/3599: loss=0.10167899201829053\n",
      "SGD iter. 1094/3599: loss=0.09968226890287836\n",
      "SGD iter. 1095/3599: loss=0.09319572202929287\n",
      "SGD iter. 1096/3599: loss=0.09127256661646241\n",
      "SGD iter. 1097/3599: loss=0.106985512778333\n",
      "SGD iter. 1098/3599: loss=0.10541364886748954\n",
      "SGD iter. 1099/3599: loss=0.09059826878613347\n",
      "SGD iter. 1100/3599: loss=0.10835939340588571\n",
      "SGD iter. 1101/3599: loss=0.08815390643729099\n",
      "SGD iter. 1102/3599: loss=0.10354205585409826\n",
      "SGD iter. 1103/3599: loss=0.10341599175192469\n",
      "SGD iter. 1104/3599: loss=0.0987852292856029\n",
      "SGD iter. 1105/3599: loss=0.09532345534637673\n",
      "SGD iter. 1106/3599: loss=0.09775498211984571\n",
      "SGD iter. 1107/3599: loss=0.09890893317007785\n",
      "SGD iter. 1108/3599: loss=0.10228045618632431\n",
      "SGD iter. 1109/3599: loss=0.09704538151240759\n",
      "SGD iter. 1110/3599: loss=0.09752375759507774\n",
      "SGD iter. 1111/3599: loss=0.0995619555128277\n",
      "SGD iter. 1112/3599: loss=0.08461845423485878\n",
      "SGD iter. 1113/3599: loss=0.09872664879477162\n",
      "SGD iter. 1114/3599: loss=0.09289446432554625\n",
      "SGD iter. 1115/3599: loss=0.10061451186862236\n",
      "SGD iter. 1116/3599: loss=0.09537601725654568\n",
      "SGD iter. 1117/3599: loss=0.10557866524117553\n",
      "SGD iter. 1118/3599: loss=0.08909741975813915\n",
      "SGD iter. 1119/3599: loss=0.09459762607845526\n",
      "SGD iter. 1120/3599: loss=0.10158644496428784\n",
      "SGD iter. 1121/3599: loss=0.09251728227074904\n",
      "SGD iter. 1122/3599: loss=0.09954461049376628\n",
      "SGD iter. 1123/3599: loss=0.10164969646231334\n",
      "SGD iter. 1124/3599: loss=0.09477637188619821\n",
      "SGD iter. 1125/3599: loss=0.10467131475899466\n",
      "SGD iter. 1126/3599: loss=0.09982918887967476\n",
      "SGD iter. 1127/3599: loss=0.09295532996625526\n",
      "SGD iter. 1128/3599: loss=0.08570187292102038\n",
      "SGD iter. 1129/3599: loss=0.08832093834640106\n",
      "SGD iter. 1130/3599: loss=0.10145914421109253\n",
      "SGD iter. 1131/3599: loss=0.09516248002349814\n",
      "SGD iter. 1132/3599: loss=0.08741651002821396\n",
      "SGD iter. 1133/3599: loss=0.09802293855873051\n",
      "SGD iter. 1134/3599: loss=0.09705739416873883\n",
      "SGD iter. 1135/3599: loss=0.09176596280432092\n",
      "SGD iter. 1136/3599: loss=0.088872532535469\n",
      "SGD iter. 1137/3599: loss=0.09394476599749318\n",
      "SGD iter. 1138/3599: loss=0.09490035382980913\n",
      "SGD iter. 1139/3599: loss=0.0898039493043283\n",
      "SGD iter. 1140/3599: loss=0.09146089402193469\n",
      "SGD iter. 1141/3599: loss=0.09733271219403564\n",
      "SGD iter. 1142/3599: loss=0.09842743767465381\n",
      "SGD iter. 1143/3599: loss=0.0957941240344365\n",
      "SGD iter. 1144/3599: loss=0.09186460015345489\n",
      "SGD iter. 1145/3599: loss=0.09792060428723617\n",
      "SGD iter. 1146/3599: loss=0.0999258818534754\n",
      "SGD iter. 1147/3599: loss=0.10038866877032629\n",
      "SGD iter. 1148/3599: loss=0.09832320572317543\n",
      "SGD iter. 1149/3599: loss=0.09645696251636426\n",
      "SGD iter. 1150/3599: loss=0.10094827200288485\n",
      "SGD iter. 1151/3599: loss=0.09139031836843772\n",
      "SGD iter. 1152/3599: loss=0.09020433316102824\n",
      "SGD iter. 1153/3599: loss=0.10552140399126884\n",
      "SGD iter. 1154/3599: loss=0.10039765041023163\n",
      "SGD iter. 1155/3599: loss=0.08967726452092105\n",
      "SGD iter. 1156/3599: loss=0.09252548797539542\n",
      "SGD iter. 1157/3599: loss=0.09650476411777881\n",
      "SGD iter. 1158/3599: loss=0.10181878900277265\n",
      "SGD iter. 1159/3599: loss=0.10400513079379231\n",
      "SGD iter. 1160/3599: loss=0.09513232540728417\n",
      "SGD iter. 1161/3599: loss=0.09254953217624286\n",
      "SGD iter. 1162/3599: loss=0.09305801580384142\n",
      "SGD iter. 1163/3599: loss=0.09878153645044226\n",
      "SGD iter. 1164/3599: loss=0.0970349233569445\n",
      "SGD iter. 1165/3599: loss=0.10304586594351166\n",
      "SGD iter. 1166/3599: loss=0.10255354578195339\n",
      "SGD iter. 1167/3599: loss=0.1043697990840273\n",
      "SGD iter. 1168/3599: loss=0.09100160539125757\n",
      "SGD iter. 1169/3599: loss=0.09884650072882534\n",
      "SGD iter. 1170/3599: loss=0.0967057982628078\n",
      "SGD iter. 1171/3599: loss=0.08792205959891639\n",
      "SGD iter. 1172/3599: loss=0.11212674697552825\n",
      "SGD iter. 1173/3599: loss=0.09099111577468788\n",
      "SGD iter. 1174/3599: loss=0.09645753719215243\n",
      "SGD iter. 1175/3599: loss=0.09254653534828025\n",
      "SGD iter. 1176/3599: loss=0.09778523607559168\n",
      "SGD iter. 1177/3599: loss=0.09563276475841796\n",
      "SGD iter. 1178/3599: loss=0.09409322880731513\n",
      "SGD iter. 1179/3599: loss=0.09616509870897141\n",
      "SGD iter. 1180/3599: loss=0.0901181957771286\n",
      "SGD iter. 1181/3599: loss=0.1064951092696908\n",
      "SGD iter. 1182/3599: loss=0.09809453474619786\n",
      "SGD iter. 1183/3599: loss=0.09216134667360419\n",
      "SGD iter. 1184/3599: loss=0.09590894361316452\n",
      "SGD iter. 1185/3599: loss=0.10082126107307297\n",
      "SGD iter. 1186/3599: loss=0.0989019395434211\n",
      "SGD iter. 1187/3599: loss=0.09753384955832708\n",
      "SGD iter. 1188/3599: loss=0.09743939351939396\n",
      "SGD iter. 1189/3599: loss=0.09805177427814556\n",
      "SGD iter. 1190/3599: loss=0.10125275729986627\n",
      "SGD iter. 1191/3599: loss=0.1010414823648739\n",
      "SGD iter. 1192/3599: loss=0.1015775598573056\n",
      "SGD iter. 1193/3599: loss=0.1009997872271719\n",
      "SGD iter. 1194/3599: loss=0.0883122800481749\n",
      "SGD iter. 1195/3599: loss=0.09961847058484444\n",
      "SGD iter. 1196/3599: loss=0.09046946213248627\n",
      "SGD iter. 1197/3599: loss=0.09809106902942072\n",
      "SGD iter. 1198/3599: loss=0.0932339658421735\n",
      "SGD iter. 1199/3599: loss=0.09180537896987363\n",
      "SGD iter. 1200/3599: loss=0.09888099359974295\n",
      "SGD iter. 1201/3599: loss=0.09618496875716917\n",
      "SGD iter. 1202/3599: loss=0.09559782024239591\n",
      "SGD iter. 1203/3599: loss=0.10321715952294674\n",
      "SGD iter. 1204/3599: loss=0.09746570370552644\n",
      "SGD iter. 1205/3599: loss=0.09365976627666137\n",
      "SGD iter. 1206/3599: loss=0.10453598514279727\n",
      "SGD iter. 1207/3599: loss=0.10131353955439007\n",
      "SGD iter. 1208/3599: loss=0.09695101992349958\n",
      "SGD iter. 1209/3599: loss=0.08860900323129675\n",
      "SGD iter. 1210/3599: loss=0.10119766548738318\n",
      "SGD iter. 1211/3599: loss=0.08378002614067666\n",
      "SGD iter. 1212/3599: loss=0.09127388381044263\n",
      "SGD iter. 1213/3599: loss=0.0885186377827325\n",
      "SGD iter. 1214/3599: loss=0.0914909939703057\n",
      "SGD iter. 1215/3599: loss=0.0998093710944927\n",
      "SGD iter. 1216/3599: loss=0.10283625426660437\n",
      "SGD iter. 1217/3599: loss=0.10477621705878559\n",
      "SGD iter. 1218/3599: loss=0.09861706671555566\n",
      "SGD iter. 1219/3599: loss=0.09041402068515757\n",
      "SGD iter. 1220/3599: loss=0.0973885272955887\n",
      "SGD iter. 1221/3599: loss=0.10125647035956967\n",
      "SGD iter. 1222/3599: loss=0.09610426408684991\n",
      "SGD iter. 1223/3599: loss=0.1023038232625022\n",
      "SGD iter. 1224/3599: loss=0.10000079250683092\n",
      "SGD iter. 1225/3599: loss=0.10058008047790011\n",
      "SGD iter. 1226/3599: loss=0.10104557276445694\n",
      "SGD iter. 1227/3599: loss=0.10207212446085265\n",
      "SGD iter. 1228/3599: loss=0.10039023126673263\n",
      "SGD iter. 1229/3599: loss=0.09117957838348664\n",
      "SGD iter. 1230/3599: loss=0.11055730373807998\n",
      "SGD iter. 1231/3599: loss=0.09677741494853355\n",
      "SGD iter. 1232/3599: loss=0.095856396794277\n",
      "SGD iter. 1233/3599: loss=0.09334853749283895\n",
      "SGD iter. 1234/3599: loss=0.0945098017893039\n",
      "SGD iter. 1235/3599: loss=0.09632676294508909\n",
      "SGD iter. 1236/3599: loss=0.08572557954859601\n",
      "SGD iter. 1237/3599: loss=0.0906168897632057\n",
      "SGD iter. 1238/3599: loss=0.09970983025385599\n",
      "SGD iter. 1239/3599: loss=0.10072172507749579\n",
      "SGD iter. 1240/3599: loss=0.10125222982190601\n",
      "SGD iter. 1241/3599: loss=0.09400488621924641\n",
      "SGD iter. 1242/3599: loss=0.09500489110504579\n",
      "SGD iter. 1243/3599: loss=0.10129746020536454\n",
      "SGD iter. 1244/3599: loss=0.10086576297641511\n",
      "SGD iter. 1245/3599: loss=0.09072348094046477\n",
      "SGD iter. 1246/3599: loss=0.10459345527662264\n",
      "SGD iter. 1247/3599: loss=0.1007644341233153\n",
      "SGD iter. 1248/3599: loss=0.09442113432113379\n",
      "SGD iter. 1249/3599: loss=0.08584182970477362\n",
      "SGD iter. 1250/3599: loss=0.092917496021135\n",
      "SGD iter. 1251/3599: loss=0.09596945591328926\n",
      "SGD iter. 1252/3599: loss=0.08551033539448069\n",
      "SGD iter. 1253/3599: loss=0.0921729868782237\n",
      "SGD iter. 1254/3599: loss=0.09515009450553448\n",
      "SGD iter. 1255/3599: loss=0.09739107869709329\n",
      "SGD iter. 1256/3599: loss=0.0992754628671809\n",
      "SGD iter. 1257/3599: loss=0.09864320061981849\n",
      "SGD iter. 1258/3599: loss=0.09265551791331995\n",
      "SGD iter. 1259/3599: loss=0.09587060123343517\n",
      "SGD iter. 1260/3599: loss=0.09264602009776646\n",
      "SGD iter. 1261/3599: loss=0.09708365099494662\n",
      "SGD iter. 1262/3599: loss=0.10334271205620259\n",
      "SGD iter. 1263/3599: loss=0.0972623067617584\n",
      "SGD iter. 1264/3599: loss=0.09724028768149211\n",
      "SGD iter. 1265/3599: loss=0.10045143255268568\n",
      "SGD iter. 1266/3599: loss=0.0954840865982764\n",
      "SGD iter. 1267/3599: loss=0.09196092930125868\n",
      "SGD iter. 1268/3599: loss=0.09976904289151192\n",
      "SGD iter. 1269/3599: loss=0.08545951307776663\n",
      "SGD iter. 1270/3599: loss=0.10182517909027296\n",
      "SGD iter. 1271/3599: loss=0.09801588659267867\n",
      "SGD iter. 1272/3599: loss=0.08832649890661362\n",
      "SGD iter. 1273/3599: loss=0.09681142944036161\n",
      "SGD iter. 1274/3599: loss=0.09614848946178034\n",
      "SGD iter. 1275/3599: loss=0.10162733981453384\n",
      "SGD iter. 1276/3599: loss=0.09517164802062957\n",
      "SGD iter. 1277/3599: loss=0.09030205979286055\n",
      "SGD iter. 1278/3599: loss=0.1107866835999962\n",
      "SGD iter. 1279/3599: loss=0.08635873093665437\n",
      "SGD iter. 1280/3599: loss=0.10405081844700735\n",
      "SGD iter. 1281/3599: loss=0.09784319236371157\n",
      "SGD iter. 1282/3599: loss=0.09668003076147721\n",
      "SGD iter. 1283/3599: loss=0.10192862875589369\n",
      "SGD iter. 1284/3599: loss=0.10133140706202123\n",
      "SGD iter. 1285/3599: loss=0.10220845011940846\n",
      "SGD iter. 1286/3599: loss=0.10276652591937727\n",
      "SGD iter. 1287/3599: loss=0.09702167718562675\n",
      "SGD iter. 1288/3599: loss=0.09480879967823358\n",
      "SGD iter. 1289/3599: loss=0.09443916655588441\n",
      "SGD iter. 1290/3599: loss=0.10546217947178199\n",
      "SGD iter. 1291/3599: loss=0.10015919911443417\n",
      "SGD iter. 1292/3599: loss=0.1077237211955589\n",
      "SGD iter. 1293/3599: loss=0.09794691066001657\n",
      "SGD iter. 1294/3599: loss=0.09725896452606418\n",
      "SGD iter. 1295/3599: loss=0.09623686806620899\n",
      "SGD iter. 1296/3599: loss=0.10321657734159308\n",
      "SGD iter. 1297/3599: loss=0.09873948128088612\n",
      "SGD iter. 1298/3599: loss=0.09107068713022594\n",
      "SGD iter. 1299/3599: loss=0.10034684239030432\n",
      "SGD iter. 1300/3599: loss=0.10389730929141056\n",
      "SGD iter. 1301/3599: loss=0.10403482923480419\n",
      "SGD iter. 1302/3599: loss=0.09051397386322621\n",
      "SGD iter. 1303/3599: loss=0.09227975036999451\n",
      "SGD iter. 1304/3599: loss=0.09303625977504347\n",
      "SGD iter. 1305/3599: loss=0.09764300548951935\n",
      "SGD iter. 1306/3599: loss=0.09210235558014876\n",
      "SGD iter. 1307/3599: loss=0.09566942424159014\n",
      "SGD iter. 1308/3599: loss=0.10323329707898554\n",
      "SGD iter. 1309/3599: loss=0.1015243979036933\n",
      "SGD iter. 1310/3599: loss=0.09434722143213128\n",
      "SGD iter. 1311/3599: loss=0.09036577994105341\n",
      "SGD iter. 1312/3599: loss=0.1026971267683873\n",
      "SGD iter. 1313/3599: loss=0.09433148510945882\n",
      "SGD iter. 1314/3599: loss=0.09698318781176657\n",
      "SGD iter. 1315/3599: loss=0.08709768508163689\n",
      "SGD iter. 1316/3599: loss=0.09976535006181547\n",
      "SGD iter. 1317/3599: loss=0.09953074096327406\n",
      "SGD iter. 1318/3599: loss=0.10090217365065203\n",
      "SGD iter. 1319/3599: loss=0.09032012036602756\n",
      "SGD iter. 1320/3599: loss=0.09657283135909464\n",
      "SGD iter. 1321/3599: loss=0.09552271933827623\n",
      "SGD iter. 1322/3599: loss=0.09828435185671286\n",
      "SGD iter. 1323/3599: loss=0.09893105187384141\n",
      "SGD iter. 1324/3599: loss=0.09382005185558953\n",
      "SGD iter. 1325/3599: loss=0.08807653530012195\n",
      "SGD iter. 1326/3599: loss=0.09901321333843986\n",
      "SGD iter. 1327/3599: loss=0.09813152040171619\n",
      "SGD iter. 1328/3599: loss=0.10178031085184719\n",
      "SGD iter. 1329/3599: loss=0.10037972726634511\n",
      "SGD iter. 1330/3599: loss=0.10190319409428521\n",
      "SGD iter. 1331/3599: loss=0.08928094640194831\n",
      "SGD iter. 1332/3599: loss=0.10043582253002711\n",
      "SGD iter. 1333/3599: loss=0.09171233382055742\n",
      "SGD iter. 1334/3599: loss=0.0968966197286596\n",
      "SGD iter. 1335/3599: loss=0.08737725764661797\n",
      "SGD iter. 1336/3599: loss=0.10248325343725023\n",
      "SGD iter. 1337/3599: loss=0.09898839773488045\n",
      "SGD iter. 1338/3599: loss=0.09709155660120189\n",
      "SGD iter. 1339/3599: loss=0.09349981897158754\n",
      "SGD iter. 1340/3599: loss=0.09169891431029868\n",
      "SGD iter. 1341/3599: loss=0.08944023690162745\n",
      "SGD iter. 1342/3599: loss=0.11481259256578627\n",
      "SGD iter. 1343/3599: loss=0.10389858297955357\n",
      "SGD iter. 1344/3599: loss=0.10569231301252549\n",
      "SGD iter. 1345/3599: loss=0.0973021643736577\n",
      "SGD iter. 1346/3599: loss=0.09934038699029134\n",
      "SGD iter. 1347/3599: loss=0.09662954931805003\n",
      "SGD iter. 1348/3599: loss=0.10210747491374306\n",
      "SGD iter. 1349/3599: loss=0.1051006739695096\n",
      "SGD iter. 1350/3599: loss=0.097654970111597\n",
      "SGD iter. 1351/3599: loss=0.08672274737385\n",
      "SGD iter. 1352/3599: loss=0.09439332815443743\n",
      "SGD iter. 1353/3599: loss=0.0904654642612675\n",
      "SGD iter. 1354/3599: loss=0.0935375015390955\n",
      "SGD iter. 1355/3599: loss=0.09804594923584775\n",
      "SGD iter. 1356/3599: loss=0.09197921421814659\n",
      "SGD iter. 1357/3599: loss=0.08841118269299506\n",
      "SGD iter. 1358/3599: loss=0.0998666866851666\n",
      "SGD iter. 1359/3599: loss=0.09580910756755529\n",
      "SGD iter. 1360/3599: loss=0.09458749251885493\n",
      "SGD iter. 1361/3599: loss=0.09831273954758901\n",
      "SGD iter. 1362/3599: loss=0.10240014966332789\n",
      "SGD iter. 1363/3599: loss=0.09252343207337806\n",
      "SGD iter. 1364/3599: loss=0.09631496496247913\n",
      "SGD iter. 1365/3599: loss=0.08582798751468651\n",
      "SGD iter. 1366/3599: loss=0.10063823219410473\n",
      "SGD iter. 1367/3599: loss=0.09628078372401222\n",
      "SGD iter. 1368/3599: loss=0.09800696257375263\n",
      "SGD iter. 1369/3599: loss=0.09583661990027464\n",
      "SGD iter. 1370/3599: loss=0.10219292321380996\n",
      "SGD iter. 1371/3599: loss=0.09503299717258915\n",
      "SGD iter. 1372/3599: loss=0.09287619534700851\n",
      "SGD iter. 1373/3599: loss=0.09810174954264282\n",
      "SGD iter. 1374/3599: loss=0.10083102230913336\n",
      "SGD iter. 1375/3599: loss=0.10194584674095879\n",
      "SGD iter. 1376/3599: loss=0.08109619979421424\n",
      "SGD iter. 1377/3599: loss=0.09865375025741399\n",
      "SGD iter. 1378/3599: loss=0.0852565789432656\n",
      "SGD iter. 1379/3599: loss=0.10078276439134679\n",
      "SGD iter. 1380/3599: loss=0.10084992168951507\n",
      "SGD iter. 1381/3599: loss=0.10763765457309422\n",
      "SGD iter. 1382/3599: loss=0.09222724424000828\n",
      "SGD iter. 1383/3599: loss=0.08879950108547935\n",
      "SGD iter. 1384/3599: loss=0.08511250592997349\n",
      "SGD iter. 1385/3599: loss=0.09468479697158515\n",
      "SGD iter. 1386/3599: loss=0.09581217529643267\n",
      "SGD iter. 1387/3599: loss=0.09583339401473626\n",
      "SGD iter. 1388/3599: loss=0.09652438833929641\n",
      "SGD iter. 1389/3599: loss=0.09605534851352332\n",
      "SGD iter. 1390/3599: loss=0.09628587388259728\n",
      "SGD iter. 1391/3599: loss=0.09799862585704769\n",
      "SGD iter. 1392/3599: loss=0.09345944670371609\n",
      "SGD iter. 1393/3599: loss=0.10007166410817184\n",
      "SGD iter. 1394/3599: loss=0.0942851224845351\n",
      "SGD iter. 1395/3599: loss=0.10183185308488582\n",
      "SGD iter. 1396/3599: loss=0.09500671397581908\n",
      "SGD iter. 1397/3599: loss=0.09306433448076083\n",
      "SGD iter. 1398/3599: loss=0.10205176911706812\n",
      "SGD iter. 1399/3599: loss=0.09736208023502772\n",
      "SGD iter. 1400/3599: loss=0.09407527120623738\n",
      "SGD iter. 1401/3599: loss=0.09292516682153909\n",
      "SGD iter. 1402/3599: loss=0.09717977419237932\n",
      "SGD iter. 1403/3599: loss=0.09975621714520705\n",
      "SGD iter. 1404/3599: loss=0.09483359835422228\n",
      "SGD iter. 1405/3599: loss=0.09459852121987536\n",
      "SGD iter. 1406/3599: loss=0.10225215840588395\n",
      "SGD iter. 1407/3599: loss=0.09299944556745386\n",
      "SGD iter. 1408/3599: loss=0.09360009772978824\n",
      "SGD iter. 1409/3599: loss=0.08662062482318758\n",
      "SGD iter. 1410/3599: loss=0.0919111851818018\n",
      "SGD iter. 1411/3599: loss=0.10021083711812084\n",
      "SGD iter. 1412/3599: loss=0.1000394212063095\n",
      "SGD iter. 1413/3599: loss=0.09656917392702609\n",
      "SGD iter. 1414/3599: loss=0.09875159659384611\n",
      "SGD iter. 1415/3599: loss=0.09815516161042467\n",
      "SGD iter. 1416/3599: loss=0.09785504361061367\n",
      "SGD iter. 1417/3599: loss=0.09142059713564965\n",
      "SGD iter. 1418/3599: loss=0.09883231952868797\n",
      "SGD iter. 1419/3599: loss=0.09999637912337747\n",
      "SGD iter. 1420/3599: loss=0.08356177089719553\n",
      "SGD iter. 1421/3599: loss=0.09849954379643878\n",
      "SGD iter. 1422/3599: loss=0.09659909767463995\n",
      "SGD iter. 1423/3599: loss=0.09494825320441477\n",
      "SGD iter. 1424/3599: loss=0.1013615748983255\n",
      "SGD iter. 1425/3599: loss=0.0921694724190109\n",
      "SGD iter. 1426/3599: loss=0.1026626853967696\n",
      "SGD iter. 1427/3599: loss=0.09668682155497858\n",
      "SGD iter. 1428/3599: loss=0.0979234979141925\n",
      "SGD iter. 1429/3599: loss=0.101902242143972\n",
      "SGD iter. 1430/3599: loss=0.1045054461066118\n",
      "SGD iter. 1431/3599: loss=0.09441863579197822\n",
      "SGD iter. 1432/3599: loss=0.0962743499226176\n",
      "SGD iter. 1433/3599: loss=0.09211890684764291\n",
      "SGD iter. 1434/3599: loss=0.1012436243576541\n",
      "SGD iter. 1435/3599: loss=0.09998020622170178\n",
      "SGD iter. 1436/3599: loss=0.10483948352238237\n",
      "SGD iter. 1437/3599: loss=0.10462102686816449\n",
      "SGD iter. 1438/3599: loss=0.09227276935192912\n",
      "SGD iter. 1439/3599: loss=0.08771550436919202\n",
      "SGD iter. 1440/3599: loss=0.09459653416688008\n",
      "SGD iter. 1441/3599: loss=0.09426616193620382\n",
      "SGD iter. 1442/3599: loss=0.09259584583113466\n",
      "SGD iter. 1443/3599: loss=0.09331468906269827\n",
      "SGD iter. 1444/3599: loss=0.09092480948559309\n",
      "SGD iter. 1445/3599: loss=0.09299110719759428\n",
      "SGD iter. 1446/3599: loss=0.09495574997258921\n",
      "SGD iter. 1447/3599: loss=0.09277320790442777\n",
      "SGD iter. 1448/3599: loss=0.09356998680823661\n",
      "SGD iter. 1449/3599: loss=0.08804607728433654\n",
      "SGD iter. 1450/3599: loss=0.0795693405177687\n",
      "SGD iter. 1451/3599: loss=0.09958295455527266\n",
      "SGD iter. 1452/3599: loss=0.10672898491285716\n",
      "SGD iter. 1453/3599: loss=0.09084251245160982\n",
      "SGD iter. 1454/3599: loss=0.09399481165181177\n",
      "SGD iter. 1455/3599: loss=0.09838464766413241\n",
      "SGD iter. 1456/3599: loss=0.10324138836262858\n",
      "SGD iter. 1457/3599: loss=0.09794228235620087\n",
      "SGD iter. 1458/3599: loss=0.09012244242108211\n",
      "SGD iter. 1459/3599: loss=0.10464403849268826\n",
      "SGD iter. 1460/3599: loss=0.09567144402319983\n",
      "SGD iter. 1461/3599: loss=0.09511712470731139\n",
      "SGD iter. 1462/3599: loss=0.09440306640805453\n",
      "SGD iter. 1463/3599: loss=0.1042078129308667\n",
      "SGD iter. 1464/3599: loss=0.09937350325708103\n",
      "SGD iter. 1465/3599: loss=0.09828958477122202\n",
      "SGD iter. 1466/3599: loss=0.08373929462488378\n",
      "SGD iter. 1467/3599: loss=0.09247205761728391\n",
      "SGD iter. 1468/3599: loss=0.09287101522483812\n",
      "SGD iter. 1469/3599: loss=0.08996233076574983\n",
      "SGD iter. 1470/3599: loss=0.10168157997863028\n",
      "SGD iter. 1471/3599: loss=0.0890817685614771\n",
      "SGD iter. 1472/3599: loss=0.09489477020477544\n",
      "SGD iter. 1473/3599: loss=0.09418728918594457\n",
      "SGD iter. 1474/3599: loss=0.10101512739423987\n",
      "SGD iter. 1475/3599: loss=0.09493732497557547\n",
      "SGD iter. 1476/3599: loss=0.09984736613904521\n",
      "SGD iter. 1477/3599: loss=0.09540629228161487\n",
      "SGD iter. 1478/3599: loss=0.09998586552039304\n",
      "SGD iter. 1479/3599: loss=0.09160437800085426\n",
      "SGD iter. 1480/3599: loss=0.09270745020871345\n",
      "SGD iter. 1481/3599: loss=0.0906896181737891\n",
      "SGD iter. 1482/3599: loss=0.08536213377092339\n",
      "SGD iter. 1483/3599: loss=0.10407617989523521\n",
      "SGD iter. 1484/3599: loss=0.0945117429565218\n",
      "SGD iter. 1485/3599: loss=0.0852109119229408\n",
      "SGD iter. 1486/3599: loss=0.09983917681869042\n",
      "SGD iter. 1487/3599: loss=0.08809900665974907\n",
      "SGD iter. 1488/3599: loss=0.08556985370508104\n",
      "SGD iter. 1489/3599: loss=0.09620528262722951\n",
      "SGD iter. 1490/3599: loss=0.09771985903525897\n",
      "SGD iter. 1491/3599: loss=0.1011817934624005\n",
      "SGD iter. 1492/3599: loss=0.09629880473624366\n",
      "SGD iter. 1493/3599: loss=0.09740842695834773\n",
      "SGD iter. 1494/3599: loss=0.09717369467114943\n",
      "SGD iter. 1495/3599: loss=0.09354281165771454\n",
      "SGD iter. 1496/3599: loss=0.09974922201607603\n",
      "SGD iter. 1497/3599: loss=0.09403677539105948\n",
      "SGD iter. 1498/3599: loss=0.09364809628585584\n",
      "SGD iter. 1499/3599: loss=0.09533594793707606\n",
      "SGD iter. 1500/3599: loss=0.09190086449537498\n",
      "SGD iter. 1501/3599: loss=0.08734265278105292\n",
      "SGD iter. 1502/3599: loss=0.0886561532479431\n",
      "SGD iter. 1503/3599: loss=0.09127200695995122\n",
      "SGD iter. 1504/3599: loss=0.10085612953135525\n",
      "SGD iter. 1505/3599: loss=0.0979617296469214\n",
      "SGD iter. 1506/3599: loss=0.09843259550477199\n",
      "SGD iter. 1507/3599: loss=0.09257649502686774\n",
      "SGD iter. 1508/3599: loss=0.09577062402795125\n",
      "SGD iter. 1509/3599: loss=0.09378337002947561\n",
      "SGD iter. 1510/3599: loss=0.09497277772940843\n",
      "SGD iter. 1511/3599: loss=0.09316657951116715\n",
      "SGD iter. 1512/3599: loss=0.08872280963946919\n",
      "SGD iter. 1513/3599: loss=0.09315715240739819\n",
      "SGD iter. 1514/3599: loss=0.09536397617245645\n",
      "SGD iter. 1515/3599: loss=0.100743793186262\n",
      "SGD iter. 1516/3599: loss=0.09883329725174217\n",
      "SGD iter. 1517/3599: loss=0.09763719100613612\n",
      "SGD iter. 1518/3599: loss=0.09872401689377888\n",
      "SGD iter. 1519/3599: loss=0.09295172110125377\n",
      "SGD iter. 1520/3599: loss=0.0886651092639861\n",
      "SGD iter. 1521/3599: loss=0.07370722955855742\n",
      "SGD iter. 1522/3599: loss=0.09299953041523332\n",
      "SGD iter. 1523/3599: loss=0.09050212092812873\n",
      "SGD iter. 1524/3599: loss=0.0985046097973569\n",
      "SGD iter. 1525/3599: loss=0.09235937787512928\n",
      "SGD iter. 1526/3599: loss=0.0933363285461945\n",
      "SGD iter. 1527/3599: loss=0.09569143655539158\n",
      "SGD iter. 1528/3599: loss=0.0912419596495737\n",
      "SGD iter. 1529/3599: loss=0.09761325398735499\n",
      "SGD iter. 1530/3599: loss=0.0908681586610513\n",
      "SGD iter. 1531/3599: loss=0.09761338267363313\n",
      "SGD iter. 1532/3599: loss=0.10160471386024925\n",
      "SGD iter. 1533/3599: loss=0.10191795962789915\n",
      "SGD iter. 1534/3599: loss=0.09261722833367259\n",
      "SGD iter. 1535/3599: loss=0.09739326874415705\n",
      "SGD iter. 1536/3599: loss=0.09638076380002192\n",
      "SGD iter. 1537/3599: loss=0.09510029411440615\n",
      "SGD iter. 1538/3599: loss=0.09030539679286761\n",
      "SGD iter. 1539/3599: loss=0.09867647605805827\n",
      "SGD iter. 1540/3599: loss=0.10331571393284304\n",
      "SGD iter. 1541/3599: loss=0.09615490159878216\n",
      "SGD iter. 1542/3599: loss=0.09229113690495877\n",
      "SGD iter. 1543/3599: loss=0.08871481561275214\n",
      "SGD iter. 1544/3599: loss=0.09504542156054349\n",
      "SGD iter. 1545/3599: loss=0.09713589478443005\n",
      "SGD iter. 1546/3599: loss=0.09946549469289942\n",
      "SGD iter. 1547/3599: loss=0.08942668835412096\n",
      "SGD iter. 1548/3599: loss=0.08771558983759946\n",
      "SGD iter. 1549/3599: loss=0.09744652009809937\n",
      "SGD iter. 1550/3599: loss=0.09532044579573445\n",
      "SGD iter. 1551/3599: loss=0.09506265277095458\n",
      "SGD iter. 1552/3599: loss=0.08946247732203383\n",
      "SGD iter. 1553/3599: loss=0.09747825500738458\n",
      "SGD iter. 1554/3599: loss=0.0998436215479136\n",
      "SGD iter. 1555/3599: loss=0.09009351525125275\n",
      "SGD iter. 1556/3599: loss=0.09439371280151848\n",
      "SGD iter. 1557/3599: loss=0.09595726747916314\n",
      "SGD iter. 1558/3599: loss=0.09952384843097281\n",
      "SGD iter. 1559/3599: loss=0.09002369535775914\n",
      "SGD iter. 1560/3599: loss=0.09113571583742384\n",
      "SGD iter. 1561/3599: loss=0.09760781736993729\n",
      "SGD iter. 1562/3599: loss=0.0998810768025416\n",
      "SGD iter. 1563/3599: loss=0.08448165648234968\n",
      "SGD iter. 1564/3599: loss=0.09589913025606431\n",
      "SGD iter. 1565/3599: loss=0.10135170798355653\n",
      "SGD iter. 1566/3599: loss=0.09561434203793115\n",
      "SGD iter. 1567/3599: loss=0.09307256756804792\n",
      "SGD iter. 1568/3599: loss=0.09534532731851106\n",
      "SGD iter. 1569/3599: loss=0.10021409432370224\n",
      "SGD iter. 1570/3599: loss=0.09662935067451336\n",
      "SGD iter. 1571/3599: loss=0.09810572603584544\n",
      "SGD iter. 1572/3599: loss=0.09502192805075227\n",
      "SGD iter. 1573/3599: loss=0.0941178140082978\n",
      "SGD iter. 1574/3599: loss=0.09486891876841377\n",
      "SGD iter. 1575/3599: loss=0.09032109260374252\n",
      "SGD iter. 1576/3599: loss=0.09133291105824733\n",
      "SGD iter. 1577/3599: loss=0.10007694753077603\n",
      "SGD iter. 1578/3599: loss=0.10119551482906466\n",
      "SGD iter. 1579/3599: loss=0.09376998597131139\n",
      "SGD iter. 1580/3599: loss=0.08876494655319891\n",
      "SGD iter. 1581/3599: loss=0.1000320834429135\n",
      "SGD iter. 1582/3599: loss=0.09043204332177704\n",
      "SGD iter. 1583/3599: loss=0.0884133544010238\n",
      "SGD iter. 1584/3599: loss=0.08412296660750333\n",
      "SGD iter. 1585/3599: loss=0.09462846713824492\n",
      "SGD iter. 1586/3599: loss=0.09119878355352164\n",
      "SGD iter. 1587/3599: loss=0.09778743522018353\n",
      "SGD iter. 1588/3599: loss=0.09706365485732718\n",
      "SGD iter. 1589/3599: loss=0.09640466422476773\n",
      "SGD iter. 1590/3599: loss=0.09432325491133939\n",
      "SGD iter. 1591/3599: loss=0.08951409167336843\n",
      "SGD iter. 1592/3599: loss=0.08866453278973495\n",
      "SGD iter. 1593/3599: loss=0.10172677677758157\n",
      "SGD iter. 1594/3599: loss=0.08729436470167104\n",
      "SGD iter. 1595/3599: loss=0.09606894593096571\n",
      "SGD iter. 1596/3599: loss=0.09154865639076004\n",
      "SGD iter. 1597/3599: loss=0.10241575953146574\n",
      "SGD iter. 1598/3599: loss=0.09437142695552961\n",
      "SGD iter. 1599/3599: loss=0.08865785749257346\n",
      "SGD iter. 1600/3599: loss=0.09725662675164942\n",
      "SGD iter. 1601/3599: loss=0.0891021907870139\n",
      "SGD iter. 1602/3599: loss=0.10204215540455441\n",
      "SGD iter. 1603/3599: loss=0.09352279116629611\n",
      "SGD iter. 1604/3599: loss=0.10250481710372958\n",
      "SGD iter. 1605/3599: loss=0.10409903506689035\n",
      "SGD iter. 1606/3599: loss=0.09473639631331578\n",
      "SGD iter. 1607/3599: loss=0.09280915244517729\n",
      "SGD iter. 1608/3599: loss=0.09823630411202441\n",
      "SGD iter. 1609/3599: loss=0.08250825219825367\n",
      "SGD iter. 1610/3599: loss=0.09330329579994279\n",
      "SGD iter. 1611/3599: loss=0.09026291495855808\n",
      "SGD iter. 1612/3599: loss=0.09243204238171908\n",
      "SGD iter. 1613/3599: loss=0.0914916277855006\n",
      "SGD iter. 1614/3599: loss=0.10011133303653129\n",
      "SGD iter. 1615/3599: loss=0.09937585806587741\n",
      "SGD iter. 1616/3599: loss=0.10028558386063233\n",
      "SGD iter. 1617/3599: loss=0.09944497990368545\n",
      "SGD iter. 1618/3599: loss=0.09600831444333008\n",
      "SGD iter. 1619/3599: loss=0.10270133724979687\n",
      "SGD iter. 1620/3599: loss=0.09274027779864563\n",
      "SGD iter. 1621/3599: loss=0.08991120826237203\n",
      "SGD iter. 1622/3599: loss=0.10004812464499167\n",
      "SGD iter. 1623/3599: loss=0.09290806889517296\n",
      "SGD iter. 1624/3599: loss=0.09786437800499895\n",
      "SGD iter. 1625/3599: loss=0.1045253856411655\n",
      "SGD iter. 1626/3599: loss=0.09221152450842504\n",
      "SGD iter. 1627/3599: loss=0.09259732151098377\n",
      "SGD iter. 1628/3599: loss=0.1004120922576828\n",
      "SGD iter. 1629/3599: loss=0.09942882924690766\n",
      "SGD iter. 1630/3599: loss=0.10059143066994354\n",
      "SGD iter. 1631/3599: loss=0.09727778687888339\n",
      "SGD iter. 1632/3599: loss=0.09193414556828516\n",
      "SGD iter. 1633/3599: loss=0.08653551759838882\n",
      "SGD iter. 1634/3599: loss=0.09490393068245123\n",
      "SGD iter. 1635/3599: loss=0.09211472308731981\n",
      "SGD iter. 1636/3599: loss=0.09806117135365805\n",
      "SGD iter. 1637/3599: loss=0.09346277059494953\n",
      "SGD iter. 1638/3599: loss=0.09019916234115893\n",
      "SGD iter. 1639/3599: loss=0.09155475435074124\n",
      "SGD iter. 1640/3599: loss=0.10094516522754834\n",
      "SGD iter. 1641/3599: loss=0.09564250792933067\n",
      "SGD iter. 1642/3599: loss=0.10043006546100165\n",
      "SGD iter. 1643/3599: loss=0.09429927814523693\n",
      "SGD iter. 1644/3599: loss=0.09517602776633097\n",
      "SGD iter. 1645/3599: loss=0.09811477248551129\n",
      "SGD iter. 1646/3599: loss=0.09350908351740811\n",
      "SGD iter. 1647/3599: loss=0.09519919492166556\n",
      "SGD iter. 1648/3599: loss=0.09283282262177717\n",
      "SGD iter. 1649/3599: loss=0.09064706246854487\n",
      "SGD iter. 1650/3599: loss=0.10004514729983921\n",
      "SGD iter. 1651/3599: loss=0.10584449836169621\n",
      "SGD iter. 1652/3599: loss=0.09467543201914072\n",
      "SGD iter. 1653/3599: loss=0.08582105412796472\n",
      "SGD iter. 1654/3599: loss=0.10139692615700333\n",
      "SGD iter. 1655/3599: loss=0.08370406348998147\n",
      "SGD iter. 1656/3599: loss=0.09614544285777386\n",
      "SGD iter. 1657/3599: loss=0.08575334710682739\n",
      "SGD iter. 1658/3599: loss=0.09736572530202114\n",
      "SGD iter. 1659/3599: loss=0.09889283235690007\n",
      "SGD iter. 1660/3599: loss=0.09262188606235869\n",
      "SGD iter. 1661/3599: loss=0.10615354526372581\n",
      "SGD iter. 1662/3599: loss=0.08740816305011476\n",
      "SGD iter. 1663/3599: loss=0.09488269095760991\n",
      "SGD iter. 1664/3599: loss=0.09032007178302365\n",
      "SGD iter. 1665/3599: loss=0.09913356894510593\n",
      "SGD iter. 1666/3599: loss=0.09872165982049841\n",
      "SGD iter. 1667/3599: loss=0.0913050871462657\n",
      "SGD iter. 1668/3599: loss=0.09769740566133889\n",
      "SGD iter. 1669/3599: loss=0.10076314894180453\n",
      "SGD iter. 1670/3599: loss=0.0978626871617169\n",
      "SGD iter. 1671/3599: loss=0.08533246738437653\n",
      "SGD iter. 1672/3599: loss=0.09900342856385708\n",
      "SGD iter. 1673/3599: loss=0.08242011392215773\n",
      "SGD iter. 1674/3599: loss=0.09344209705475351\n",
      "SGD iter. 1675/3599: loss=0.09930392731908724\n",
      "SGD iter. 1676/3599: loss=0.09675145567388828\n",
      "SGD iter. 1677/3599: loss=0.10110548451259833\n",
      "SGD iter. 1678/3599: loss=0.0987782577607138\n",
      "SGD iter. 1679/3599: loss=0.09496202547301844\n",
      "SGD iter. 1680/3599: loss=0.09738420397143457\n",
      "SGD iter. 1681/3599: loss=0.09502331363559771\n",
      "SGD iter. 1682/3599: loss=0.09005997504766905\n",
      "SGD iter. 1683/3599: loss=0.10505172591623066\n",
      "SGD iter. 1684/3599: loss=0.09571526855789174\n",
      "SGD iter. 1685/3599: loss=0.1040910266653774\n",
      "SGD iter. 1686/3599: loss=0.08619529172127462\n",
      "SGD iter. 1687/3599: loss=0.09438568751794438\n",
      "SGD iter. 1688/3599: loss=0.09558826223126173\n",
      "SGD iter. 1689/3599: loss=0.10137322979325891\n",
      "SGD iter. 1690/3599: loss=0.09755973679300592\n",
      "SGD iter. 1691/3599: loss=0.09819593178099378\n",
      "SGD iter. 1692/3599: loss=0.09238099459423174\n",
      "SGD iter. 1693/3599: loss=0.1057623802809771\n",
      "SGD iter. 1694/3599: loss=0.09632342708009325\n",
      "SGD iter. 1695/3599: loss=0.08387477521416328\n",
      "SGD iter. 1696/3599: loss=0.10019614200519733\n",
      "SGD iter. 1697/3599: loss=0.097949109438066\n",
      "SGD iter. 1698/3599: loss=0.0925355392395219\n",
      "SGD iter. 1699/3599: loss=0.0900541900638619\n",
      "SGD iter. 1700/3599: loss=0.09885171102766124\n",
      "SGD iter. 1701/3599: loss=0.09878691899744746\n",
      "SGD iter. 1702/3599: loss=0.09941768064144092\n",
      "SGD iter. 1703/3599: loss=0.08561249005140378\n",
      "SGD iter. 1704/3599: loss=0.09402679694716554\n",
      "SGD iter. 1705/3599: loss=0.0956200154521665\n",
      "SGD iter. 1706/3599: loss=0.0970162464422937\n",
      "SGD iter. 1707/3599: loss=0.0935029151130158\n",
      "SGD iter. 1708/3599: loss=0.10026045575730469\n",
      "SGD iter. 1709/3599: loss=0.09532823279483951\n",
      "SGD iter. 1710/3599: loss=0.08819710000807915\n",
      "SGD iter. 1711/3599: loss=0.09190308284232608\n",
      "SGD iter. 1712/3599: loss=0.09730868550384761\n",
      "SGD iter. 1713/3599: loss=0.09693313008871335\n",
      "SGD iter. 1714/3599: loss=0.09782789223448927\n",
      "SGD iter. 1715/3599: loss=0.09660475787242806\n",
      "SGD iter. 1716/3599: loss=0.09182121552290354\n",
      "SGD iter. 1717/3599: loss=0.09861760752374897\n",
      "SGD iter. 1718/3599: loss=0.0956548319238322\n",
      "SGD iter. 1719/3599: loss=0.08322601671064328\n",
      "SGD iter. 1720/3599: loss=0.09485284473815661\n",
      "SGD iter. 1721/3599: loss=0.09090898292556361\n",
      "SGD iter. 1722/3599: loss=0.10086952806277086\n",
      "SGD iter. 1723/3599: loss=0.09846096536350007\n",
      "SGD iter. 1724/3599: loss=0.10084028065212178\n",
      "SGD iter. 1725/3599: loss=0.09397763677919882\n",
      "SGD iter. 1726/3599: loss=0.08507371876295065\n",
      "SGD iter. 1727/3599: loss=0.0947810995914119\n",
      "SGD iter. 1728/3599: loss=0.10228047036161636\n",
      "SGD iter. 1729/3599: loss=0.10386258354190829\n",
      "SGD iter. 1730/3599: loss=0.09028206429865215\n",
      "SGD iter. 1731/3599: loss=0.10704021412069675\n",
      "SGD iter. 1732/3599: loss=0.0958985635313081\n",
      "SGD iter. 1733/3599: loss=0.09486416146792247\n",
      "SGD iter. 1734/3599: loss=0.09497811775070933\n",
      "SGD iter. 1735/3599: loss=0.09205711969593575\n",
      "SGD iter. 1736/3599: loss=0.09861121577449787\n",
      "SGD iter. 1737/3599: loss=0.0946622387086447\n",
      "SGD iter. 1738/3599: loss=0.09260711513487266\n",
      "SGD iter. 1739/3599: loss=0.0893142705242981\n",
      "SGD iter. 1740/3599: loss=0.09380557936568806\n",
      "SGD iter. 1741/3599: loss=0.09228847635113441\n",
      "SGD iter. 1742/3599: loss=0.09713129353182674\n",
      "SGD iter. 1743/3599: loss=0.09313444191352874\n",
      "SGD iter. 1744/3599: loss=0.10633291509984591\n",
      "SGD iter. 1745/3599: loss=0.09267420010602467\n",
      "SGD iter. 1746/3599: loss=0.09864250753671734\n",
      "SGD iter. 1747/3599: loss=0.08712799035627505\n",
      "SGD iter. 1748/3599: loss=0.0907946962432964\n",
      "SGD iter. 1749/3599: loss=0.08869198825136947\n",
      "SGD iter. 1750/3599: loss=0.09171090348105247\n",
      "SGD iter. 1751/3599: loss=0.0972370279786341\n",
      "SGD iter. 1752/3599: loss=0.09161160902657643\n",
      "SGD iter. 1753/3599: loss=0.09761455638157651\n",
      "SGD iter. 1754/3599: loss=0.09087777188481262\n",
      "SGD iter. 1755/3599: loss=0.08855870955341584\n",
      "SGD iter. 1756/3599: loss=0.09413800935331332\n",
      "SGD iter. 1757/3599: loss=0.09832454797855887\n",
      "SGD iter. 1758/3599: loss=0.09189372731937205\n",
      "SGD iter. 1759/3599: loss=0.09781413310182718\n",
      "SGD iter. 1760/3599: loss=0.08759292006707337\n",
      "SGD iter. 1761/3599: loss=0.09944280193117348\n",
      "SGD iter. 1762/3599: loss=0.09861088276625188\n",
      "SGD iter. 1763/3599: loss=0.09548062493282328\n",
      "SGD iter. 1764/3599: loss=0.08683227668608585\n",
      "SGD iter. 1765/3599: loss=0.09733283588855796\n",
      "SGD iter. 1766/3599: loss=0.09378171610783125\n",
      "SGD iter. 1767/3599: loss=0.09339553885799674\n",
      "SGD iter. 1768/3599: loss=0.09574292935104439\n",
      "SGD iter. 1769/3599: loss=0.09054663474533313\n",
      "SGD iter. 1770/3599: loss=0.0894044242109561\n",
      "SGD iter. 1771/3599: loss=0.09160704092976717\n",
      "SGD iter. 1772/3599: loss=0.09298263194268946\n",
      "SGD iter. 1773/3599: loss=0.08700138556399323\n",
      "SGD iter. 1774/3599: loss=0.09996704330267461\n",
      "SGD iter. 1775/3599: loss=0.08527410573930325\n",
      "SGD iter. 1776/3599: loss=0.0849477412755367\n",
      "SGD iter. 1777/3599: loss=0.0952060707709549\n",
      "SGD iter. 1778/3599: loss=0.09738560385349906\n",
      "SGD iter. 1779/3599: loss=0.09122977535225751\n",
      "SGD iter. 1780/3599: loss=0.09392931048058618\n",
      "SGD iter. 1781/3599: loss=0.09428551903138468\n",
      "SGD iter. 1782/3599: loss=0.09428752196699154\n",
      "SGD iter. 1783/3599: loss=0.09927140981676691\n",
      "SGD iter. 1784/3599: loss=0.08900456999962891\n",
      "SGD iter. 1785/3599: loss=0.09051900588323478\n",
      "SGD iter. 1786/3599: loss=0.09928024178162159\n",
      "SGD iter. 1787/3599: loss=0.099805777577121\n",
      "SGD iter. 1788/3599: loss=0.10057693114583283\n",
      "SGD iter. 1789/3599: loss=0.09997486842029524\n",
      "SGD iter. 1790/3599: loss=0.09079646594624868\n",
      "SGD iter. 1791/3599: loss=0.09502739188029513\n",
      "SGD iter. 1792/3599: loss=0.0927440189214426\n",
      "SGD iter. 1793/3599: loss=0.09756288697102052\n",
      "SGD iter. 1794/3599: loss=0.09392943314670715\n",
      "SGD iter. 1795/3599: loss=0.0955508966019927\n",
      "SGD iter. 1796/3599: loss=0.09785901903886081\n",
      "SGD iter. 1797/3599: loss=0.10181172592920468\n",
      "SGD iter. 1798/3599: loss=0.09194236171668395\n",
      "SGD iter. 1799/3599: loss=0.09771010327600864\n",
      "SGD iter. 1800/3599: loss=0.095093340041326\n",
      "SGD iter. 1801/3599: loss=0.09604677367727027\n",
      "SGD iter. 1802/3599: loss=0.09517332280762283\n",
      "SGD iter. 1803/3599: loss=0.09139775733823037\n",
      "SGD iter. 1804/3599: loss=0.10646251791596509\n",
      "SGD iter. 1805/3599: loss=0.10370702839804216\n",
      "SGD iter. 1806/3599: loss=0.09343227154950157\n",
      "SGD iter. 1807/3599: loss=0.089095648617911\n",
      "SGD iter. 1808/3599: loss=0.08888221718046155\n",
      "SGD iter. 1809/3599: loss=0.08739820486146897\n",
      "SGD iter. 1810/3599: loss=0.07873675782621115\n",
      "SGD iter. 1811/3599: loss=0.0975219959411241\n",
      "SGD iter. 1812/3599: loss=0.07830137259059523\n",
      "SGD iter. 1813/3599: loss=0.10104168954674078\n",
      "SGD iter. 1814/3599: loss=0.0883292070875971\n",
      "SGD iter. 1815/3599: loss=0.09117607026393401\n",
      "SGD iter. 1816/3599: loss=0.1002644633614692\n",
      "SGD iter. 1817/3599: loss=0.0946300281088612\n",
      "SGD iter. 1818/3599: loss=0.092288077478872\n",
      "SGD iter. 1819/3599: loss=0.10283289217703666\n",
      "SGD iter. 1820/3599: loss=0.09518483912797626\n",
      "SGD iter. 1821/3599: loss=0.092068828646909\n",
      "SGD iter. 1822/3599: loss=0.1002513763009614\n",
      "SGD iter. 1823/3599: loss=0.08909198090302382\n",
      "SGD iter. 1824/3599: loss=0.08336214726491709\n",
      "SGD iter. 1825/3599: loss=0.0931231017236249\n",
      "SGD iter. 1826/3599: loss=0.09443181368717088\n",
      "SGD iter. 1827/3599: loss=0.09018753012105951\n",
      "SGD iter. 1828/3599: loss=0.09861621050498201\n",
      "SGD iter. 1829/3599: loss=0.09753435375550532\n",
      "SGD iter. 1830/3599: loss=0.09821335897967451\n",
      "SGD iter. 1831/3599: loss=0.09476843158714837\n",
      "SGD iter. 1832/3599: loss=0.09841013175173106\n",
      "SGD iter. 1833/3599: loss=0.09065206355246366\n",
      "SGD iter. 1834/3599: loss=0.1018431783428238\n",
      "SGD iter. 1835/3599: loss=0.08903957735933747\n",
      "SGD iter. 1836/3599: loss=0.10007272630609232\n",
      "SGD iter. 1837/3599: loss=0.0980197122903261\n",
      "SGD iter. 1838/3599: loss=0.09218800016338366\n",
      "SGD iter. 1839/3599: loss=0.09736488093598292\n",
      "SGD iter. 1840/3599: loss=0.10112109208109307\n",
      "SGD iter. 1841/3599: loss=0.09683628810938086\n",
      "SGD iter. 1842/3599: loss=0.09797911485952764\n",
      "SGD iter. 1843/3599: loss=0.09999824006703137\n",
      "SGD iter. 1844/3599: loss=0.09374049672153476\n",
      "SGD iter. 1845/3599: loss=0.09659613209913415\n",
      "SGD iter. 1846/3599: loss=0.09260347482173525\n",
      "SGD iter. 1847/3599: loss=0.08736376412731893\n",
      "SGD iter. 1848/3599: loss=0.10738687167712606\n",
      "SGD iter. 1849/3599: loss=0.09739521190173754\n",
      "SGD iter. 1850/3599: loss=0.09514805811575822\n",
      "SGD iter. 1851/3599: loss=0.09386654121088849\n",
      "SGD iter. 1852/3599: loss=0.0847250589393646\n",
      "SGD iter. 1853/3599: loss=0.0823648769468274\n",
      "SGD iter. 1854/3599: loss=0.09350129718889474\n",
      "SGD iter. 1855/3599: loss=0.09453714287496712\n",
      "SGD iter. 1856/3599: loss=0.10727776244412028\n",
      "SGD iter. 1857/3599: loss=0.09547631245198332\n",
      "SGD iter. 1858/3599: loss=0.09618884285428109\n",
      "SGD iter. 1859/3599: loss=0.09459322474270239\n",
      "SGD iter. 1860/3599: loss=0.09677711133808473\n",
      "SGD iter. 1861/3599: loss=0.09346717171231383\n",
      "SGD iter. 1862/3599: loss=0.0957039247403625\n",
      "SGD iter. 1863/3599: loss=0.09687815026778751\n",
      "SGD iter. 1864/3599: loss=0.0978505282067695\n",
      "SGD iter. 1865/3599: loss=0.09634868540352994\n",
      "SGD iter. 1866/3599: loss=0.09565841824630872\n",
      "SGD iter. 1867/3599: loss=0.09490605482841627\n",
      "SGD iter. 1868/3599: loss=0.1003881474237297\n",
      "SGD iter. 1869/3599: loss=0.09437462611094585\n",
      "SGD iter. 1870/3599: loss=0.10226800749862894\n",
      "SGD iter. 1871/3599: loss=0.10409102109764687\n",
      "SGD iter. 1872/3599: loss=0.09563654168138017\n",
      "SGD iter. 1873/3599: loss=0.09615272110285988\n",
      "SGD iter. 1874/3599: loss=0.08480137790951373\n",
      "SGD iter. 1875/3599: loss=0.0991701347361825\n",
      "SGD iter. 1876/3599: loss=0.0757659725976852\n",
      "SGD iter. 1877/3599: loss=0.10577667722355402\n",
      "SGD iter. 1878/3599: loss=0.0981225206276563\n",
      "SGD iter. 1879/3599: loss=0.09810920618219712\n",
      "SGD iter. 1880/3599: loss=0.08800764275442888\n",
      "SGD iter. 1881/3599: loss=0.09089486753724045\n",
      "SGD iter. 1882/3599: loss=0.10242021687025395\n",
      "SGD iter. 1883/3599: loss=0.10242864824604067\n",
      "SGD iter. 1884/3599: loss=0.08945422444379118\n",
      "SGD iter. 1885/3599: loss=0.08596851721853747\n",
      "SGD iter. 1886/3599: loss=0.10493245932300618\n",
      "SGD iter. 1887/3599: loss=0.09845249387753809\n",
      "SGD iter. 1888/3599: loss=0.10199560253746731\n",
      "SGD iter. 1889/3599: loss=0.09065879432142718\n",
      "SGD iter. 1890/3599: loss=0.09304691933594397\n",
      "SGD iter. 1891/3599: loss=0.09170106689682586\n",
      "SGD iter. 1892/3599: loss=0.09464695944891502\n",
      "SGD iter. 1893/3599: loss=0.08900886151365187\n",
      "SGD iter. 1894/3599: loss=0.09347233464732627\n",
      "SGD iter. 1895/3599: loss=0.08802610044725426\n",
      "SGD iter. 1896/3599: loss=0.1019320065359961\n",
      "SGD iter. 1897/3599: loss=0.0936167638346729\n",
      "SGD iter. 1898/3599: loss=0.08771236482321237\n",
      "SGD iter. 1899/3599: loss=0.10193227636308339\n",
      "SGD iter. 1900/3599: loss=0.1002288846170844\n",
      "SGD iter. 1901/3599: loss=0.08988853903801473\n",
      "SGD iter. 1902/3599: loss=0.09154865371606477\n",
      "SGD iter. 1903/3599: loss=0.0878819384605122\n",
      "SGD iter. 1904/3599: loss=0.09303081972520078\n",
      "SGD iter. 1905/3599: loss=0.10430758498070504\n",
      "SGD iter. 1906/3599: loss=0.09237972279092707\n",
      "SGD iter. 1907/3599: loss=0.09501126587187189\n",
      "SGD iter. 1908/3599: loss=0.09710634617422308\n",
      "SGD iter. 1909/3599: loss=0.09306930745147717\n",
      "SGD iter. 1910/3599: loss=0.09831050451524742\n",
      "SGD iter. 1911/3599: loss=0.08608508857850197\n",
      "SGD iter. 1912/3599: loss=0.09659028850651817\n",
      "SGD iter. 1913/3599: loss=0.08513085569967455\n",
      "SGD iter. 1914/3599: loss=0.08376463729930875\n",
      "SGD iter. 1915/3599: loss=0.09647280602443856\n",
      "SGD iter. 1916/3599: loss=0.09583861697445013\n",
      "SGD iter. 1917/3599: loss=0.09892681950483047\n",
      "SGD iter. 1918/3599: loss=0.0936315552073965\n",
      "SGD iter. 1919/3599: loss=0.09609049108163875\n",
      "SGD iter. 1920/3599: loss=0.09013163537742985\n",
      "SGD iter. 1921/3599: loss=0.10207615414669349\n",
      "SGD iter. 1922/3599: loss=0.09188296430999102\n",
      "SGD iter. 1923/3599: loss=0.0950875420456859\n",
      "SGD iter. 1924/3599: loss=0.08535531095033971\n",
      "SGD iter. 1925/3599: loss=0.08558048307863389\n",
      "SGD iter. 1926/3599: loss=0.10069448325761601\n",
      "SGD iter. 1927/3599: loss=0.09943554197224534\n",
      "SGD iter. 1928/3599: loss=0.09984193222013099\n",
      "SGD iter. 1929/3599: loss=0.09042212730074417\n",
      "SGD iter. 1930/3599: loss=0.09655411096432223\n",
      "SGD iter. 1931/3599: loss=0.09660631929289787\n",
      "SGD iter. 1932/3599: loss=0.0891393174547248\n",
      "SGD iter. 1933/3599: loss=0.09295452706597998\n",
      "SGD iter. 1934/3599: loss=0.09848041793243563\n",
      "SGD iter. 1935/3599: loss=0.09458537523869637\n",
      "SGD iter. 1936/3599: loss=0.09050820291882203\n",
      "SGD iter. 1937/3599: loss=0.09617466596086832\n",
      "SGD iter. 1938/3599: loss=0.08426824441369807\n",
      "SGD iter. 1939/3599: loss=0.0971987289919628\n",
      "SGD iter. 1940/3599: loss=0.09860518292137624\n",
      "SGD iter. 1941/3599: loss=0.09246661960698421\n",
      "SGD iter. 1942/3599: loss=0.09825337748075758\n",
      "SGD iter. 1943/3599: loss=0.09810222194195667\n",
      "SGD iter. 1944/3599: loss=0.1004137833005351\n",
      "SGD iter. 1945/3599: loss=0.08473551914747462\n",
      "SGD iter. 1946/3599: loss=0.10061183476094332\n",
      "SGD iter. 1947/3599: loss=0.09988910567869906\n",
      "SGD iter. 1948/3599: loss=0.092262697258195\n",
      "SGD iter. 1949/3599: loss=0.0877383099973948\n",
      "SGD iter. 1950/3599: loss=0.10283648484379068\n",
      "SGD iter. 1951/3599: loss=0.1005117592828003\n",
      "SGD iter. 1952/3599: loss=0.08741693717454029\n",
      "SGD iter. 1953/3599: loss=0.08766144183813651\n",
      "SGD iter. 1954/3599: loss=0.09263467073401585\n",
      "SGD iter. 1955/3599: loss=0.09446662867818086\n",
      "SGD iter. 1956/3599: loss=0.09412719048014355\n",
      "SGD iter. 1957/3599: loss=0.09857405538069211\n",
      "SGD iter. 1958/3599: loss=0.08986031202025332\n",
      "SGD iter. 1959/3599: loss=0.09720305037309589\n",
      "SGD iter. 1960/3599: loss=0.10260610152215772\n",
      "SGD iter. 1961/3599: loss=0.09865615373147749\n",
      "SGD iter. 1962/3599: loss=0.10069303170231259\n",
      "SGD iter. 1963/3599: loss=0.08922894756295699\n",
      "SGD iter. 1964/3599: loss=0.100890543467555\n",
      "SGD iter. 1965/3599: loss=0.09571195025285514\n",
      "SGD iter. 1966/3599: loss=0.09218001995922455\n",
      "SGD iter. 1967/3599: loss=0.09502767425956254\n",
      "SGD iter. 1968/3599: loss=0.10213474718064416\n",
      "SGD iter. 1969/3599: loss=0.09451123183202467\n",
      "SGD iter. 1970/3599: loss=0.09911376991399312\n",
      "SGD iter. 1971/3599: loss=0.0961629598467197\n",
      "SGD iter. 1972/3599: loss=0.09972507098645622\n",
      "SGD iter. 1973/3599: loss=0.0970865189295314\n",
      "SGD iter. 1974/3599: loss=0.09425890283185473\n",
      "SGD iter. 1975/3599: loss=0.09303286339434547\n",
      "SGD iter. 1976/3599: loss=0.09775154328305943\n",
      "SGD iter. 1977/3599: loss=0.09867061197318001\n",
      "SGD iter. 1978/3599: loss=0.09950282829115634\n",
      "SGD iter. 1979/3599: loss=0.09532296385644114\n",
      "SGD iter. 1980/3599: loss=0.10351389228486131\n",
      "SGD iter. 1981/3599: loss=0.09233995716885393\n",
      "SGD iter. 1982/3599: loss=0.09040821266662982\n",
      "SGD iter. 1983/3599: loss=0.09135566763219491\n",
      "SGD iter. 1984/3599: loss=0.09013893387824848\n",
      "SGD iter. 1985/3599: loss=0.09284940317491862\n",
      "SGD iter. 1986/3599: loss=0.0935312581110848\n",
      "SGD iter. 1987/3599: loss=0.09029164658168601\n",
      "SGD iter. 1988/3599: loss=0.09398466081757557\n",
      "SGD iter. 1989/3599: loss=0.09561210168483324\n",
      "SGD iter. 1990/3599: loss=0.10056276049771898\n",
      "SGD iter. 1991/3599: loss=0.10007959648837587\n",
      "SGD iter. 1992/3599: loss=0.10095536176269293\n",
      "SGD iter. 1993/3599: loss=0.09240535522963134\n",
      "SGD iter. 1994/3599: loss=0.09057139503072993\n",
      "SGD iter. 1995/3599: loss=0.09141412122705535\n",
      "SGD iter. 1996/3599: loss=0.09279209415925062\n",
      "SGD iter. 1997/3599: loss=0.08967662155857345\n",
      "SGD iter. 1998/3599: loss=0.09360074261337004\n",
      "SGD iter. 1999/3599: loss=0.09437865734281309\n",
      "SGD iter. 2000/3599: loss=0.08795704645078926\n",
      "SGD iter. 2001/3599: loss=0.09323866944515224\n",
      "SGD iter. 2002/3599: loss=0.07996629447115852\n",
      "SGD iter. 2003/3599: loss=0.09303590047011194\n",
      "SGD iter. 2004/3599: loss=0.09395120206614842\n",
      "SGD iter. 2005/3599: loss=0.10464022929009112\n",
      "SGD iter. 2006/3599: loss=0.09013023590568746\n",
      "SGD iter. 2007/3599: loss=0.09529080795107894\n",
      "SGD iter. 2008/3599: loss=0.10250259366194128\n",
      "SGD iter. 2009/3599: loss=0.09187135897125481\n",
      "SGD iter. 2010/3599: loss=0.08971942911017805\n",
      "SGD iter. 2011/3599: loss=0.09357902182591223\n",
      "SGD iter. 2012/3599: loss=0.09318070524087949\n",
      "SGD iter. 2013/3599: loss=0.07942242108118705\n",
      "SGD iter. 2014/3599: loss=0.10655724113301623\n",
      "SGD iter. 2015/3599: loss=0.09399577844691501\n",
      "SGD iter. 2016/3599: loss=0.10306664421370117\n",
      "SGD iter. 2017/3599: loss=0.09085037918294991\n",
      "SGD iter. 2018/3599: loss=0.08934247321834798\n",
      "SGD iter. 2019/3599: loss=0.09335313518098344\n",
      "SGD iter. 2020/3599: loss=0.0925201395848245\n",
      "SGD iter. 2021/3599: loss=0.09258356323051624\n",
      "SGD iter. 2022/3599: loss=0.08523598400324403\n",
      "SGD iter. 2023/3599: loss=0.09811179671325362\n",
      "SGD iter. 2024/3599: loss=0.09515678184315918\n",
      "SGD iter. 2025/3599: loss=0.09744442315447693\n",
      "SGD iter. 2026/3599: loss=0.07864113782490462\n",
      "SGD iter. 2027/3599: loss=0.0902307254659111\n",
      "SGD iter. 2028/3599: loss=0.08517134999501279\n",
      "SGD iter. 2029/3599: loss=0.08912952576987723\n",
      "SGD iter. 2030/3599: loss=0.08443813578404089\n",
      "SGD iter. 2031/3599: loss=0.08410746519860846\n",
      "SGD iter. 2032/3599: loss=0.08686109384250126\n",
      "SGD iter. 2033/3599: loss=0.09961234460869431\n",
      "SGD iter. 2034/3599: loss=0.08639496204309706\n",
      "SGD iter. 2035/3599: loss=0.0933918301999775\n",
      "SGD iter. 2036/3599: loss=0.09788782679548014\n",
      "SGD iter. 2037/3599: loss=0.09467394425787945\n",
      "SGD iter. 2038/3599: loss=0.09725258765430153\n",
      "SGD iter. 2039/3599: loss=0.10163849946634161\n",
      "SGD iter. 2040/3599: loss=0.08456378703888656\n",
      "SGD iter. 2041/3599: loss=0.08179523973639202\n",
      "SGD iter. 2042/3599: loss=0.09661926106503368\n",
      "SGD iter. 2043/3599: loss=0.09330040563339201\n",
      "SGD iter. 2044/3599: loss=0.10601049008927203\n",
      "SGD iter. 2045/3599: loss=0.0907547796177132\n",
      "SGD iter. 2046/3599: loss=0.08965352405668528\n",
      "SGD iter. 2047/3599: loss=0.09377760791419582\n",
      "SGD iter. 2048/3599: loss=0.09258714394808429\n",
      "SGD iter. 2049/3599: loss=0.08620041596302434\n",
      "SGD iter. 2050/3599: loss=0.09031521948228376\n",
      "SGD iter. 2051/3599: loss=0.1015369355501881\n",
      "SGD iter. 2052/3599: loss=0.10323820253315469\n",
      "SGD iter. 2053/3599: loss=0.09640762956394545\n",
      "SGD iter. 2054/3599: loss=0.08937564818176782\n",
      "SGD iter. 2055/3599: loss=0.09132923717477003\n",
      "SGD iter. 2056/3599: loss=0.09218760495689496\n",
      "SGD iter. 2057/3599: loss=0.09911868315100827\n",
      "SGD iter. 2058/3599: loss=0.09055258834242236\n",
      "SGD iter. 2059/3599: loss=0.09452800513444858\n",
      "SGD iter. 2060/3599: loss=0.09273632037729239\n",
      "SGD iter. 2061/3599: loss=0.1008851696098637\n",
      "SGD iter. 2062/3599: loss=0.09807544996699692\n",
      "SGD iter. 2063/3599: loss=0.08724399733706836\n",
      "SGD iter. 2064/3599: loss=0.09238322330285204\n",
      "SGD iter. 2065/3599: loss=0.08735079443541768\n",
      "SGD iter. 2066/3599: loss=0.08904360130876773\n",
      "SGD iter. 2067/3599: loss=0.08387159556628561\n",
      "SGD iter. 2068/3599: loss=0.09163485978256872\n",
      "SGD iter. 2069/3599: loss=0.09592138537767039\n",
      "SGD iter. 2070/3599: loss=0.08366476551751188\n",
      "SGD iter. 2071/3599: loss=0.09140261127335406\n",
      "SGD iter. 2072/3599: loss=0.09365476435902409\n",
      "SGD iter. 2073/3599: loss=0.10110434629766185\n",
      "SGD iter. 2074/3599: loss=0.09657792731697493\n",
      "SGD iter. 2075/3599: loss=0.08992630931282189\n",
      "SGD iter. 2076/3599: loss=0.09105147454828497\n",
      "SGD iter. 2077/3599: loss=0.08204659124013945\n",
      "SGD iter. 2078/3599: loss=0.09804861352267852\n",
      "SGD iter. 2079/3599: loss=0.0898861782550752\n",
      "SGD iter. 2080/3599: loss=0.10331033414349192\n",
      "SGD iter. 2081/3599: loss=0.093944740785748\n",
      "SGD iter. 2082/3599: loss=0.09172388913164879\n",
      "SGD iter. 2083/3599: loss=0.09111689207178211\n",
      "SGD iter. 2084/3599: loss=0.08704499005033295\n",
      "SGD iter. 2085/3599: loss=0.09508019577673145\n",
      "SGD iter. 2086/3599: loss=0.0907723967459476\n",
      "SGD iter. 2087/3599: loss=0.09035629514452145\n",
      "SGD iter. 2088/3599: loss=0.08736215038617073\n",
      "SGD iter. 2089/3599: loss=0.08983167998369562\n",
      "SGD iter. 2090/3599: loss=0.09146232014167242\n",
      "SGD iter. 2091/3599: loss=0.08647651535046373\n",
      "SGD iter. 2092/3599: loss=0.09897391533713999\n",
      "SGD iter. 2093/3599: loss=0.08987694959355323\n",
      "SGD iter. 2094/3599: loss=0.10123564330475132\n",
      "SGD iter. 2095/3599: loss=0.08777130388343872\n",
      "SGD iter. 2096/3599: loss=0.10195414723204471\n",
      "SGD iter. 2097/3599: loss=0.10233896487023707\n",
      "SGD iter. 2098/3599: loss=0.09223367195179996\n",
      "SGD iter. 2099/3599: loss=0.08857407317561276\n",
      "SGD iter. 2100/3599: loss=0.0837696021926371\n",
      "SGD iter. 2101/3599: loss=0.09690359029009735\n",
      "SGD iter. 2102/3599: loss=0.09576299791660578\n",
      "SGD iter. 2103/3599: loss=0.10019619258813489\n",
      "SGD iter. 2104/3599: loss=0.09151097567284802\n",
      "SGD iter. 2105/3599: loss=0.08209937966829241\n",
      "SGD iter. 2106/3599: loss=0.0924967036623453\n",
      "SGD iter. 2107/3599: loss=0.08725990134831771\n",
      "SGD iter. 2108/3599: loss=0.10018722391673018\n",
      "SGD iter. 2109/3599: loss=0.08877026494051835\n",
      "SGD iter. 2110/3599: loss=0.10136419598382987\n",
      "SGD iter. 2111/3599: loss=0.08913571276991175\n",
      "SGD iter. 2112/3599: loss=0.09987041923996408\n",
      "SGD iter. 2113/3599: loss=0.08473523704063228\n",
      "SGD iter. 2114/3599: loss=0.09606064743123265\n",
      "SGD iter. 2115/3599: loss=0.0909326599087174\n",
      "SGD iter. 2116/3599: loss=0.09440435521595274\n",
      "SGD iter. 2117/3599: loss=0.09232102532763353\n",
      "SGD iter. 2118/3599: loss=0.08031465006922103\n",
      "SGD iter. 2119/3599: loss=0.10144855188953367\n",
      "SGD iter. 2120/3599: loss=0.09365732024026568\n",
      "SGD iter. 2121/3599: loss=0.0947135113343072\n",
      "SGD iter. 2122/3599: loss=0.08470995441112646\n",
      "SGD iter. 2123/3599: loss=0.09772460624750975\n",
      "SGD iter. 2124/3599: loss=0.09896539257944104\n",
      "SGD iter. 2125/3599: loss=0.09552024086462026\n",
      "SGD iter. 2126/3599: loss=0.08919168311996764\n",
      "SGD iter. 2127/3599: loss=0.09848740046955598\n",
      "SGD iter. 2128/3599: loss=0.105065213801877\n",
      "SGD iter. 2129/3599: loss=0.0866899223438062\n",
      "SGD iter. 2130/3599: loss=0.09941177866028525\n",
      "SGD iter. 2131/3599: loss=0.09402994031807158\n",
      "SGD iter. 2132/3599: loss=0.0953148632005355\n",
      "SGD iter. 2133/3599: loss=0.09393362031393862\n",
      "SGD iter. 2134/3599: loss=0.08773021056883659\n",
      "SGD iter. 2135/3599: loss=0.0922732779572694\n",
      "SGD iter. 2136/3599: loss=0.0821395684216017\n",
      "SGD iter. 2137/3599: loss=0.08906218719840048\n",
      "SGD iter. 2138/3599: loss=0.09687479295806259\n",
      "SGD iter. 2139/3599: loss=0.09841459651560261\n",
      "SGD iter. 2140/3599: loss=0.09183555875150601\n",
      "SGD iter. 2141/3599: loss=0.0858493664236431\n",
      "SGD iter. 2142/3599: loss=0.0928455913408402\n",
      "SGD iter. 2143/3599: loss=0.08320008772429074\n",
      "SGD iter. 2144/3599: loss=0.09658132586727133\n",
      "SGD iter. 2145/3599: loss=0.10158990607696444\n",
      "SGD iter. 2146/3599: loss=0.0850289375637147\n",
      "SGD iter. 2147/3599: loss=0.0823932381528504\n",
      "SGD iter. 2148/3599: loss=0.0970303213437819\n",
      "SGD iter. 2149/3599: loss=0.09562514213869538\n",
      "SGD iter. 2150/3599: loss=0.08974288616641393\n",
      "SGD iter. 2151/3599: loss=0.09372878724574304\n",
      "SGD iter. 2152/3599: loss=0.09654301099927284\n",
      "SGD iter. 2153/3599: loss=0.09413181981385202\n",
      "SGD iter. 2154/3599: loss=0.0940646566100446\n",
      "SGD iter. 2155/3599: loss=0.09316205898112778\n",
      "SGD iter. 2156/3599: loss=0.10139566871787827\n",
      "SGD iter. 2157/3599: loss=0.09557628259969364\n",
      "SGD iter. 2158/3599: loss=0.09791005109714232\n",
      "SGD iter. 2159/3599: loss=0.09821461489456028\n",
      "SGD iter. 2160/3599: loss=0.08940774707251226\n",
      "SGD iter. 2161/3599: loss=0.08206681194578697\n",
      "SGD iter. 2162/3599: loss=0.09306520164081175\n",
      "SGD iter. 2163/3599: loss=0.09459670743528041\n",
      "SGD iter. 2164/3599: loss=0.09214610100850562\n",
      "SGD iter. 2165/3599: loss=0.09062400512281876\n",
      "SGD iter. 2166/3599: loss=0.09419213982171448\n",
      "SGD iter. 2167/3599: loss=0.09003192801840551\n",
      "SGD iter. 2168/3599: loss=0.0911236744284972\n",
      "SGD iter. 2169/3599: loss=0.07875276152973723\n",
      "SGD iter. 2170/3599: loss=0.08923702421511086\n",
      "SGD iter. 2171/3599: loss=0.09189474391592099\n",
      "SGD iter. 2172/3599: loss=0.08794615162153648\n",
      "SGD iter. 2173/3599: loss=0.09446066609571466\n",
      "SGD iter. 2174/3599: loss=0.09207817096443358\n",
      "SGD iter. 2175/3599: loss=0.0996684325081757\n",
      "SGD iter. 2176/3599: loss=0.09263291069812922\n",
      "SGD iter. 2177/3599: loss=0.09711778008992508\n",
      "SGD iter. 2178/3599: loss=0.10001407086891702\n",
      "SGD iter. 2179/3599: loss=0.086663289873004\n",
      "SGD iter. 2180/3599: loss=0.0766687919726218\n",
      "SGD iter. 2181/3599: loss=0.08759166952821237\n",
      "SGD iter. 2182/3599: loss=0.08990625386454656\n",
      "SGD iter. 2183/3599: loss=0.10363662393366119\n",
      "SGD iter. 2184/3599: loss=0.0986582838569141\n",
      "SGD iter. 2185/3599: loss=0.08012922189869508\n",
      "SGD iter. 2186/3599: loss=0.09779476984219333\n",
      "SGD iter. 2187/3599: loss=0.09396610148145296\n",
      "SGD iter. 2188/3599: loss=0.08213603414977641\n",
      "SGD iter. 2189/3599: loss=0.0850830526164548\n",
      "SGD iter. 2190/3599: loss=0.10071328814075209\n",
      "SGD iter. 2191/3599: loss=0.09812852258218052\n",
      "SGD iter. 2192/3599: loss=0.0928800727801007\n",
      "SGD iter. 2193/3599: loss=0.08646552694334547\n",
      "SGD iter. 2194/3599: loss=0.09013561070540924\n",
      "SGD iter. 2195/3599: loss=0.09563898643647356\n",
      "SGD iter. 2196/3599: loss=0.09498062687138745\n",
      "SGD iter. 2197/3599: loss=0.0935601037490271\n",
      "SGD iter. 2198/3599: loss=0.0879716325927855\n",
      "SGD iter. 2199/3599: loss=0.09085297837974056\n",
      "SGD iter. 2200/3599: loss=0.08660360547171844\n",
      "SGD iter. 2201/3599: loss=0.09131545283116713\n",
      "SGD iter. 2202/3599: loss=0.0972724344756691\n",
      "SGD iter. 2203/3599: loss=0.10679437442327336\n",
      "SGD iter. 2204/3599: loss=0.09847666560017046\n",
      "SGD iter. 2205/3599: loss=0.08906804690662821\n",
      "SGD iter. 2206/3599: loss=0.0919033698439396\n",
      "SGD iter. 2207/3599: loss=0.09309464540605636\n",
      "SGD iter. 2208/3599: loss=0.09340358118817918\n",
      "SGD iter. 2209/3599: loss=0.08226781469612827\n",
      "SGD iter. 2210/3599: loss=0.08918655305436078\n",
      "SGD iter. 2211/3599: loss=0.08875247537289552\n",
      "SGD iter. 2212/3599: loss=0.08367918406747138\n",
      "SGD iter. 2213/3599: loss=0.09824594167766988\n",
      "SGD iter. 2214/3599: loss=0.09206735439092933\n",
      "SGD iter. 2215/3599: loss=0.09572840726406429\n",
      "SGD iter. 2216/3599: loss=0.08795506586390231\n",
      "SGD iter. 2217/3599: loss=0.1011156140975385\n",
      "SGD iter. 2218/3599: loss=0.09475814401165236\n",
      "SGD iter. 2219/3599: loss=0.08931454600780325\n",
      "SGD iter. 2220/3599: loss=0.0986762996764427\n",
      "SGD iter. 2221/3599: loss=0.09253102019616893\n",
      "SGD iter. 2222/3599: loss=0.09456130907733129\n",
      "SGD iter. 2223/3599: loss=0.09494906654250729\n",
      "SGD iter. 2224/3599: loss=0.09004481470017565\n",
      "SGD iter. 2225/3599: loss=0.09174065192527123\n",
      "SGD iter. 2226/3599: loss=0.08641810792618805\n",
      "SGD iter. 2227/3599: loss=0.09643424595956748\n",
      "SGD iter. 2228/3599: loss=0.09658370029150345\n",
      "SGD iter. 2229/3599: loss=0.09011080009951769\n",
      "SGD iter. 2230/3599: loss=0.09164647792064169\n",
      "SGD iter. 2231/3599: loss=0.09587952365958702\n",
      "SGD iter. 2232/3599: loss=0.1005588245641427\n",
      "SGD iter. 2233/3599: loss=0.08653446551605325\n",
      "SGD iter. 2234/3599: loss=0.09579485084320319\n",
      "SGD iter. 2235/3599: loss=0.08698431426850099\n",
      "SGD iter. 2236/3599: loss=0.09458910248084813\n",
      "SGD iter. 2237/3599: loss=0.08743894077328423\n",
      "SGD iter. 2238/3599: loss=0.09679875596255799\n",
      "SGD iter. 2239/3599: loss=0.08945437042310475\n",
      "SGD iter. 2240/3599: loss=0.10038014881119765\n",
      "SGD iter. 2241/3599: loss=0.08890414365077713\n",
      "SGD iter. 2242/3599: loss=0.09153641714028261\n",
      "SGD iter. 2243/3599: loss=0.10118773530720916\n",
      "SGD iter. 2244/3599: loss=0.08227865946886105\n",
      "SGD iter. 2245/3599: loss=0.08774354756843411\n",
      "SGD iter. 2246/3599: loss=0.09949160464102288\n",
      "SGD iter. 2247/3599: loss=0.09757153381216341\n",
      "SGD iter. 2248/3599: loss=0.08326303847739958\n",
      "SGD iter. 2249/3599: loss=0.07696562383770707\n",
      "SGD iter. 2250/3599: loss=0.09401985674301437\n",
      "SGD iter. 2251/3599: loss=0.08829504646642329\n",
      "SGD iter. 2252/3599: loss=0.08818709674768918\n",
      "SGD iter. 2253/3599: loss=0.09461190883818082\n",
      "SGD iter. 2254/3599: loss=0.10334814775352387\n",
      "SGD iter. 2255/3599: loss=0.09227963924594178\n",
      "SGD iter. 2256/3599: loss=0.08963328391130779\n",
      "SGD iter. 2257/3599: loss=0.08072429800539402\n",
      "SGD iter. 2258/3599: loss=0.0878013336406129\n",
      "SGD iter. 2259/3599: loss=0.09592890934577865\n",
      "SGD iter. 2260/3599: loss=0.09484702015507065\n",
      "SGD iter. 2261/3599: loss=0.09605735951656495\n",
      "SGD iter. 2262/3599: loss=0.10123901467459225\n",
      "SGD iter. 2263/3599: loss=0.0998709747656554\n",
      "SGD iter. 2264/3599: loss=0.08924456518906386\n",
      "SGD iter. 2265/3599: loss=0.09843140523629287\n",
      "SGD iter. 2266/3599: loss=0.09479577098209398\n",
      "SGD iter. 2267/3599: loss=0.09439654865510283\n",
      "SGD iter. 2268/3599: loss=0.09110315831685153\n",
      "SGD iter. 2269/3599: loss=0.09281490764701453\n",
      "SGD iter. 2270/3599: loss=0.09314298123725703\n",
      "SGD iter. 2271/3599: loss=0.08863609696318582\n",
      "SGD iter. 2272/3599: loss=0.0887571720121256\n",
      "SGD iter. 2273/3599: loss=0.0834162534516182\n",
      "SGD iter. 2274/3599: loss=0.08682827528380836\n",
      "SGD iter. 2275/3599: loss=0.09473679802587605\n",
      "SGD iter. 2276/3599: loss=0.08933387784533298\n",
      "SGD iter. 2277/3599: loss=0.09325026601747545\n",
      "SGD iter. 2278/3599: loss=0.08877251911762453\n",
      "SGD iter. 2279/3599: loss=0.09123535863983942\n",
      "SGD iter. 2280/3599: loss=0.09920997377090524\n",
      "SGD iter. 2281/3599: loss=0.09310414957850302\n",
      "SGD iter. 2282/3599: loss=0.08982095186698665\n",
      "SGD iter. 2283/3599: loss=0.09291384932870597\n",
      "SGD iter. 2284/3599: loss=0.09205590467887824\n",
      "SGD iter. 2285/3599: loss=0.08645297295124635\n",
      "SGD iter. 2286/3599: loss=0.0809540810248017\n",
      "SGD iter. 2287/3599: loss=0.09917869305292262\n",
      "SGD iter. 2288/3599: loss=0.08863840868122544\n",
      "SGD iter. 2289/3599: loss=0.08513503159521119\n",
      "SGD iter. 2290/3599: loss=0.093242791559603\n",
      "SGD iter. 2291/3599: loss=0.09153464646970211\n",
      "SGD iter. 2292/3599: loss=0.09395383612116213\n",
      "SGD iter. 2293/3599: loss=0.09898063604562246\n",
      "SGD iter. 2294/3599: loss=0.09971697639976038\n",
      "SGD iter. 2295/3599: loss=0.08584211770930099\n",
      "SGD iter. 2296/3599: loss=0.09133750141003671\n",
      "SGD iter. 2297/3599: loss=0.09846580627858853\n",
      "SGD iter. 2298/3599: loss=0.09377562411590179\n",
      "SGD iter. 2299/3599: loss=0.09680686365974253\n",
      "SGD iter. 2300/3599: loss=0.09110547092875443\n",
      "SGD iter. 2301/3599: loss=0.09724381526303025\n",
      "SGD iter. 2302/3599: loss=0.08877036393090564\n",
      "SGD iter. 2303/3599: loss=0.0899966780383114\n",
      "SGD iter. 2304/3599: loss=0.09152677480948401\n",
      "SGD iter. 2305/3599: loss=0.09568196667911776\n",
      "SGD iter. 2306/3599: loss=0.08665214414469037\n",
      "SGD iter. 2307/3599: loss=0.09549627171265658\n",
      "SGD iter. 2308/3599: loss=0.0972794334136794\n",
      "SGD iter. 2309/3599: loss=0.08874894856287696\n",
      "SGD iter. 2310/3599: loss=0.0863559898659701\n",
      "SGD iter. 2311/3599: loss=0.09011744469550384\n",
      "SGD iter. 2312/3599: loss=0.08851185773791526\n",
      "SGD iter. 2313/3599: loss=0.10067559851848255\n",
      "SGD iter. 2314/3599: loss=0.09659142829483607\n",
      "SGD iter. 2315/3599: loss=0.10016212475531043\n",
      "SGD iter. 2316/3599: loss=0.09193350108704468\n",
      "SGD iter. 2317/3599: loss=0.10073211369704366\n",
      "SGD iter. 2318/3599: loss=0.08943836288717949\n",
      "SGD iter. 2319/3599: loss=0.08964301634963168\n",
      "SGD iter. 2320/3599: loss=0.09373619902524874\n",
      "SGD iter. 2321/3599: loss=0.08693613098095135\n",
      "SGD iter. 2322/3599: loss=0.0876319526230008\n",
      "SGD iter. 2323/3599: loss=0.09677017710246957\n",
      "SGD iter. 2324/3599: loss=0.08229696932311353\n",
      "SGD iter. 2325/3599: loss=0.0957575303327734\n",
      "SGD iter. 2326/3599: loss=0.0905431449194147\n",
      "SGD iter. 2327/3599: loss=0.10593868057395851\n",
      "SGD iter. 2328/3599: loss=0.0967120085174393\n",
      "SGD iter. 2329/3599: loss=0.09033828117473486\n",
      "SGD iter. 2330/3599: loss=0.09531019983426733\n",
      "SGD iter. 2331/3599: loss=0.09507686089841749\n",
      "SGD iter. 2332/3599: loss=0.095174611408089\n",
      "SGD iter. 2333/3599: loss=0.0916561174265462\n",
      "SGD iter. 2334/3599: loss=0.09416701549408223\n",
      "SGD iter. 2335/3599: loss=0.09202572630980621\n",
      "SGD iter. 2336/3599: loss=0.09497158461748798\n",
      "SGD iter. 2337/3599: loss=0.08792680075198613\n",
      "SGD iter. 2338/3599: loss=0.08954663598935625\n",
      "SGD iter. 2339/3599: loss=0.08296689027139809\n",
      "SGD iter. 2340/3599: loss=0.09805988759726661\n",
      "SGD iter. 2341/3599: loss=0.09047151073734624\n",
      "SGD iter. 2342/3599: loss=0.10465362497476433\n",
      "SGD iter. 2343/3599: loss=0.09078063341364578\n",
      "SGD iter. 2344/3599: loss=0.08720898986550177\n",
      "SGD iter. 2345/3599: loss=0.08781447443496829\n",
      "SGD iter. 2346/3599: loss=0.08721203451429836\n",
      "SGD iter. 2347/3599: loss=0.08559964497500279\n",
      "SGD iter. 2348/3599: loss=0.09529070182646826\n",
      "SGD iter. 2349/3599: loss=0.09618704052857452\n",
      "SGD iter. 2350/3599: loss=0.09203993662529387\n",
      "SGD iter. 2351/3599: loss=0.09477758835593636\n",
      "SGD iter. 2352/3599: loss=0.09231590053346153\n",
      "SGD iter. 2353/3599: loss=0.09672900873475819\n",
      "SGD iter. 2354/3599: loss=0.09230301775854227\n",
      "SGD iter. 2355/3599: loss=0.08857006564645156\n",
      "SGD iter. 2356/3599: loss=0.08918465409496525\n",
      "SGD iter. 2357/3599: loss=0.10651668482961449\n",
      "SGD iter. 2358/3599: loss=0.09820937325725282\n",
      "SGD iter. 2359/3599: loss=0.09633305078357056\n",
      "SGD iter. 2360/3599: loss=0.09503930303889169\n",
      "SGD iter. 2361/3599: loss=0.08753175181024295\n",
      "SGD iter. 2362/3599: loss=0.08524833760219563\n",
      "SGD iter. 2363/3599: loss=0.09602968376889423\n",
      "SGD iter. 2364/3599: loss=0.09258213869475916\n",
      "SGD iter. 2365/3599: loss=0.09150447706139705\n",
      "SGD iter. 2366/3599: loss=0.09344897819107065\n",
      "SGD iter. 2367/3599: loss=0.10191186347550621\n",
      "SGD iter. 2368/3599: loss=0.09017877699618598\n",
      "SGD iter. 2369/3599: loss=0.08861560559647311\n",
      "SGD iter. 2370/3599: loss=0.09466918608440122\n",
      "SGD iter. 2371/3599: loss=0.09142132608422031\n",
      "SGD iter. 2372/3599: loss=0.09206094966289435\n",
      "SGD iter. 2373/3599: loss=0.10227506556350074\n",
      "SGD iter. 2374/3599: loss=0.10099208310252288\n",
      "SGD iter. 2375/3599: loss=0.09144360016153531\n",
      "SGD iter. 2376/3599: loss=0.08764645427868417\n",
      "SGD iter. 2377/3599: loss=0.08954925367343675\n",
      "SGD iter. 2378/3599: loss=0.09162175338731385\n",
      "SGD iter. 2379/3599: loss=0.09846504533393788\n",
      "SGD iter. 2380/3599: loss=0.09442889928217284\n",
      "SGD iter. 2381/3599: loss=0.09570643342119378\n",
      "SGD iter. 2382/3599: loss=0.08806196543696801\n",
      "SGD iter. 2383/3599: loss=0.09058349048023949\n",
      "SGD iter. 2384/3599: loss=0.09194923662792898\n",
      "SGD iter. 2385/3599: loss=0.08619645168978071\n",
      "SGD iter. 2386/3599: loss=0.09310527980349073\n",
      "SGD iter. 2387/3599: loss=0.08996628247485156\n",
      "SGD iter. 2388/3599: loss=0.08222958569290834\n",
      "SGD iter. 2389/3599: loss=0.0929105275173689\n",
      "SGD iter. 2390/3599: loss=0.08431277138540573\n",
      "SGD iter. 2391/3599: loss=0.10162162948535153\n",
      "SGD iter. 2392/3599: loss=0.10122276302401989\n",
      "SGD iter. 2393/3599: loss=0.09249144854758765\n",
      "SGD iter. 2394/3599: loss=0.09567218251391443\n",
      "SGD iter. 2395/3599: loss=0.08647385302395819\n",
      "SGD iter. 2396/3599: loss=0.09012386920434115\n",
      "SGD iter. 2397/3599: loss=0.08421715695911142\n",
      "SGD iter. 2398/3599: loss=0.08445771428371072\n",
      "SGD iter. 2399/3599: loss=0.09902311323236455\n",
      "SGD iter. 2400/3599: loss=0.09078796966293208\n",
      "SGD iter. 2401/3599: loss=0.08992514552023906\n",
      "SGD iter. 2402/3599: loss=0.0875734726142399\n",
      "SGD iter. 2403/3599: loss=0.09809486146168372\n",
      "SGD iter. 2404/3599: loss=0.09240036443260732\n",
      "SGD iter. 2405/3599: loss=0.10070791910197494\n",
      "SGD iter. 2406/3599: loss=0.10267319806342465\n",
      "SGD iter. 2407/3599: loss=0.09280582955096281\n",
      "SGD iter. 2408/3599: loss=0.08468234609801795\n",
      "SGD iter. 2409/3599: loss=0.09065568667793887\n",
      "SGD iter. 2410/3599: loss=0.09220247234823263\n",
      "SGD iter. 2411/3599: loss=0.09253504375515142\n",
      "SGD iter. 2412/3599: loss=0.09599122564164683\n",
      "SGD iter. 2413/3599: loss=0.08713520528759125\n",
      "SGD iter. 2414/3599: loss=0.09399901506279013\n",
      "SGD iter. 2415/3599: loss=0.09612302764798214\n",
      "SGD iter. 2416/3599: loss=0.09974505976013381\n",
      "SGD iter. 2417/3599: loss=0.08708432986362807\n",
      "SGD iter. 2418/3599: loss=0.08797514276204203\n",
      "SGD iter. 2419/3599: loss=0.09138966559202821\n",
      "SGD iter. 2420/3599: loss=0.09534366530607682\n",
      "SGD iter. 2421/3599: loss=0.09055708269847275\n",
      "SGD iter. 2422/3599: loss=0.08159952073555518\n",
      "SGD iter. 2423/3599: loss=0.0914707479965852\n",
      "SGD iter. 2424/3599: loss=0.09227878477275503\n",
      "SGD iter. 2425/3599: loss=0.09085035176404224\n",
      "SGD iter. 2426/3599: loss=0.09286975066486677\n",
      "SGD iter. 2427/3599: loss=0.08872483321740701\n",
      "SGD iter. 2428/3599: loss=0.09173015682938238\n",
      "SGD iter. 2429/3599: loss=0.08526233458135428\n",
      "SGD iter. 2430/3599: loss=0.09003184753696661\n",
      "SGD iter. 2431/3599: loss=0.08657399869742344\n",
      "SGD iter. 2432/3599: loss=0.08872926065272588\n",
      "SGD iter. 2433/3599: loss=0.09892885203011775\n",
      "SGD iter. 2434/3599: loss=0.0903992819679097\n",
      "SGD iter. 2435/3599: loss=0.0873771154815868\n",
      "SGD iter. 2436/3599: loss=0.09631581547395027\n",
      "SGD iter. 2437/3599: loss=0.09600938153831629\n",
      "SGD iter. 2438/3599: loss=0.09721172229762637\n",
      "SGD iter. 2439/3599: loss=0.087382288875596\n",
      "SGD iter. 2440/3599: loss=0.08939608719784141\n",
      "SGD iter. 2441/3599: loss=0.08993228363026146\n",
      "SGD iter. 2442/3599: loss=0.09901841327740328\n",
      "SGD iter. 2443/3599: loss=0.08422460684925556\n",
      "SGD iter. 2444/3599: loss=0.09847401565269676\n",
      "SGD iter. 2445/3599: loss=0.0893885099380888\n",
      "SGD iter. 2446/3599: loss=0.08656590857854553\n",
      "SGD iter. 2447/3599: loss=0.0921468416034629\n",
      "SGD iter. 2448/3599: loss=0.08839500551420879\n",
      "SGD iter. 2449/3599: loss=0.08625576238646453\n",
      "SGD iter. 2450/3599: loss=0.08821927014712015\n",
      "SGD iter. 2451/3599: loss=0.0994953324757111\n",
      "SGD iter. 2452/3599: loss=0.09362513207771199\n",
      "SGD iter. 2453/3599: loss=0.089354469076147\n",
      "SGD iter. 2454/3599: loss=0.10176578252816007\n",
      "SGD iter. 2455/3599: loss=0.08888453155993054\n",
      "SGD iter. 2456/3599: loss=0.08093668619554095\n",
      "SGD iter. 2457/3599: loss=0.09254421133710578\n",
      "SGD iter. 2458/3599: loss=0.08928383655518393\n",
      "SGD iter. 2459/3599: loss=0.0949485905667026\n",
      "SGD iter. 2460/3599: loss=0.09540259271253315\n",
      "SGD iter. 2461/3599: loss=0.0874973598323842\n",
      "SGD iter. 2462/3599: loss=0.09182002119614888\n",
      "SGD iter. 2463/3599: loss=0.0945877109363728\n",
      "SGD iter. 2464/3599: loss=0.09478962656412541\n",
      "SGD iter. 2465/3599: loss=0.08897930670968861\n",
      "SGD iter. 2466/3599: loss=0.08787985832556681\n",
      "SGD iter. 2467/3599: loss=0.09575218957459856\n",
      "SGD iter. 2468/3599: loss=0.0869947781850157\n",
      "SGD iter. 2469/3599: loss=0.09371883512984225\n",
      "SGD iter. 2470/3599: loss=0.08770584311894464\n",
      "SGD iter. 2471/3599: loss=0.08304468311802292\n",
      "SGD iter. 2472/3599: loss=0.08652912259646175\n",
      "SGD iter. 2473/3599: loss=0.09306184198427075\n",
      "SGD iter. 2474/3599: loss=0.10056041945715413\n",
      "SGD iter. 2475/3599: loss=0.09222939849042572\n",
      "SGD iter. 2476/3599: loss=0.09895747373137215\n",
      "SGD iter. 2477/3599: loss=0.08201758786712324\n",
      "SGD iter. 2478/3599: loss=0.09102843379595638\n",
      "SGD iter. 2479/3599: loss=0.08459541365304268\n",
      "SGD iter. 2480/3599: loss=0.09510281557828999\n",
      "SGD iter. 2481/3599: loss=0.08913675364483528\n",
      "SGD iter. 2482/3599: loss=0.1021881986134599\n",
      "SGD iter. 2483/3599: loss=0.09221167288112778\n",
      "SGD iter. 2484/3599: loss=0.09687757416423907\n",
      "SGD iter. 2485/3599: loss=0.09057623993929896\n",
      "SGD iter. 2486/3599: loss=0.09078744669367998\n",
      "SGD iter. 2487/3599: loss=0.0923857906060246\n",
      "SGD iter. 2488/3599: loss=0.09588195871681154\n",
      "SGD iter. 2489/3599: loss=0.08836883344062725\n",
      "SGD iter. 2490/3599: loss=0.09391111079647094\n",
      "SGD iter. 2491/3599: loss=0.08818935945410894\n",
      "SGD iter. 2492/3599: loss=0.10105197561605199\n",
      "SGD iter. 2493/3599: loss=0.08961390715692724\n",
      "SGD iter. 2494/3599: loss=0.09141486576868046\n",
      "SGD iter. 2495/3599: loss=0.09415601843111421\n",
      "SGD iter. 2496/3599: loss=0.09011129922332303\n",
      "SGD iter. 2497/3599: loss=0.07950516724015744\n",
      "SGD iter. 2498/3599: loss=0.09137034990134527\n",
      "SGD iter. 2499/3599: loss=0.09578234391153581\n",
      "SGD iter. 2500/3599: loss=0.09058343167810695\n",
      "SGD iter. 2501/3599: loss=0.09473639391670885\n",
      "SGD iter. 2502/3599: loss=0.09056489438791943\n",
      "SGD iter. 2503/3599: loss=0.09070987896031629\n",
      "SGD iter. 2504/3599: loss=0.09085686532828408\n",
      "SGD iter. 2505/3599: loss=0.09724553092900332\n",
      "SGD iter. 2506/3599: loss=0.08815232123883124\n",
      "SGD iter. 2507/3599: loss=0.09114391532738095\n",
      "SGD iter. 2508/3599: loss=0.09619310558489128\n",
      "SGD iter. 2509/3599: loss=0.08344943678595637\n",
      "SGD iter. 2510/3599: loss=0.09072134855105585\n",
      "SGD iter. 2511/3599: loss=0.0816523647692195\n",
      "SGD iter. 2512/3599: loss=0.09227195010733825\n",
      "SGD iter. 2513/3599: loss=0.08764636436851685\n",
      "SGD iter. 2514/3599: loss=0.0859391788358547\n",
      "SGD iter. 2515/3599: loss=0.08943698571461886\n",
      "SGD iter. 2516/3599: loss=0.09473659756011012\n",
      "SGD iter. 2517/3599: loss=0.099428492272517\n",
      "SGD iter. 2518/3599: loss=0.09179179843367666\n",
      "SGD iter. 2519/3599: loss=0.08057271691898898\n",
      "SGD iter. 2520/3599: loss=0.09863065216734566\n",
      "SGD iter. 2521/3599: loss=0.09532030812107878\n",
      "SGD iter. 2522/3599: loss=0.08715340263707064\n",
      "SGD iter. 2523/3599: loss=0.08253521379158624\n",
      "SGD iter. 2524/3599: loss=0.08955987898291753\n",
      "SGD iter. 2525/3599: loss=0.08630205286343207\n",
      "SGD iter. 2526/3599: loss=0.10198138363518683\n",
      "SGD iter. 2527/3599: loss=0.09417452628829237\n",
      "SGD iter. 2528/3599: loss=0.0856830678047661\n",
      "SGD iter. 2529/3599: loss=0.09129991365976715\n",
      "SGD iter. 2530/3599: loss=0.09034432169292493\n",
      "SGD iter. 2531/3599: loss=0.09632979696627839\n",
      "SGD iter. 2532/3599: loss=0.09358265020238554\n",
      "SGD iter. 2533/3599: loss=0.07890047383398789\n",
      "SGD iter. 2534/3599: loss=0.09898955291285302\n",
      "SGD iter. 2535/3599: loss=0.08519640975058143\n",
      "SGD iter. 2536/3599: loss=0.09744776460781875\n",
      "SGD iter. 2537/3599: loss=0.09540440128242339\n",
      "SGD iter. 2538/3599: loss=0.08624568716961492\n",
      "SGD iter. 2539/3599: loss=0.09289239628368778\n",
      "SGD iter. 2540/3599: loss=0.08129574790928196\n",
      "SGD iter. 2541/3599: loss=0.08299439439295095\n",
      "SGD iter. 2542/3599: loss=0.0951240697495881\n",
      "SGD iter. 2543/3599: loss=0.09721100488725187\n",
      "SGD iter. 2544/3599: loss=0.09113830720209695\n",
      "SGD iter. 2545/3599: loss=0.09771068820758672\n",
      "SGD iter. 2546/3599: loss=0.08988281273015546\n",
      "SGD iter. 2547/3599: loss=0.09183456651515785\n",
      "SGD iter. 2548/3599: loss=0.09315380107774512\n",
      "SGD iter. 2549/3599: loss=0.074573660719352\n",
      "SGD iter. 2550/3599: loss=0.08519591252055381\n",
      "SGD iter. 2551/3599: loss=0.09308976398927374\n",
      "SGD iter. 2552/3599: loss=0.09334444261097055\n",
      "SGD iter. 2553/3599: loss=0.0906191904799238\n",
      "SGD iter. 2554/3599: loss=0.09389475671151881\n",
      "SGD iter. 2555/3599: loss=0.09325469516348493\n",
      "SGD iter. 2556/3599: loss=0.10047127223213548\n",
      "SGD iter. 2557/3599: loss=0.08251863888049307\n",
      "SGD iter. 2558/3599: loss=0.08692271155226927\n",
      "SGD iter. 2559/3599: loss=0.09175761219679784\n",
      "SGD iter. 2560/3599: loss=0.09192462227445759\n",
      "SGD iter. 2561/3599: loss=0.08942847992590375\n",
      "SGD iter. 2562/3599: loss=0.08296250837517935\n",
      "SGD iter. 2563/3599: loss=0.09317323506020439\n",
      "SGD iter. 2564/3599: loss=0.09420159131964805\n",
      "SGD iter. 2565/3599: loss=0.09339606552525084\n",
      "SGD iter. 2566/3599: loss=0.08273626207460413\n",
      "SGD iter. 2567/3599: loss=0.083157412235393\n",
      "SGD iter. 2568/3599: loss=0.0934616871580888\n",
      "SGD iter. 2569/3599: loss=0.09232006201908698\n",
      "SGD iter. 2570/3599: loss=0.09329225284609838\n",
      "SGD iter. 2571/3599: loss=0.08400312796567713\n",
      "SGD iter. 2572/3599: loss=0.08336450692498507\n",
      "SGD iter. 2573/3599: loss=0.08455734883789315\n",
      "SGD iter. 2574/3599: loss=0.08206526527879598\n",
      "SGD iter. 2575/3599: loss=0.08910329622112842\n",
      "SGD iter. 2576/3599: loss=0.09301529289464018\n",
      "SGD iter. 2577/3599: loss=0.08549567945962723\n",
      "SGD iter. 2578/3599: loss=0.1023594617743486\n",
      "SGD iter. 2579/3599: loss=0.09920914438125969\n",
      "SGD iter. 2580/3599: loss=0.08102844970581494\n",
      "SGD iter. 2581/3599: loss=0.09485185605565005\n",
      "SGD iter. 2582/3599: loss=0.10038809878480992\n",
      "SGD iter. 2583/3599: loss=0.08970102298744195\n",
      "SGD iter. 2584/3599: loss=0.0884016830279871\n",
      "SGD iter. 2585/3599: loss=0.09946432185082765\n",
      "SGD iter. 2586/3599: loss=0.09862526348777023\n",
      "SGD iter. 2587/3599: loss=0.08862564834188533\n",
      "SGD iter. 2588/3599: loss=0.10585949386347848\n",
      "SGD iter. 2589/3599: loss=0.08854586681551363\n",
      "SGD iter. 2590/3599: loss=0.07967876367373433\n",
      "SGD iter. 2591/3599: loss=0.08746287067498364\n",
      "SGD iter. 2592/3599: loss=0.08759570928274091\n",
      "SGD iter. 2593/3599: loss=0.09090485875877677\n",
      "SGD iter. 2594/3599: loss=0.08883675090084878\n",
      "SGD iter. 2595/3599: loss=0.09243058240886934\n",
      "SGD iter. 2596/3599: loss=0.10125122355286212\n",
      "SGD iter. 2597/3599: loss=0.084040643359394\n",
      "SGD iter. 2598/3599: loss=0.09133523115898007\n",
      "SGD iter. 2599/3599: loss=0.08849182807043252\n",
      "SGD iter. 2600/3599: loss=0.09563545867618443\n",
      "SGD iter. 2601/3599: loss=0.08552066057249033\n",
      "SGD iter. 2602/3599: loss=0.09080187549369026\n",
      "SGD iter. 2603/3599: loss=0.09903659366668971\n",
      "SGD iter. 2604/3599: loss=0.08899854379568672\n",
      "SGD iter. 2605/3599: loss=0.09826210880175733\n",
      "SGD iter. 2606/3599: loss=0.08188694534256098\n",
      "SGD iter. 2607/3599: loss=0.09755845786966229\n",
      "SGD iter. 2608/3599: loss=0.09700091662287236\n",
      "SGD iter. 2609/3599: loss=0.09232774761098524\n",
      "SGD iter. 2610/3599: loss=0.09235947983434387\n",
      "SGD iter. 2611/3599: loss=0.09153114646423165\n",
      "SGD iter. 2612/3599: loss=0.08696120953546589\n",
      "SGD iter. 2613/3599: loss=0.0902917332406632\n",
      "SGD iter. 2614/3599: loss=0.08669684942756331\n",
      "SGD iter. 2615/3599: loss=0.08328451317579069\n",
      "SGD iter. 2616/3599: loss=0.08767959077077006\n",
      "SGD iter. 2617/3599: loss=0.09564885596553971\n",
      "SGD iter. 2618/3599: loss=0.11577565531821818\n",
      "SGD iter. 2619/3599: loss=0.08474495324267188\n",
      "SGD iter. 2620/3599: loss=0.09284559424244587\n",
      "SGD iter. 2621/3599: loss=0.09302520647484114\n",
      "SGD iter. 2622/3599: loss=0.08960137791738332\n",
      "SGD iter. 2623/3599: loss=0.09398065137753459\n",
      "SGD iter. 2624/3599: loss=0.09461979753062873\n",
      "SGD iter. 2625/3599: loss=0.0985215640181852\n",
      "SGD iter. 2626/3599: loss=0.09232667983980021\n",
      "SGD iter. 2627/3599: loss=0.09314964842805795\n",
      "SGD iter. 2628/3599: loss=0.08682454168031636\n",
      "SGD iter. 2629/3599: loss=0.08801292530552295\n",
      "SGD iter. 2630/3599: loss=0.09706890612903495\n",
      "SGD iter. 2631/3599: loss=0.0947617942545922\n",
      "SGD iter. 2632/3599: loss=0.09745966537336953\n",
      "SGD iter. 2633/3599: loss=0.09260779098208209\n",
      "SGD iter. 2634/3599: loss=0.09171412617331583\n",
      "SGD iter. 2635/3599: loss=0.09307817905404099\n",
      "SGD iter. 2636/3599: loss=0.09921407135733096\n",
      "SGD iter. 2637/3599: loss=0.08994245964198794\n",
      "SGD iter. 2638/3599: loss=0.08268065613688444\n",
      "SGD iter. 2639/3599: loss=0.08907354250891801\n",
      "SGD iter. 2640/3599: loss=0.09447014680329438\n",
      "SGD iter. 2641/3599: loss=0.09536553967708555\n",
      "SGD iter. 2642/3599: loss=0.08314003492836138\n",
      "SGD iter. 2643/3599: loss=0.08476259535959892\n",
      "SGD iter. 2644/3599: loss=0.08626688524405823\n",
      "SGD iter. 2645/3599: loss=0.09155997274629823\n",
      "SGD iter. 2646/3599: loss=0.08926416907613668\n",
      "SGD iter. 2647/3599: loss=0.09224002920311081\n",
      "SGD iter. 2648/3599: loss=0.08674652102600394\n",
      "SGD iter. 2649/3599: loss=0.08622918105993686\n",
      "SGD iter. 2650/3599: loss=0.08980108793276556\n",
      "SGD iter. 2651/3599: loss=0.09218445529589163\n",
      "SGD iter. 2652/3599: loss=0.09612860806162787\n",
      "SGD iter. 2653/3599: loss=0.09091123327304723\n",
      "SGD iter. 2654/3599: loss=0.07986925804152838\n",
      "SGD iter. 2655/3599: loss=0.0947904888574354\n",
      "SGD iter. 2656/3599: loss=0.0929103201865721\n",
      "SGD iter. 2657/3599: loss=0.09163526522987941\n",
      "SGD iter. 2658/3599: loss=0.08582723410033251\n",
      "SGD iter. 2659/3599: loss=0.09284489971938567\n",
      "SGD iter. 2660/3599: loss=0.08718550510050171\n",
      "SGD iter. 2661/3599: loss=0.08438882966659988\n",
      "SGD iter. 2662/3599: loss=0.08612624901803435\n",
      "SGD iter. 2663/3599: loss=0.08939065482290304\n",
      "SGD iter. 2664/3599: loss=0.09634135600410301\n",
      "SGD iter. 2665/3599: loss=0.08784093358408071\n",
      "SGD iter. 2666/3599: loss=0.08931747741378646\n",
      "SGD iter. 2667/3599: loss=0.09180749297114293\n",
      "SGD iter. 2668/3599: loss=0.09892555755233183\n",
      "SGD iter. 2669/3599: loss=0.08374702884460256\n",
      "SGD iter. 2670/3599: loss=0.08673965228697204\n",
      "SGD iter. 2671/3599: loss=0.09551565423817497\n",
      "SGD iter. 2672/3599: loss=0.10370408108382798\n",
      "SGD iter. 2673/3599: loss=0.09152620062845039\n",
      "SGD iter. 2674/3599: loss=0.08983566215487036\n",
      "SGD iter. 2675/3599: loss=0.09477526653175869\n",
      "SGD iter. 2676/3599: loss=0.09242082899591628\n",
      "SGD iter. 2677/3599: loss=0.09187927405418693\n",
      "SGD iter. 2678/3599: loss=0.09510374382433645\n",
      "SGD iter. 2679/3599: loss=0.09472956488834233\n",
      "SGD iter. 2680/3599: loss=0.09025695220744395\n",
      "SGD iter. 2681/3599: loss=0.08862777172403549\n",
      "SGD iter. 2682/3599: loss=0.07549445514197327\n",
      "SGD iter. 2683/3599: loss=0.09142439679848643\n",
      "SGD iter. 2684/3599: loss=0.09079155424937957\n",
      "SGD iter. 2685/3599: loss=0.09531971974319864\n",
      "SGD iter. 2686/3599: loss=0.09887554217386159\n",
      "SGD iter. 2687/3599: loss=0.09829851439929838\n",
      "SGD iter. 2688/3599: loss=0.09618960042356649\n",
      "SGD iter. 2689/3599: loss=0.08654666001709986\n",
      "SGD iter. 2690/3599: loss=0.07335753476907761\n",
      "SGD iter. 2691/3599: loss=0.08643442161285439\n",
      "SGD iter. 2692/3599: loss=0.09372743898291026\n",
      "SGD iter. 2693/3599: loss=0.0887713068431385\n",
      "SGD iter. 2694/3599: loss=0.09718696231536922\n",
      "SGD iter. 2695/3599: loss=0.08964629176240566\n",
      "SGD iter. 2696/3599: loss=0.09198507693060043\n",
      "SGD iter. 2697/3599: loss=0.09594276507361524\n",
      "SGD iter. 2698/3599: loss=0.08810708363871572\n",
      "SGD iter. 2699/3599: loss=0.0930442108836313\n",
      "SGD iter. 2700/3599: loss=0.08786061085555898\n",
      "SGD iter. 2701/3599: loss=0.09607064630129182\n",
      "SGD iter. 2702/3599: loss=0.09287312495874117\n",
      "SGD iter. 2703/3599: loss=0.08647263486302104\n",
      "SGD iter. 2704/3599: loss=0.09313124155010236\n",
      "SGD iter. 2705/3599: loss=0.08848741792657025\n",
      "SGD iter. 2706/3599: loss=0.08942567331803045\n",
      "SGD iter. 2707/3599: loss=0.09275875617558424\n",
      "SGD iter. 2708/3599: loss=0.09361413040551358\n",
      "SGD iter. 2709/3599: loss=0.09738354331921745\n",
      "SGD iter. 2710/3599: loss=0.08869176138126708\n",
      "SGD iter. 2711/3599: loss=0.0889736467507801\n",
      "SGD iter. 2712/3599: loss=0.08940337153788837\n",
      "SGD iter. 2713/3599: loss=0.08203881483962414\n",
      "SGD iter. 2714/3599: loss=0.09395496312453983\n",
      "SGD iter. 2715/3599: loss=0.08706351512543675\n",
      "SGD iter. 2716/3599: loss=0.08226164042670904\n",
      "SGD iter. 2717/3599: loss=0.09019039929923849\n",
      "SGD iter. 2718/3599: loss=0.09311912123042423\n",
      "SGD iter. 2719/3599: loss=0.08181193843976317\n",
      "SGD iter. 2720/3599: loss=0.10043467304564074\n",
      "SGD iter. 2721/3599: loss=0.0936167452235621\n",
      "SGD iter. 2722/3599: loss=0.08337762932016826\n",
      "SGD iter. 2723/3599: loss=0.0810959613442597\n",
      "SGD iter. 2724/3599: loss=0.10038442373315634\n",
      "SGD iter. 2725/3599: loss=0.08902687574570159\n",
      "SGD iter. 2726/3599: loss=0.0788596355735288\n",
      "SGD iter. 2727/3599: loss=0.10298690535570205\n",
      "SGD iter. 2728/3599: loss=0.09530822974330917\n",
      "SGD iter. 2729/3599: loss=0.08534537984122587\n",
      "SGD iter. 2730/3599: loss=0.09264928537256513\n",
      "SGD iter. 2731/3599: loss=0.08916496311708622\n",
      "SGD iter. 2732/3599: loss=0.08455231548494033\n",
      "SGD iter. 2733/3599: loss=0.09066078365682753\n",
      "SGD iter. 2734/3599: loss=0.09344415835550597\n",
      "SGD iter. 2735/3599: loss=0.0830170214785553\n",
      "SGD iter. 2736/3599: loss=0.09100700312802626\n",
      "SGD iter. 2737/3599: loss=0.09195562733176081\n",
      "SGD iter. 2738/3599: loss=0.08887648528386102\n",
      "SGD iter. 2739/3599: loss=0.08675958647238566\n",
      "SGD iter. 2740/3599: loss=0.08862961820066985\n",
      "SGD iter. 2741/3599: loss=0.09252750129873365\n",
      "SGD iter. 2742/3599: loss=0.09231420178215546\n",
      "SGD iter. 2743/3599: loss=0.090307915031101\n",
      "SGD iter. 2744/3599: loss=0.0957464626607904\n",
      "SGD iter. 2745/3599: loss=0.09175185104264277\n",
      "SGD iter. 2746/3599: loss=0.09180693138052057\n",
      "SGD iter. 2747/3599: loss=0.08330739352972805\n",
      "SGD iter. 2748/3599: loss=0.08950745262989274\n",
      "SGD iter. 2749/3599: loss=0.09657869562355426\n",
      "SGD iter. 2750/3599: loss=0.09187914495511527\n",
      "SGD iter. 2751/3599: loss=0.09334834270716097\n",
      "SGD iter. 2752/3599: loss=0.08756614124755521\n",
      "SGD iter. 2753/3599: loss=0.09315258086976974\n",
      "SGD iter. 2754/3599: loss=0.08194882326367955\n",
      "SGD iter. 2755/3599: loss=0.08994189347864916\n",
      "SGD iter. 2756/3599: loss=0.09480187114832625\n",
      "SGD iter. 2757/3599: loss=0.08896304897638818\n",
      "SGD iter. 2758/3599: loss=0.08355491004756041\n",
      "SGD iter. 2759/3599: loss=0.09173076784442386\n",
      "SGD iter. 2760/3599: loss=0.0891845733937374\n",
      "SGD iter. 2761/3599: loss=0.10560548841889691\n",
      "SGD iter. 2762/3599: loss=0.08046474389328334\n",
      "SGD iter. 2763/3599: loss=0.09081168169738889\n",
      "SGD iter. 2764/3599: loss=0.09044456075220084\n",
      "SGD iter. 2765/3599: loss=0.09311685372712185\n",
      "SGD iter. 2766/3599: loss=0.08811651540108299\n",
      "SGD iter. 2767/3599: loss=0.09492288148319622\n",
      "SGD iter. 2768/3599: loss=0.09490501895804773\n",
      "SGD iter. 2769/3599: loss=0.07694828371672682\n",
      "SGD iter. 2770/3599: loss=0.0909534175823841\n",
      "SGD iter. 2771/3599: loss=0.09222812903987848\n",
      "SGD iter. 2772/3599: loss=0.09330081155738437\n",
      "SGD iter. 2773/3599: loss=0.09109455492858123\n",
      "SGD iter. 2774/3599: loss=0.09484348917762811\n",
      "SGD iter. 2775/3599: loss=0.08308996623211493\n",
      "SGD iter. 2776/3599: loss=0.09582540950436566\n",
      "SGD iter. 2777/3599: loss=0.0908197446298259\n",
      "SGD iter. 2778/3599: loss=0.09180919209164287\n",
      "SGD iter. 2779/3599: loss=0.09260614186215617\n",
      "SGD iter. 2780/3599: loss=0.07720642951503215\n",
      "SGD iter. 2781/3599: loss=0.0897993259032431\n",
      "SGD iter. 2782/3599: loss=0.09512517862810282\n",
      "SGD iter. 2783/3599: loss=0.09946376287141095\n",
      "SGD iter. 2784/3599: loss=0.10170509256191705\n",
      "SGD iter. 2785/3599: loss=0.09333229718463076\n",
      "SGD iter. 2786/3599: loss=0.08742496563189875\n",
      "SGD iter. 2787/3599: loss=0.08934003996539977\n",
      "SGD iter. 2788/3599: loss=0.07972822397612206\n",
      "SGD iter. 2789/3599: loss=0.09620672820909304\n",
      "SGD iter. 2790/3599: loss=0.0905663692071135\n",
      "SGD iter. 2791/3599: loss=0.08094506493413159\n",
      "SGD iter. 2792/3599: loss=0.09161970988863924\n",
      "SGD iter. 2793/3599: loss=0.08493483446388869\n",
      "SGD iter. 2794/3599: loss=0.09559452642151778\n",
      "SGD iter. 2795/3599: loss=0.09289390442165937\n",
      "SGD iter. 2796/3599: loss=0.07886988592564959\n",
      "SGD iter. 2797/3599: loss=0.09795680574671434\n",
      "SGD iter. 2798/3599: loss=0.09703325976756176\n",
      "SGD iter. 2799/3599: loss=0.10653790995054754\n",
      "SGD iter. 2800/3599: loss=0.08899006018102412\n",
      "SGD iter. 2801/3599: loss=0.09478369489545468\n",
      "SGD iter. 2802/3599: loss=0.082740059670974\n",
      "SGD iter. 2803/3599: loss=0.0908252834309438\n",
      "SGD iter. 2804/3599: loss=0.0990775944356351\n",
      "SGD iter. 2805/3599: loss=0.08810799478269296\n",
      "SGD iter. 2806/3599: loss=0.1013947651009148\n",
      "SGD iter. 2807/3599: loss=0.08996051087068638\n",
      "SGD iter. 2808/3599: loss=0.0845213002410603\n",
      "SGD iter. 2809/3599: loss=0.0842379068391262\n",
      "SGD iter. 2810/3599: loss=0.09449001742633054\n",
      "SGD iter. 2811/3599: loss=0.08417353520712971\n",
      "SGD iter. 2812/3599: loss=0.0971186166813933\n",
      "SGD iter. 2813/3599: loss=0.09534691622643914\n",
      "SGD iter. 2814/3599: loss=0.10262277066961906\n",
      "SGD iter. 2815/3599: loss=0.09016464224258375\n",
      "SGD iter. 2816/3599: loss=0.10028623313114239\n",
      "SGD iter. 2817/3599: loss=0.0852504415073557\n",
      "SGD iter. 2818/3599: loss=0.08970387348788951\n",
      "SGD iter. 2819/3599: loss=0.08766221016723413\n",
      "SGD iter. 2820/3599: loss=0.09525292196452433\n",
      "SGD iter. 2821/3599: loss=0.08960438783167013\n",
      "SGD iter. 2822/3599: loss=0.09191535281747437\n",
      "SGD iter. 2823/3599: loss=0.08722441503789959\n",
      "SGD iter. 2824/3599: loss=0.08847213493407184\n",
      "SGD iter. 2825/3599: loss=0.09425831525642275\n",
      "SGD iter. 2826/3599: loss=0.09116265690220415\n",
      "SGD iter. 2827/3599: loss=0.092342110436871\n",
      "SGD iter. 2828/3599: loss=0.09652487523908226\n",
      "SGD iter. 2829/3599: loss=0.09421270891877867\n",
      "SGD iter. 2830/3599: loss=0.09613257721030839\n",
      "SGD iter. 2831/3599: loss=0.09534104999998765\n",
      "SGD iter. 2832/3599: loss=0.0907271158756719\n",
      "SGD iter. 2833/3599: loss=0.0962847505439145\n",
      "SGD iter. 2834/3599: loss=0.09712987426062106\n",
      "SGD iter. 2835/3599: loss=0.08259149685427566\n",
      "SGD iter. 2836/3599: loss=0.09178554874532124\n",
      "SGD iter. 2837/3599: loss=0.09839459045093821\n",
      "SGD iter. 2838/3599: loss=0.09022657098635001\n",
      "SGD iter. 2839/3599: loss=0.08704435767918364\n",
      "SGD iter. 2840/3599: loss=0.08974710790991361\n",
      "SGD iter. 2841/3599: loss=0.08661293665164117\n",
      "SGD iter. 2842/3599: loss=0.0829490320252459\n",
      "SGD iter. 2843/3599: loss=0.07956906990799842\n",
      "SGD iter. 2844/3599: loss=0.08792029025080114\n",
      "SGD iter. 2845/3599: loss=0.09212189488785383\n",
      "SGD iter. 2846/3599: loss=0.08734401538613226\n",
      "SGD iter. 2847/3599: loss=0.09404303350183135\n",
      "SGD iter. 2848/3599: loss=0.09422228429481255\n",
      "SGD iter. 2849/3599: loss=0.09904569035759617\n",
      "SGD iter. 2850/3599: loss=0.09297673156489841\n",
      "SGD iter. 2851/3599: loss=0.0976691700889775\n",
      "SGD iter. 2852/3599: loss=0.08502819621955535\n",
      "SGD iter. 2853/3599: loss=0.0831258435021988\n",
      "SGD iter. 2854/3599: loss=0.08533681868957371\n",
      "SGD iter. 2855/3599: loss=0.09322305770666067\n",
      "SGD iter. 2856/3599: loss=0.08961953360595099\n",
      "SGD iter. 2857/3599: loss=0.09142906872675752\n",
      "SGD iter. 2858/3599: loss=0.086525098525444\n",
      "SGD iter. 2859/3599: loss=0.08704224857403374\n",
      "SGD iter. 2860/3599: loss=0.09410008516781848\n",
      "SGD iter. 2861/3599: loss=0.09259259429797091\n",
      "SGD iter. 2862/3599: loss=0.08139535835731197\n",
      "SGD iter. 2863/3599: loss=0.10053708531728231\n",
      "SGD iter. 2864/3599: loss=0.0894677962745809\n",
      "SGD iter. 2865/3599: loss=0.10292960930713366\n",
      "SGD iter. 2866/3599: loss=0.10300796388272618\n",
      "SGD iter. 2867/3599: loss=0.0898555415150377\n",
      "SGD iter. 2868/3599: loss=0.09706093211641911\n",
      "SGD iter. 2869/3599: loss=0.09004669696667791\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [65], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m initial_w \u001b[39m=\u001b[39m generate_w(x_tr\u001b[39m.\u001b[39mshape)\n\u001b[0;32m      8\u001b[0m np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mseed(seed)\n\u001b[1;32m----> 9\u001b[0m w, loss \u001b[39m=\u001b[39m mean_squared_error_sgd(y_tr, x_tr, initial_w, max_iters, gamma, batch_size, shuffle \u001b[39m=\u001b[39;49m \u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m     10\u001b[0m pred \u001b[39m=\u001b[39m predict_mse(x_tr, w)\n\u001b[0;32m     11\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mThe training accuracy is:\u001b[39m\u001b[39m\"\u001b[39m, get_accuracy(y_tr, pred))\n",
      "File \u001b[1;32mf:\\ML\\ML_Project\\ML-Project1\\implementations.py:134\u001b[0m, in \u001b[0;36mmean_squared_error_sgd\u001b[1;34m(y, tx, initial_w, max_iters, gamma, batch_size, shuffle)\u001b[0m\n\u001b[0;32m    132\u001b[0m loss \u001b[39m=\u001b[39m compute_loss(y, tx, w)\n\u001b[0;32m    133\u001b[0m \u001b[39mfor\u001b[39;00m n_iter \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mint\u001b[39m(max_iters)):\n\u001b[1;32m--> 134\u001b[0m     \u001b[39mfor\u001b[39;00m yi, txi \u001b[39min\u001b[39;00m batch_iter(y, tx, batch_size, num_batches\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, shuffle \u001b[39m=\u001b[39m shuffle):\n\u001b[0;32m    135\u001b[0m         g, e \u001b[39m=\u001b[39m compute_stoch_gradient(yi, txi, w)\n\u001b[0;32m    136\u001b[0m         w \u001b[39m=\u001b[39m w \u001b[39m-\u001b[39m gamma\u001b[39m*\u001b[39mg\n",
      "File \u001b[1;32mf:\\ML\\ML_Project\\ML-Project1\\helpers.py:226\u001b[0m, in \u001b[0;36mbatch_iter\u001b[1;34m(y, tx, batch_size, num_batches, shuffle)\u001b[0m\n\u001b[0;32m    224\u001b[0m     shuffled_y \u001b[39m=\u001b[39m y\n\u001b[0;32m    225\u001b[0m     shuffled_tx \u001b[39m=\u001b[39m tx\n\u001b[1;32m--> 226\u001b[0m \u001b[39mfor\u001b[39;00m batch_num \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39;49m(num_batches):\n\u001b[0;32m    227\u001b[0m     start_index \u001b[39m=\u001b[39m batch_num \u001b[39m*\u001b[39m batch_size\n\u001b[0;32m    228\u001b[0m     end_index \u001b[39m=\u001b[39m \u001b[39mmin\u001b[39m((batch_num \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m) \u001b[39m*\u001b[39m batch_size, data_size)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Define the parameters of the algorithm.\n",
    "max_iters = 3600\n",
    "gamma = 0.01\n",
    "batch_size = 200\n",
    "seed = 1\n",
    "# Initialization\n",
    "initial_w = generate_w(x_tr.shape)\n",
    "np.random.seed(seed)\n",
    "w, loss = mean_squared_error_sgd(y_tr, x_tr, initial_w, max_iters, gamma, batch_size, shuffle = True)\n",
    "pred = predict_mse(x_tr, w)\n",
    "print(\"The training accuracy is:\", get_accuracy(y_tr, pred))\n",
    "pred = predict_mse(x_v, w)\n",
    "print(\"The validation accuracy is:\", get_accuracy(y_v, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it: 0 acc: 0.34218499999999996 loss: 2.9093900686434693\n",
      "it: 10 acc: 0.6578200000000001 loss: 3.939499413836463\n",
      "it: 20 acc: 0.657845 loss: 1.2279828428273687\n",
      "it: 30 acc: 0.34218499999999996 loss: 6.346472283858717\n",
      "it: 40 acc: 0.6578200000000001 loss: 3.939494255542461\n",
      "it: 50 acc: 0.65787 loss: 1.2206895340533688\n",
      "it: 60 acc: 0.34218499999999996 loss: 6.299403328340079\n",
      "it: 70 acc: 0.6578200000000001 loss: 3.9394904834467175\n",
      "it: 80 acc: 0.6578999999999999 loss: 1.2183468656894563\n",
      "it: 90 acc: 0.34218499999999996 loss: 6.246312186683734\n",
      "it: 100 acc: 0.6578200000000001 loss: 3.939486791485679\n",
      "it: 110 acc: 0.6579699999999999 loss: 1.2191900026260998\n",
      "it: 120 acc: 0.34218499999999996 loss: 6.187441598539171\n",
      "it: 130 acc: 0.6578200000000001 loss: 3.939481320635358\n",
      "it: 140 acc: 0.658115 loss: 1.223082657163389\n",
      "it: 150 acc: 0.34218499999999996 loss: 6.123063805725133\n",
      "it: 160 acc: 0.6578200000000001 loss: 3.9394754940923193\n",
      "it: 170 acc: 0.6582250000000001 loss: 1.2298617719780613\n",
      "it: 180 acc: 0.34218499999999996 loss: 6.053516042086538\n",
      "it: 190 acc: 0.6578200000000001 loss: 3.939469379461755\n",
      "it: 200 acc: 0.658415 loss: 1.2393440885712699\n",
      "it: 210 acc: 0.34218499999999996 loss: 5.979174414737232\n",
      "it: 220 acc: 0.6578200000000001 loss: 3.939459865107137\n",
      "it: 230 acc: 0.6587149999999999 loss: 1.25133255430475\n",
      "it: 240 acc: 0.34218499999999996 loss: 5.900407927072225\n",
      "it: 250 acc: 0.6578200000000001 loss: 3.9394455252355907\n",
      "it: 260 acc: 0.65908 loss: 1.2656218873021885\n",
      "it: 270 acc: 0.34218499999999996 loss: 5.817584065035102\n",
      "it: 280 acc: 0.6578200000000001 loss: 3.9394278528371225\n",
      "it: 290 acc: 0.65943 loss: 1.2820027091828279\n",
      "it: 300 acc: 0.34218499999999996 loss: 5.73105866145506\n",
      "it: 310 acc: 0.6578200000000001 loss: 3.939409746549233\n",
      "it: 320 acc: 0.6598200000000001 loss: 1.30026401412637\n",
      "it: 330 acc: 0.34218499999999996 loss: 5.641198271958964\n",
      "it: 340 acc: 0.6578200000000001 loss: 3.9393902494018764\n",
      "it: 350 acc: 0.66031 loss: 1.3201938931987844\n",
      "it: 360 acc: 0.34218499999999996 loss: 5.548336535012962\n",
      "it: 370 acc: 0.6578200000000001 loss: 3.9393692602679953\n",
      "it: 380 acc: 0.66089 loss: 1.341578576564\n",
      "it: 390 acc: 0.34218499999999996 loss: 5.4527886564480585\n",
      "it: 400 acc: 0.6578200000000001 loss: 3.939344494274764\n",
      "it: 410 acc: 0.66132 loss: 1.3641998088394665\n",
      "it: 420 acc: 0.34218499999999996 loss: 5.354847520830883\n",
      "it: 430 acc: 0.6578200000000001 loss: 3.9393107130527425\n",
      "it: 440 acc: 0.661915 loss: 1.3878305393653954\n",
      "it: 450 acc: 0.34218499999999996 loss: 5.254801886891773\n",
      "it: 460 acc: 0.6578200000000001 loss: 3.93927190676009\n",
      "it: 470 acc: 0.66256 loss: 1.4122288468990922\n",
      "it: 480 acc: 0.34218499999999996 loss: 5.152932577900934\n",
      "it: 490 acc: 0.6578200000000001 loss: 3.9392258952221124\n"
     ]
    }
   ],
   "source": [
    "# x_tr_aug = np.concatenate((np.ones((x_tr.shape[0], 1)), x_tr, x_tr**2, x_tr**3), axis=1)\n",
    "initial_w = np.random.randn(x_tr.shape[1])\n",
    "max_iters = 500\n",
    "gamma = 0.3\n",
    "losses = []\n",
    "for i in range(max_iters):\n",
    "    w, loss = logistic_regression(y_tr>0, x_tr, initial_w, 1, gamma)\n",
    "    losses.append(loss)\n",
    "    initial_w = w\n",
    "    pred = predict_logistic(x_tr, w)\n",
    "    if i%10 == 0:\n",
    "        print(\"it:\", i, \"acc:\", get_accuracy(y_tr, pred), \"loss:\", loss)\n",
    "#print(\"The validation accuracy is:\", get_accuracy(y_v, x_v, w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08356183231405012\n",
      "The training accuracy is: 0.75037\n",
      "The validation accuracy is: 0.75074\n"
     ]
    }
   ],
   "source": [
    "w, loss = least_squares(y_tr, x_tr)\n",
    "print(loss)\n",
    "pred = predict_mse(x_tr, w)\n",
    "print(\"The training accuracy is:\", get_accuracy(y_tr, pred))\n",
    "pred = predict_mse(x_v, w)\n",
    "print(\"The validation accuracy is:\", get_accuracy(y_v, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "id, preds = test(id_te, x_te, w)\n",
    "create_csv_submission(id, preds, \"least_squares_75.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient descent training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training accuracy is: 0.749065\n",
      "The validation accuracy is: 0.75008\n"
     ]
    }
   ],
   "source": [
    "# Define the parameters of the algorithm.\n",
    "max_iters = 200\n",
    "gamma = 0.15\n",
    "# Initialization\n",
    "initial_w = generate_w(x_tr.shape)\n",
    "w, loss = mean_squared_error_gd(y_tr, x_tr, initial_w, max_iters, gamma)\n",
    "pred = predict_mse(x_tr, w)\n",
    "print(\"The training accuracy is:\", get_accuracy(y_tr, pred))\n",
    "pred = predict_mse(x_v, w)\n",
    "print(\"The validation accuracy is:\", get_accuracy(y_v, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "id, preds = test(id_te, x_te, w)\n",
    "create_csv_submission(id, preds, \"testing_test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SGD training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training accuracy is: 0.74769\n",
      "The validation accuracy is: 0.74864\n"
     ]
    }
   ],
   "source": [
    "# Define the parameters of the algorithm.\n",
    "max_iters = 200\n",
    "gamma = 0.06\n",
    "batch_size = 200\n",
    "seed = 1\n",
    "# Initialization\n",
    "initial_w = generate_w(x_tr.shape)\n",
    "np.random.seed(seed)\n",
    "w, loss = mean_squared_error_sgd(y_tr, x_tr, initial_w, max_iters, gamma, batch_size, shuffle = True)\n",
    "pred = predict_mse(x_tr, w)\n",
    "print(\"The training accuracy is:\", get_accuracy(y_tr, pred))\n",
    "pred = predict_mse(x_v, w)\n",
    "print(\"The validation accuracy is:\", get_accuracy(y_v, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training accuracy is: 0.746028\n"
     ]
    }
   ],
   "source": [
    "print(\"The training accuracy is:\", get_accuracy(y_tr, x_tr, w))\n",
    "#print(\"The validation accuracy is:\", get_accuracy(y_v, x_v, w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "id, preds = test(id_te, x_te, w)\n",
    "create_csv_submission(id, preds, \"SGD_test_74.8.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# insert remaining test codes below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08412672882257373\n",
      "The training accuracy is: 0.7474799999999999\n"
     ]
    }
   ],
   "source": [
    "w, loss = least_squares(y_tr, x_tr)\n",
    "print(loss)\n",
    "print(\"The training accuracy is:\", get_accuracy(y_tr, x_tr, w))\n",
    "#print(\"The validation accuracy is:\", get_accuracy(y_v, x_v, w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "id, preds = test(id_te, x_te, w)\n",
    "create_csv_submission(id, preds, \"least_squares_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training accuracy is: 0.7455879999999999\n"
     ]
    }
   ],
   "source": [
    "w, loss = ridge_regression(y_tr, x_tr, 0.005)\n",
    "pred = predict_mse(x_tr, w)\n",
    "print(\"The training accuracy is:\", get_accuracy(y_tr,pred))\n",
    "pred = predict_mse(x_v, w)\n",
    "print(\"The validation accuracy is:\", get_accuracy(y_v, x_v, w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio = 0.8  #ratio is the percentage of the data allocated for training \n",
    "seed = 1  #random seed for data shuffling\n",
    "x_tr, y_tr, x_te, id_te = preprocess_data_final() #preprocess intput data from the training and test sets\n",
    "x_tr, x_v, y_tr, y_v = split_data(x_tr, y_tr, ratio, seed) #split training data into training and validation setsb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training accuracy is: 0.754665\n",
      "The validation accuracy is: 0.7554\n",
      "The training accuracy is: 0.77809\n",
      "The validation accuracy is: 0.77896\n",
      "The training accuracy is: 0.79217\n",
      "The validation accuracy is: 0.7923\n",
      "The training accuracy is: 0.80223\n",
      "The validation accuracy is: 0.80106\n",
      "The training accuracy is: 0.80399\n",
      "The validation accuracy is: 0.80238\n",
      "The training accuracy is: 0.80442\n",
      "The validation accuracy is: 0.80234\n",
      "The training accuracy is: 0.804605\n",
      "The validation accuracy is: 0.80188\n",
      "The training accuracy is: 0.805575\n",
      "The validation accuracy is: 0.8028\n",
      "The training accuracy is: 0.80541\n",
      "The validation accuracy is: 0.80358\n",
      "The training accuracy is: 0.805355\n",
      "The validation accuracy is: 0.80392\n",
      "The training accuracy is: 0.805775\n",
      "The validation accuracy is: 0.80436\n"
     ]
    }
   ],
   "source": [
    "x_tr =  build_poly(x_tr, 3)\n",
    "x_v =  build_poly(x_v, 3)\n",
    "\n",
    "w, loss = ridge_regression(y_tr, x_tr, 10e-2)\n",
    "pred = predict_mse(x_tr, w)\n",
    "print(\"The training accuracy is:\", get_accuracy(y_tr,pred))\n",
    "pred = predict_mse(x_v, w)\n",
    "print(\"The validation accuracy is:\", get_accuracy(y_v,pred))\n",
    "\n",
    "w, loss = ridge_regression(y_tr, x_tr, 10e-3)\n",
    "pred = predict_mse(x_tr, w)\n",
    "print(\"The training accuracy is:\", get_accuracy(y_tr,pred))\n",
    "pred = predict_mse(x_v, w)\n",
    "print(\"The validation accuracy is:\", get_accuracy(y_v,pred))\n",
    "\n",
    "w, loss = ridge_regression(y_tr, x_tr, 10e-4)\n",
    "pred = predict_mse(x_tr, w)\n",
    "print(\"The training accuracy is:\", get_accuracy(y_tr,pred))\n",
    "pred = predict_mse(x_v, w)\n",
    "print(\"The validation accuracy is:\", get_accuracy(y_v,pred))\n",
    "\n",
    "w, loss = ridge_regression(y_tr, x_tr, 10e-5)\n",
    "pred = predict_mse(x_tr, w)\n",
    "print(\"The training accuracy is:\", get_accuracy(y_tr,pred))\n",
    "pred = predict_mse(x_v, w)\n",
    "print(\"The validation accuracy is:\", get_accuracy(y_v,pred))\n",
    "\n",
    "w, loss = ridge_regression(y_tr, x_tr, 10e-6)\n",
    "pred = predict_mse(x_tr, w)\n",
    "print(\"The training accuracy is:\", get_accuracy(y_tr,pred))\n",
    "pred = predict_mse(x_v, w)\n",
    "print(\"The validation accuracy is:\", get_accuracy(y_v,pred))\n",
    "\n",
    "w, loss = ridge_regression(y_tr, x_tr, 10e-7)\n",
    "pred = predict_mse(x_tr, w)\n",
    "print(\"The training accuracy is:\", get_accuracy(y_tr,pred))\n",
    "pred = predict_mse(x_v, w)\n",
    "print(\"The validation accuracy is:\", get_accuracy(y_v,pred))\n",
    "\n",
    "w, loss = ridge_regression(y_tr, x_tr, 10e-8)\n",
    "pred = predict_mse(x_tr, w)\n",
    "print(\"The training accuracy is:\", get_accuracy(y_tr,pred))\n",
    "pred = predict_mse(x_v, w)\n",
    "print(\"The validation accuracy is:\", get_accuracy(y_v,pred))\n",
    "\n",
    "w, loss = ridge_regression(y_tr, x_tr, 10e-9)\n",
    "pred = predict_mse(x_tr, w)\n",
    "print(\"The training accuracy is:\", get_accuracy(y_tr,pred))\n",
    "pred = predict_mse(x_v, w)\n",
    "print(\"The validation accuracy is:\", get_accuracy(y_v,pred))\n",
    "\n",
    "w, loss = ridge_regression(y_tr, x_tr, 10e-10)\n",
    "pred = predict_mse(x_tr, w)\n",
    "print(\"The training accuracy is:\", get_accuracy(y_tr,pred))\n",
    "pred = predict_mse(x_v, w)\n",
    "print(\"The validation accuracy is:\", get_accuracy(y_v,pred))\n",
    "\n",
    "w, loss = ridge_regression(y_tr, x_tr, 10e-11)\n",
    "pred = predict_mse(x_tr, w)\n",
    "print(\"The training accuracy is:\", get_accuracy(y_tr,pred))\n",
    "pred = predict_mse(x_v, w)\n",
    "print(\"The validation accuracy is:\", get_accuracy(y_v,pred))\n",
    "\n",
    "w, loss = ridge_regression(y_tr, x_tr, 10e-12)\n",
    "pred = predict_mse(x_tr, w)\n",
    "print(\"The training accuracy is:\", get_accuracy(y_tr,pred))\n",
    "pred = predict_mse(x_v, w)\n",
    "print(\"The validation accuracy is:\", get_accuracy(y_v,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_te =  build_poly(x_te, 3)\n",
    "id, preds = test(id_te, x_te, w)\n",
    "create_csv_submission(id, preds, \"ridge_higher.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_w = np.random.randn(x_tr.shape[1])\n",
    "max_iters = 500\n",
    "gamma = 0.3\n",
    "losses = []\n",
    "w, loss = logistic_regression(y_tr>0, x_tr, initial_w, max_iters, gamma)\n",
    "losses.append(loss)\n",
    "initial_w = w\n",
    "pred = predict_logistic(x_tr, w)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training accuracy is: 0.75115\n"
     ]
    }
   ],
   "source": [
    "print(\"The training accuracy is:\", get_accuracy(y_tr,pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training accuracy is: 0.6655519999999999\n"
     ]
    }
   ],
   "source": [
    "initial_w = generate_w(x_tr.shape)\n",
    "max_iters = 50\n",
    "gamma = 0.01\n",
    "lambda_ = 0.1\n",
    "w, loss = reg_logistic_regression(y_tr, x_tr, lambda_, initial_w, max_iters, gamma)\n",
    "pred = predict_logistic(x_tr, w)\n",
    "print(\"The training accuracy is:\", get_accuracy(y_tr, pred))\n",
    "#print(\"The validation accuracy is:\", get_accuracy(y_v, x_v, w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.342668\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.077432"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(y_tr.mean())\n",
    "initial_w = generate_w(x_tr.shape)\n",
    "pred = sigmoid(x_tr.dot(initial_w)) > 0.5\n",
    "np.mean(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (250000,31) and (250000,10) not aligned: 31 (dim 1) != 250000 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [34]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m initial_w \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrandn(x_tr\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m10\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m \u001b[43mx_tr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43minitial_w\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValueError\u001b[0m: shapes (250000,31) and (250000,10) not aligned: 31 (dim 1) != 250000 (dim 0)"
     ]
    }
   ],
   "source": [
    "initial_w = np.random.randn(x_tr.shape[0], 10)\n",
    "x_tr.dot(initial_w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## make test file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = ((x_te.dot(w) >= 0 ) - 0.5 )* 2\n",
    "# create_csv_submission(id_te, pred, 'least_sq.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "ee6b41961f93c6f250bc55b15f7bfcab9769f15680d1f879ddd8dd4e686622cd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
